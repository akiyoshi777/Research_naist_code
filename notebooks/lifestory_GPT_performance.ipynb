{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/is/akiyoshi-n/my-project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 使用するGPUを指定. この環境変数の場所は，pytorchをimportする前に入れる\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from src.my_project.dataset import load_multiclass_dataset, load_dataset_2class_classification, load_dataset_4class_Multi_classification, split_test_data_stratify, load_text_dataset, split_multilabel_data\n",
    "from src.my_project.train_v2 import MultiClassClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.my_project.dataset import load_multiclass_dataset\n",
    "import wandb\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = Path('/home/is/akiyoshi-n/my-project/data')\n",
    "# 本日の日付\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "# 出力先ディレクトリ\n",
    "output_dir = Path('/home/is/akiyoshi-n/my-project/outputs/{}'.format(timestamp))\n",
    "# モデル出力先ディレクトリ\n",
    "output_model_dir = Path('/home/is/akiyoshi-n/my-project/outputs_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大トークン数\n",
    "MAX_LEN = 128\n",
    "# バッチサイズ\n",
    "BATCH_SIZE = 16\n",
    "# エポック数\n",
    "NUM_EPOCHS = 100\n",
    "# 学習率\n",
    "LEARNING_RATE = 2e-5\n",
    "# Cross Validation時のFold数\n",
    "NUM_FOLDS = 5\n",
    "# 早期停止のための忍耐値\n",
    "PATIENCE = 4\n",
    "# 乱数シード\n",
    "SEED = 2024\n",
    "# クラス数\n",
    "NUM_LABELS = 4\n",
    "# 閾値\n",
    "THRESH = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辞書型でデータ取得\n",
    "data = load_dataset_2class_classification(f\"{DATASET_PATH}/lifestory_GPT+human_annotation.xlsx\")\n",
    "data_pred = load_dataset_2class_classification(f\"{DATASET_PATH}/raw_lifestory_GPT-4o_annotation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7017543859649122, 'macro_f1': 0.6262990108295193}\n"
     ]
    }
   ],
   "source": [
    "answer = np.array(data['labels'])\n",
    "pred = np.array(data_pred['labels'])\n",
    "accuracy = accuracy_score(y_true=answer, y_pred=pred)\n",
    "f1 = f1_score(y_true=answer, y_pred=pred, average='macro')\n",
    "print({\"accuracy\": accuracy, \"macro_f1\": macro_f1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "data, class_name = load_dataset_4class_Multi_classification(f\"{DATASET_PATH}/lifestory_GPT+human_annotation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "data_pred, class_name_pred = load_dataset_4class_Multi_classification(f\"{DATASET_PATH}/raw_lifestory_GPT-4o_annotation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5727554179566563, 'macro_f1': 0.6262990108295193, 'class_f1': [0.646, 0.559, 0.71, 0.591]}\n"
     ]
    }
   ],
   "source": [
    "# AccuracyとMacro-F1\n",
    "# numpy.ndarray配列に変換\n",
    "answer = np.array(data['labels'])\n",
    "pred = np.array(data_pred['labels'])\n",
    "# accuracyを計算\n",
    "accuracy = accuracy_score(y_true=answer, y_pred=pred)\n",
    "# macro f1を計算\n",
    "macro_f1 = f1_score(y_true=answer, y_pred=pred, average='macro', zero_division=0)\n",
    "# クラス毎のF1値を計算\n",
    "class_f1 = [round(score, 3) for score in f1_score(y_true=answer, y_pred=pred, average=None, zero_division=0)]\n",
    "print({\"accuracy\": accuracy, \"macro_f1\": macro_f1, \"class_f1\": class_f1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "data, class_name = load_multiclass_dataset(f\"{DATASET_PATH}/lifestory_GPT+human_annotation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1 - A. 睡眠', '1 - B. 身の回りの用事', '1 - C - a. 食事-飲酒あり',\n",
       "       '1 - C - b. 食事-飲酒なし・不明', '2 - A - a. 通勤・通学', '2 - A - b. その他の移動',\n",
       "       '2 - B. 仕事', '2 - C. 学業', '2 - D. 家事', '2 - E. 介護・看護', '2 - F. 育児',\n",
       "       '3 - A. メディア', '3 - B. 買い物', '3 - C - a. 趣味・娯楽-体動かす',\n",
       "       '3 - C - b. 趣味・娯楽-体動かさない', '3 - D - a. 交際-物理的接触',\n",
       "       '3 - D - b. 交際-オンライン的接触', '3 - E. 受診・療養', '3 - F - b. その他の活動',\n",
       "       '4. 行動なし'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name\n",
    "# 喫煙が抜けてる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "data_pred, class_name_pred = load_multiclass_dataset(f\"{DATASET_PATH}/raw_lifestory_GPT-4o_annotation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sublist in data['labels']:\n",
    "    sublist.insert(-2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5036119711042312, 'macro_f1': 0.5283847855501879, 'class_f1': [0.714, 0.591, 0.706, 0.659, 0.762, 0.602, 0.561, 0.0, 0.348, 0.311, 0.554, 0.774, 0.731, 0.629, 0.636, 0.471, 0.468, 0.615, 0.0, 0.374, 0.591]}\n"
     ]
    }
   ],
   "source": [
    "# AccuracyとMacro-F1\n",
    "# numpy.ndarray配列に変換\n",
    "answer = np.array(data['labels'])\n",
    "pred = np.array(data_pred['labels'])\n",
    "# accuracyを計算\n",
    "accuracy = accuracy_score(y_true=answer, y_pred=pred)\n",
    "# macro f1を計算\n",
    "macro_f1 = f1_score(y_true=answer, y_pred=pred, average='macro', zero_division=0)\n",
    "# クラス毎のF1値を計算\n",
    "class_f1 = [round(score, 3) for score in f1_score(y_true=answer, y_pred=pred, average=None, zero_division=0)]\n",
    "print({\"accuracy\": accuracy, \"macro_f1\": macro_f1, \"class_f1\": class_f1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カッパ係数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "# data_Nakae, class_name = load_multiclass_dataset(f\"{DATASET_PATH}/lifestory_GPT+human_annotation.xlsx\")\n",
    "data_Nakae, class_name = load_multiclass_dataset(f\"{DATASET_PATH}/lifestory_nakae_annotation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1 - A. 睡眠', '1 - B. 身の回りの用事', '1 - C - a. 食事-飲酒あり',\n",
       "       '1 - C - b. 食事-飲酒なし・不明', '2 - A - a. 通勤・通学', '2 - A - b. その他の移動',\n",
       "       '2 - B. 仕事', '2 - C. 学業', '2 - D. 家事', '2 - E. 介護・看護', '2 - F. 育児',\n",
       "       '3 - A. メディア', '3 - B. 買い物', '3 - C - a. 趣味・娯楽-体動かす',\n",
       "       '3 - C - b. 趣味・娯楽-体動かさない', '3 - D - a. 交際-物理的接触',\n",
       "       '3 - D - b. 交際-オンライン的接触', '3 - E. 受診・療養', '3 - F - b. その他の活動',\n",
       "       '4. 行動なし'], dtype=object)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name\n",
    "# 喫煙が抜けてる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "data_Akiyoshi, class_name_pred = load_multiclass_dataset(f\"{DATASET_PATH}/lifestory_annotator_annotation.xlsx\")\n",
    "# data_Akiyoshi, class_name_pred = load_multiclass_dataset(f\"{DATASET_PATH}/lifestory_GPT+human_annotation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1 - A. 睡眠', '1 - B. 身の回りの用事', '1 - C - a. 食事-飲酒あり',\n",
       "       '1 - C - b. 食事-飲酒なし・不明', '2 - A - a. 通勤・通学', '2 - A - b. その他の移動',\n",
       "       '2 - B. 仕事', '2 - C. 学業', '2 - D. 家事', '2 - E. 介護・看護', '2 - F. 育児',\n",
       "       '3 - A. メディア', '3 - B. 買い物', '3 - C - a. 趣味・娯楽-体動かす',\n",
       "       '3 - C - b. 趣味・娯楽-体動かさない', '3 - D - a. 交際-物理的接触',\n",
       "       '3 - D - b. 交際-オンライン的接触', '3 - E. 受診・療養', '3 - F - b. その他の活動',\n",
       "       '4. 行動なし'], dtype=object)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100行目までのデータを取得\n",
    "data_Nakae_100 = data_Nakae['labels'][0:100]\n",
    "data_Akiyoshi_100 = data_Akiyoshi['labels'][0:100]\n",
    "data_Nakae_100_200 = data_Nakae['labels'][100:500]\n",
    "data_Akiyoshi_100_200 = data_Akiyoshi['labels'][100:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  3,  1,  3,  0,  5,  5,  1,  4,  2,  2,  4, 10,  6,  3,  5,  1,\n",
       "        8, 13, 40])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels_np = np.array(data_Nakae_100)\n",
    "data_labels_np.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  4,  1,  5,  0,  7,  3,  1,  9,  5,  3,  4, 12,  1,  4,  3,  1,\n",
       "        9,  0,  8, 35])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels_np = np.array(data_Akiyoshi_100)\n",
    "data_labels_np.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   6,   0,   6,   5,  21,  15,   0,  25,   6,  11,  20,  19,\n",
       "         6,   8,   9,   7,  17,  13, 215])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels_np = np.array(data_Nakae_100_200)\n",
    "data_labels_np.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20)\n",
      "(100, 21)\n",
      "(400, 20)\n",
      "(400, 21)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(data_Nakae_100).shape)\n",
    "print(np.array(data_Akiyoshi_100).shape)\n",
    "print(np.array(data_Nakae_100_200).shape)\n",
    "print(np.array(data_Akiyoshi_100_200).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sublist in data_Nakae_100:\n",
    "    sublist.insert(-2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sublist in data_Nakae_100_200:\n",
    "    sublist.insert(-2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 21)\n",
      "(100, 21)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(data_Nakae_100).shape)\n",
    "print(np.array(data_Akiyoshi_100).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 5: Skipped due to no variance.\n",
      "Label 19: Skipped due to no variance.\n",
      "Average Cohen's Kappa: 0.67\n"
     ]
    }
   ],
   "source": [
    "# NumPy配列に変換（必要に応じて）\n",
    "data_Nakae_100 = np.array(data_Nakae_100)\n",
    "data_Akiyoshi_100 = np.array(data_Akiyoshi_100)\n",
    "\n",
    "# 各ラベル列ごとにCohen's Kappaを計算（バリエーションがゼロの場合スキップ）\n",
    "kappa_scores = []\n",
    "for i in range(data_Nakae_100.shape[1]):\n",
    "    if np.var(data_Nakae_100[:, i]) == 0 and np.var(data_Akiyoshi_100[:, i]) == 0:\n",
    "        print(f\"Label {i + 1}: Skipped due to no variance.\")\n",
    "        kappa_scores.append(1.0)  # 完全一致とみなす場合\n",
    "        continue\n",
    "    kappa = cohen_kappa_score(data_Nakae_100[:, i], data_Akiyoshi_100[:, i])\n",
    "    kappa_scores.append(kappa if not np.isnan(kappa) else 0)\n",
    "\n",
    "# 平均Kappa\n",
    "average_kappa = np.nanmean(kappa_scores)  # NaNを無視して平均計算\n",
    "print(f\"Average Cohen's Kappa: {average_kappa:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact match rate: 65.00%\n"
     ]
    }
   ],
   "source": [
    "# 行が完全一致している数を計算\n",
    "exact_matches = np.sum(np.all(data_Nakae_100 == data_Akiyoshi_100, axis=1))\n",
    "# 行数\n",
    "num_rows = data_Nakae_100.shape[0]\n",
    "# 完全一致率\n",
    "exact_match_rate = exact_matches / num_rows\n",
    "print(f\"Exact match rate: {exact_match_rate:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cohen's Kappa: 0.45\n"
     ]
    }
   ],
   "source": [
    "# numpy配列に変換\n",
    "data_Nakae_100_200 = np.array(data_Nakae_100_200)\n",
    "data_Akiyoshi_100_200 = np.array(data_Akiyoshi_100_200)\n",
    "\n",
    "# 各ラベル列ごとにCohen's Kappaを計算（バリエーションがゼロの場合スキップ）\n",
    "kappa_scores = []\n",
    "for i in range(data_Nakae_100_200.shape[1]):\n",
    "    if np.var(data_Nakae_100_200[:, i]) == 0 and np.var(data_Akiyoshi_100_200[:, i]) == 0:\n",
    "        print(f\"Label {i + 1}: Skipped due to no variance.\")\n",
    "        kappa_scores.append(1.0)  # 完全一致とみなす場合\n",
    "        continue\n",
    "    kappa = cohen_kappa_score(data_Nakae_100_200[:, i], data_Akiyoshi_100_200[:, i])\n",
    "    kappa_scores.append(kappa if not np.isnan(kappa) else 0)\n",
    "\n",
    "# 平均Kappa\n",
    "average_kappa = np.nanmean(kappa_scores)  # NaNを無視して平均計算\n",
    "print(f\"Average Cohen's Kappa: {average_kappa:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact match rate: 48.25%\n"
     ]
    }
   ],
   "source": [
    "# 行が完全一致している数を計算\n",
    "exact_matches = np.sum(np.all(data_Nakae_100_200 == data_Akiyoshi_100_200, axis=1))\n",
    "# 行数\n",
    "num_rows = data_Nakae_100_200.shape[0]\n",
    "# 完全一致率\n",
    "exact_match_rate = exact_matches / num_rows\n",
    "print(f\"Exact match rate: {exact_match_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
