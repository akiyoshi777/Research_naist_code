{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 使用するGPUを指定. この環境変数の場所は，pytorchをimportする前に入れる\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from src.my_project.dataset import load_dataset_4class_Multi_classification, split_multilabel_data, load_text_dataset\n",
    "from src.my_project.train_v2 import MultiClassClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.my_project.dataset import load_multiclass_dataset\n",
    "import wandb\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = Path('/home/is/akiyoshi-n/my-project/data')\n",
    "# 本日の日付\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "# 出力先ディレクトリ\n",
    "output_dir = Path('/home/is/akiyoshi-n/my-project/outputs/{}'.format(timestamp))\n",
    "# モデル出力先ディレクトリ\n",
    "output_model_dir = Path('/home/is/akiyoshi-n/my-project/outputs_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大トークン数\n",
    "MAX_LEN = 128\n",
    "# バッチサイズ\n",
    "BATCH_SIZE = 16\n",
    "# エポック数\n",
    "NUM_EPOCHS = 100\n",
    "# 学習率\n",
    "LEARNING_RATE = 2e-5\n",
    "# Cross Validation時のFold数\n",
    "NUM_FOLDS = 3\n",
    "# 早期停止のための忍耐値\n",
    "PATIENCE = 5\n",
    "# 乱数シード\n",
    "SEED = 2023\n",
    "# クラス数\n",
    "NUM_LABELS = 4\n",
    "# 閾値\n",
    "THRESH = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "data, class_name = load_dataset_4class_Multi_classification(f\"{DATASET_PATH}/act_classification_final_ChatGPT4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([122, 145, 358, 611])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels_np = np.array(data['labels'])\n",
    "data_labels_np.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 東北大BERT-v3\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-v3'\n",
    "Classifier_model = MultiClassClassifier(model_name = MODEL_NAME, num_labels=NUM_LABELS, seed=SEED, thresh=THRESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testデータと訓練に使用するデータに分割\n",
    "dataset, eval_data = split_multilabel_data(data=data, test_size=0.2, SEED=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 98 116 286 489]\n",
      "[ 24  29  72 122]\n"
     ]
    }
   ],
   "source": [
    "# dataset['labels']とtest_data['labels']の各列の合計値を出力\n",
    "dataset_labels_np = np.array(dataset['labels'])\n",
    "eval_data_labels_np = np.array(eval_data['labels'])\n",
    "print(dataset_labels_np.sum(axis=0))\n",
    "print(eval_data_labels_np.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc2016867574f0c9d63c47a1ab3f1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/960 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab34fedcd344f60b0580a7651c9b1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf5022e548a4bc8a695b5a4032d69da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112536614139875, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='540' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 540/6000 01:47 < 18:11, 5.00 it/s, Epoch 9/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Class F1</th>\n",
       "      <th>Class Recall</th>\n",
       "      <th>Class Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.587000</td>\n",
       "      <td>0.531818</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.062]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.033]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.481600</td>\n",
       "      <td>0.500947</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.114895</td>\n",
       "      <td>[0.154, 0.0, 0.0, 0.306]</td>\n",
       "      <td>[0.083, 0.0, 0.0, 0.197]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.686]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.420500</td>\n",
       "      <td>0.462990</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.296574</td>\n",
       "      <td>[0.368, 0.375, 0.159, 0.284]</td>\n",
       "      <td>[0.292, 0.31, 0.097, 0.172]</td>\n",
       "      <td>[0.5, 0.474, 0.438, 0.808]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.337100</td>\n",
       "      <td>0.423856</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.459446</td>\n",
       "      <td>[0.417, 0.423, 0.4, 0.598]</td>\n",
       "      <td>[0.417, 0.379, 0.278, 0.5]</td>\n",
       "      <td>[0.417, 0.478, 0.714, 0.744]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.241900</td>\n",
       "      <td>0.432253</td>\n",
       "      <td>0.504167</td>\n",
       "      <td>0.531505</td>\n",
       "      <td>[0.486, 0.408, 0.597, 0.634]</td>\n",
       "      <td>[0.375, 0.345, 0.597, 0.533]</td>\n",
       "      <td>[0.692, 0.5, 0.597, 0.783]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.169300</td>\n",
       "      <td>0.491664</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.527081</td>\n",
       "      <td>[0.424, 0.356, 0.606, 0.723]</td>\n",
       "      <td>[0.292, 0.276, 0.597, 0.738]</td>\n",
       "      <td>[0.778, 0.5, 0.614, 0.709]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.526732</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.572546</td>\n",
       "      <td>[0.486, 0.426, 0.649, 0.729]</td>\n",
       "      <td>[0.375, 0.345, 0.694, 0.705]</td>\n",
       "      <td>[0.692, 0.556, 0.61, 0.754]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.564048</td>\n",
       "      <td>0.554167</td>\n",
       "      <td>0.568090</td>\n",
       "      <td>[0.465, 0.526, 0.637, 0.644]</td>\n",
       "      <td>[0.417, 0.517, 0.806, 0.533]</td>\n",
       "      <td>[0.526, 0.536, 0.527, 0.812]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.530740</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.622557</td>\n",
       "      <td>[0.565, 0.545, 0.653, 0.726]</td>\n",
       "      <td>[0.542, 0.517, 0.667, 0.697]</td>\n",
       "      <td>[0.591, 0.577, 0.64, 0.759]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Classifier_model.train_model(dataset, eval_data, MAX_LEN, NUM_EPOCHS, LEARNING_RATE, BATCH_SIZE, PATIENCE, output_dir, project_name='use_training', run_name='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unursoデータに適応"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{DATASET_PATH}/unurso_Dataset_type.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# sigmoid関数を適応できるようにTensorに変換\n",
    "logits = torch.from_numpy(predictions.predictions)\n",
    "# シグモイド関数を適用し，確率に変換\n",
    "predictions_proba = torch.sigmoid(logits)\n",
    "# 閾値を設定し予測ラベルに変換\n",
    "predictions_label = (predictions_proba>0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_label = predictions_label.numpy()\n",
    "predictions_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# 正規表現パターンと対応する置換表現を辞書で定義\n",
    "replacements = {\n",
    "    r\"@(\\S*)\": \"[USR]\", # ユーザ名を[USR]に置換\n",
    "    r\"http(\\S*)\": \"[URL]\", # URLを[URL]に置換\n",
    "}\n",
    "\n",
    "# 文中のマッチした箇所を対応する置換表現に置換する関数\n",
    "def apply_regex(text):\n",
    "    for pattern, replacement in replacements.items():\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "    return text\n",
    "\n",
    "# テキストファイルを読み込み、1つ目と3つ目のフィールドに前処理を適用し、それらを出力する関数\n",
    "def preprocess_file(input_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        processed_data = []\n",
    "        for line in file:\n",
    "            fields = line.strip().split('\\t')\n",
    "            # 2つ目のフィールド（前処理なし）と3つ目のフィールド（前処理あり）4つ目のフィールド（前処理なし）を取得\n",
    "            first_field = fields[1] # ユーザ名\n",
    "            third_field = apply_regex(fields[2]) # ツイート本文\n",
    "            forth_field = fields[3] # ツイート日時\n",
    "            processed_data.append([first_field, third_field, forth_field])\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数を使用してファイルを前処理し、結果をDataFrameに格納\n",
    "input_file = f'{DATASET_PATH}/unurso_users85.txt' # 入力ファイル名\n",
    "processed_data = preprocess_file(input_file)\n",
    "column_names = ['Name','text','time']\n",
    "# DataFrameを作成\n",
    "df = pd.DataFrame(processed_data, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42048\n",
      "150584\n"
     ]
    }
   ],
   "source": [
    "# 列の合計が0の個数\n",
    "print(predictions_label.sum(axis=1).tolist().count(0))\n",
    "print(len(predictions_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150579</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150580</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150581</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150582</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150583</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150584 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3\n",
       "0       0.0  0.0  1.0  0.0\n",
       "1       0.0  0.0  0.0  0.0\n",
       "2       0.0  0.0  0.0  0.0\n",
       "3       0.0  0.0  0.0  0.0\n",
       "4       0.0  0.0  0.0  1.0\n",
       "...     ...  ...  ...  ...\n",
       "150579  0.0  0.0  1.0  0.0\n",
       "150580  0.0  0.0  0.0  0.0\n",
       "150581  0.0  0.0  0.0  1.0\n",
       "150582  0.0  0.0  1.0  0.0\n",
       "150583  0.0  0.0  0.0  0.0\n",
       "\n",
       "[150584 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame(predictions_label)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_df = pd.concat([df, new_df], axis=1)\n",
    "action_df = action_df[['Name',0, 1, 2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0~20の列の合計が0の行を削除\n",
    "action_df = action_df.drop(action_df.index[predictions_label.sum(axis=1)==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3zhen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3zhen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3zhen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3zhen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3zhen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150576</th>\n",
       "      <td>zubora_sweet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150577</th>\n",
       "      <td>zubora_sweet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150579</th>\n",
       "      <td>zubora_sweet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150581</th>\n",
       "      <td>zubora_sweet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150582</th>\n",
       "      <td>zubora_sweet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108536 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name    0    1    2    3\n",
       "0              3zhen  0.0  0.0  1.0  0.0\n",
       "4              3zhen  0.0  0.0  0.0  1.0\n",
       "6              3zhen  0.0  0.0  0.0  1.0\n",
       "13             3zhen  0.0  0.0  0.0  1.0\n",
       "18             3zhen  0.0  0.0  1.0  0.0\n",
       "...              ...  ...  ...  ...  ...\n",
       "150576  zubora_sweet  0.0  0.0  1.0  0.0\n",
       "150577  zubora_sweet  0.0  0.0  0.0  1.0\n",
       "150579  zubora_sweet  0.0  0.0  1.0  0.0\n",
       "150581  zubora_sweet  0.0  0.0  0.0  1.0\n",
       "150582  zubora_sweet  0.0  0.0  1.0  0.0\n",
       "\n",
       "[108536 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.147462\n",
       "1    0.119273\n",
       "2    0.175406\n",
       "3    0.581685\n",
       "dtype: float32"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_df.groupby('Name').mean().mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.015059\n",
       "1    0.012558\n",
       "2    0.044599\n",
       "3    0.049790\n",
       "dtype: float32"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_df.groupby('Name').mean().var(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ursoデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{DATASET_PATH}/urso_Dataset_type.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='31926' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    3/31926 00:00 < 31:29, 16.90 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# sigmoid関数を適応できるようにTensorに変換\n",
    "logits = torch.from_numpy(predictions.predictions)\n",
    "# シグモイド関数を適用し，確率に変換\n",
    "predictions_proba = torch.sigmoid(logits)\n",
    "# 閾値を設定し予測ラベルに変換\n",
    "predictions_label = (predictions_proba>0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_label = predictions_label.numpy()\n",
    "predictions_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数を使用してファイルを前処理し、結果をDataFrameに格納\n",
    "input_file = f'{DATASET_PATH}/urso_users.txt' # 入力ファイル名\n",
    "processed_data = preprocess_file(input_file)\n",
    "column_names = ['Name','text','time']\n",
    "# DataFrameを作成\n",
    "df = pd.DataFrame(processed_data, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189310\n",
      "510809\n"
     ]
    }
   ],
   "source": [
    "# 列の合計が0の個数\n",
    "print(predictions_label.sum(axis=1).tolist().count(0))\n",
    "print(len(predictions_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510804</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510805</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510806</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510807</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510808</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510809 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3\n",
       "0       0.0  0.0  0.0  1.0\n",
       "1       1.0  0.0  0.0  0.0\n",
       "2       1.0  1.0  0.0  0.0\n",
       "3       0.0  0.0  0.0  0.0\n",
       "4       0.0  0.0  0.0  1.0\n",
       "...     ...  ...  ...  ...\n",
       "510804  0.0  0.0  1.0  0.0\n",
       "510805  0.0  0.0  0.0  1.0\n",
       "510806  0.0  0.0  0.0  1.0\n",
       "510807  0.0  0.0  0.0  1.0\n",
       "510808  0.0  0.0  0.0  1.0\n",
       "\n",
       "[510809 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame(predictions_label)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_df = pd.concat([df, new_df], axis=1)\n",
    "action_df = action_df[['Name',0, 1, 2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0~20の列の合計が0の行を削除\n",
    "action_df = action_df.drop(action_df.index[predictions_label.sum(axis=1)==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>468251793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>468251793</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>468251793</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>468251793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>468251793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510804</th>\n",
       "      <td>you1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510805</th>\n",
       "      <td>you1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510806</th>\n",
       "      <td>you1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510807</th>\n",
       "      <td>you1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510808</th>\n",
       "      <td>you1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321499 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name    0    1    2    3\n",
       "0       468251793  0.0  0.0  0.0  1.0\n",
       "1       468251793  1.0  0.0  0.0  0.0\n",
       "2       468251793  1.0  1.0  0.0  0.0\n",
       "4       468251793  0.0  0.0  0.0  1.0\n",
       "5       468251793  0.0  0.0  0.0  1.0\n",
       "...           ...  ...  ...  ...  ...\n",
       "510804       you1  0.0  0.0  1.0  0.0\n",
       "510805       you1  0.0  0.0  0.0  1.0\n",
       "510806       you1  0.0  0.0  0.0  1.0\n",
       "510807       you1  0.0  0.0  0.0  1.0\n",
       "510808       you1  0.0  0.0  0.0  1.0\n",
       "\n",
       "[321499 rows x 5 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.161198\n",
       "1    0.106414\n",
       "2    0.198668\n",
       "3    0.556087\n",
       "dtype: float32"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_df.groupby('Name').mean().mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.008814\n",
       "1    0.008805\n",
       "2    0.035082\n",
       "3    0.035768\n",
       "dtype: float32"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_df.groupby('Name').mean().var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443d8bf63d0d40b294f4eede55ac174d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = Classifier_model.predict(trainer, eval_dataset, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e595c812274fae9e93f1a87927da7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from src.my_project.dataset import preprocess_for_Trainer\n",
    "import numpy as np\n",
    "import torch\n",
    "# tokenizerの定義\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "eval_dataset_use = preprocess_for_Trainer(eval_dataset, tokenizer, max_len=MAX_LEN)\n",
    "predictions = trainer.predict(eval_dataset_use)\n",
    "\n",
    "# predictions.predictionsにsigmoid関数を適用し，確率に変換\n",
    "predictions = torch.sigmoid(torch.from_numpy(predictions.predictions))\n",
    "thresh = 0.5\n",
    "# predictions = torch.where(predictions > THRESH, 1, 0)\n",
    "predictions_label = (predictions>thresh).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0440, 0.0457, 0.3518, 0.3285])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if torch.sum(predictions[0]) == 0:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "max_index = torch.argmax(predictions[0])\n",
    "max_index\n",
    "a[0][max_index] = 1\n",
    "a[1][:-1] = predictions_label[0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((5,4))\n",
    "for i in range(5):\n",
    "    a[i] = predictions[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictions\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['texts', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cab480a6a4c4b32983ecc9847cf1988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from src.my_project.dataset import preprocess_for_Trainer\n",
    "import numpy as np\n",
    "import torch\n",
    "# tokenizerの定義\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# データセットの前処理\n",
    "eval_dataset_use = preprocess_for_Trainer(eval_dataset, tokenizer, max_len=MAX_LEN)\n",
    "predictions = trainer.predict(eval_dataset_use)\n",
    "# predictions.predictionsにsigmoid関数を適用し，確率に変換\n",
    "predictions = torch.sigmoid(torch.from_numpy(predictions.predictions))\n",
    "# 0.5以上の確率を1，それ以外を0に変換\n",
    "thresh = 0.5\n",
    "# predictions = torch.where(predictions > THRESH, 1, 0)\n",
    "predictions = (predictions>thresh).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したTrainerを読み込む\n",
    "model = AutoModelForSequenceClassification.from_pretrained('/home/is/akiyoshi-n/my-project/outputs/2024-02-04/cl-tohoku/bert-base-japanese-v32024-02-04T16-22-24/checkpoint-285')\n",
    "trainer_v2 = Trainer(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6850\n",
      "F1: 0.6169\n"
     ]
    }
   ],
   "source": [
    "# trainerの予測値とeval_dataset['labels']のAccuracyとF1を出す\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "accuracy = accuracy_score(eval_dataset['labels'], predictions)\n",
    "f1 = f1_score(eval_dataset['labels'], predictions, average='macro')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'F1: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4f3391984c46338c76508f5deaf38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = Classifier_model.predict(trainer, eval_dataset, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9026d3083eaf41099d1c492a3d720b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.33989983797073364,\n",
       " 'eval_accuracy': 0.545,\n",
       " 'eval_f1': 0.5774035592587015,\n",
       " 'eval_runtime': 0.8056,\n",
       " 'eval_samples_per_second': 248.263,\n",
       " 'eval_steps_per_second': 6.207,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評価データでの評価\n",
    "Classifier_model.evaluation(trainer, eval_dataset, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "data, class_name = load_dataset_4class_Multi_classification(f\"{DATASET_PATH}/act_classification_final_ChatGPT4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([122, 145, 358, 611])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels_np = np.array(data['labels'])\n",
    "data_labels_np.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testデータと訓練に使用するデータに分割\n",
    "dataset, test_data = split_multilabel_data(data=data, test_size=0.1, SEED=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110 130 322 550]\n",
      "[12 15 36 61]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(dataset['labels']).sum(axis=0))\n",
    "print(np.array(test_data['labels']).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 東北大BERT-v3\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-v3'\n",
    "NUM_LABELS=4\n",
    "Classifier_model = MultiClassClassifier(model_name=MODEL_NAME, num_labels=NUM_LABELS, seed=SEED, thresh=THRESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Fold: 1-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62d7021631c40eeb388d73cd4792f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/719 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924e79389abb4daba62f32cf6dcade96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5338f21e0e94324b1370ec24c949a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112121534016398, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [90/90 00:19, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Class F1</th>\n",
       "      <th>Class Recall</th>\n",
       "      <th>Class Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.514800</td>\n",
       "      <td>0.473223</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.078205</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.113]</td>\n",
       "      <td>[0.111, 0.0, 0.0, 0.06]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.917]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.459800</td>\n",
       "      <td>0.466306</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.241125</td>\n",
       "      <td>[0.408, 0.0, 0.0, 0.556]</td>\n",
       "      <td>[0.278, 0.0, 0.0, 0.432]</td>\n",
       "      <td>[0.769, 0.0, 0.0, 0.782]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97bcbc41747c43a582c2d2a7b60cbe72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/121 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7083333333333334, 'macro_f1': 0.3355263157894737, 'class_f1': [0.5, 0.0, 0.0, 0.842], 'class_recall': [0.333, 0.0, 0.0, 1.0], 'class_precision': [1.0, 0.0, 0.0, 0.727]}\n",
      "-----------------Fold: 2-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cc9c7d65d7431987fd233b53ab487a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/719 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c76e5a4ab834a8085bd021b64ee03bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62049b7b15774f0ea7731df8581732e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112426449027326, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/90 00:04 < 00:10, 6.05 it/s, Epoch 0.58/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m NUM_EPOCHS\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mClassifier_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_LEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_FOLDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mChatGPT_data_4class_weight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my-project/src/my_project/train_v2.py:367\u001b[0m, in \u001b[0;36mMultiClassClassifier.cross_validation\u001b[0;34m(self, data, test_data, MAX_LEN, NUM_EPOCHS, LEARNIG_RATE, BATCH_SIZE, PATIENCE, NUM_FOLDS, output_dir, project_name)\u001b[0m\n\u001b[1;32m    362\u001b[0m eval_dataset \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtexts\u001b[39m\u001b[38;5;124m'\u001b[39m: [data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtexts\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m eval_index],\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: [data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m eval_index]\n\u001b[1;32m    365\u001b[0m }\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# モデル学習\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_LEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLEARNIG_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfold_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# 評価\u001b[39;00m\n\u001b[1;32m    369\u001b[0m eval_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation(trainer, test_data, MAX_LEN)\n",
      "File \u001b[0;32m~/my-project/src/my_project/train_v2.py:279\u001b[0m, in \u001b[0;36mMultiClassClassifier.train_model\u001b[0;34m(self, train_dataset, eval_dataset, MAX_LEN, NUM_EPOCHS, LEARNIG_RATE, BATCH_SIZE, PATIENCE, output_dir, project_name, run_name)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# Trainerの定義\u001b[39;00m\n\u001b[1;32m    271\u001b[0m trainer \u001b[38;5;241m=\u001b[39m MultilabelTrainer(\n\u001b[1;32m    272\u001b[0m     model \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m    273\u001b[0m     args \u001b[38;5;241m=\u001b[39m training_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m [EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39mPATIENCE)]\n\u001b[1;32m    278\u001b[0m )\n\u001b[0;32m--> 279\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/transformers/trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/transformers/trainer.py:1854\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1854\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1857\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1859\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1860\u001b[0m ):\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/transformers/trainer.py:2744\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2742\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2743\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/accelerate/accelerator.py:1905\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1903\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1905\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = Classifier_model.cross_validation(dataset, test_data, MAX_LEN, NUM_EPOCHS, LEARNING_RATE, BATCH_SIZE, PATIENCE, NUM_FOLDS, output_dir, project_name='ChatGPT_data_4class_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.634\n",
      "Average Macro f1: 0.53\n",
      "Average Class f1: [0.431, 0.355, 0.583, 0.753]\n",
      "Average Class recall: [0.314, 0.294, 0.593, 0.812]\n",
      "Average Class precision: [0.833, 0.501, 0.573, 0.703]\n"
     ]
    }
   ],
   "source": [
    "# 重みなしの場合の結果（cv=5）\n",
    "average_accuracy = round(sum(d['eval_accuracy'] for d in result)/len(result), 3)\n",
    "average_macro_f1 = round(sum(d['eval_macro_f1'] for d in result)/len(result), 3)\n",
    "# クラスごとの平均値を計算\n",
    "average_class_f1 = [round(sum(d['eval_class_f1'][i] for d in result) / len(result), 3) for i in range(len(result[0]['eval_class_f1']))]\n",
    "average_class_recall = [round(sum(d['eval_class_recall'][i] for d in result) / len(result), 3) for i in range(len(result[0]['eval_class_recall']))]\n",
    "average_class_precision = [round(sum(d['eval_class_precision'][i] for d in result) / len(result), 3) for i in range(len(result[0]['eval_class_precision']))]\n",
    "print(\"Average accuracy:\", average_accuracy)\n",
    "print(\"Average Macro f1:\", average_macro_f1)\n",
    "print(\"Average Class f1:\", average_class_f1)\n",
    "print(\"Average Class recall:\", average_class_recall)\n",
    "print(\"Average Class precision:\", average_class_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.545\n",
      "Average Macro f1: 0.531\n",
      "Average Class f1: [0.562, 0.43, 0.461, 0.671]\n",
      "Average Class recall: [0.432, 0.585, 0.455, 0.661]\n",
      "Average Class precision: [0.806, 0.341, 0.472, 0.685]\n"
     ]
    }
   ],
   "source": [
    "# # 重みありの場合の結果（cv=5）\n",
    "# average_accuracy = round(sum(d['eval_accuracy'] for d in result)/len(result), 3)\n",
    "# average_macro_f1 = round(sum(d['eval_macro_f1'] for d in result)/len(result), 3)\n",
    "# # クラスごとの平均値を計算\n",
    "# average_class_f1 = [round(sum(d['eval_class_f1'][i] for d in result) / len(result), 3) for i in range(len(result[0]['eval_class_f1']))]\n",
    "# average_class_recall = [round(sum(d['eval_class_recall'][i] for d in result) / len(result), 3) for i in range(len(result[0]['eval_class_recall']))]\n",
    "# average_class_precision = [round(sum(d['eval_class_precision'][i] for d in result) / len(result), 3) for i in range(len(result[0]['eval_class_precision']))]\n",
    "# print(\"Average accuracy:\", average_accuracy)\n",
    "# print(\"Average Macro f1:\", average_macro_f1)\n",
    "# print(\"Average Class f1:\", average_class_f1)\n",
    "# print(\"Average Class recall:\", average_class_recall)\n",
    "# print(\"Average Class precision:\", average_class_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110 130 322 550]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(dataset['labels']).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストサイズ×マルチラベル数の二次元リスト\n",
    "majority_pred = [[0 for i in range(4)] for j in range(len(test_data['labels']))]\n",
    "for i in range(len(test_data['labels'])):\n",
    "    majority_pred[i][-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.504\n",
      "Average Macro f1: 0.168\n",
      "Average Class f1: [0.0, 0.0, 0.0, 0.67]\n",
      "Average Class recall: [0.0, 0.0, 0.0, 1.0]\n",
      "Average Class precision: [0.0, 0.0, 0.0, 0.504]\n"
     ]
    }
   ],
   "source": [
    "# accuracyを計算\n",
    "accuracy = round(accuracy_score(y_true=test_data['labels'], y_pred=majority_pred), 3)\n",
    "# macro f1を計算\n",
    "macro_f1 = round(f1_score(y_true=test_data['labels'], y_pred=majority_pred, average='macro', zero_division=0), 3)\n",
    "# クラス毎のF1値を計算\n",
    "class_f1 = [round(score, 3) for score in f1_score(y_true=test_data['labels'], y_pred=majority_pred, average=None, zero_division=0)]\n",
    "# クラス毎のrecallを計算\n",
    "class_recall = [round(score, 3) for score in recall_score(y_true=test_data['labels'], y_pred=majority_pred, average=None, zero_division=0)]\n",
    "# クラス毎のprecisionを計算\n",
    "class_precision = [round(score, 3) for score in precision_score(y_true=test_data['labels'], y_pred=majority_pred, average=None, zero_division=0)]\n",
    "print(\"Average accuracy:\", accuracy)\n",
    "print(\"Average Macro f1:\", macro_f1)\n",
    "print(\"Average Class f1:\", class_f1)\n",
    "print(\"Average Class recall:\", class_recall)\n",
    "print(\"Average Class precision:\", class_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21クラスマルチクラス分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "data, class_name = load_multiclass_dataset(f\"{DATASET_PATH}/act_classification_final_ChatGPT4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 29,  21,  28,  47,   8,  64,  28,  11,  19,   8,  11, 138,  28,\n",
       "        20,  83,  13,  54,  13,  11,   6, 611])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels_np = np.array(data['labels'])\n",
    "data_labels_np.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testデータと訓練に使用するデータに分割\n",
    "dataset, test_data = split_multilabel_data(data=data, test_size=0.1, SEED=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 26  19  25  42   7  58  25  10  17   7  10 124  25  18  75  12  49  12\n",
      "  10   5 550]\n",
      "[ 3  2  3  5  1  6  3  1  2  1  1 14  3  2  8  1  5  1  1  1 61]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(dataset['labels']).sum(axis=0))\n",
    "print(np.array(test_data['labels']).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 東北大BERT-v3\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-v3'\n",
    "# クラス数\n",
    "NUM_LABELS = 21\n",
    "Classifier_model_21 = MultiClassClassifier(model_name=MODEL_NAME, num_labels=21, seed=SEED, thresh=THRESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Fold: 1-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Parameter 'fn_kwargs'={'tokenizer': BertJapaneseTokenizer(name_or_path='cl-tohoku/bert-base-japanese-v3', vocab_size=32768, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}, 'max_len': 128} of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79ca7d071fd49abbb044d83effed6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/716 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef554c6a66384bbfa9b2c98d7616e079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/359 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1395' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1395/4500 09:24 < 20:58, 2.47 it/s, Epoch 31/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Class F1</th>\n",
       "      <th>Class Recall</th>\n",
       "      <th>Class Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.622700</td>\n",
       "      <td>0.462342</td>\n",
       "      <td>0.401114</td>\n",
       "      <td>0.049918</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.265, 0.0, 0.108, 0.0, 0.0, 0.0, 0.675]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36, 0.0, 0.118, 0.0, 0.0, 0.0, 0.978]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.209, 0.0, 0.1, 0.0, 0.0, 0.0, 0.516]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>0.209219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.120525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>0.092991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.082648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.091800</td>\n",
       "      <td>0.077472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.074597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.072734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>0.071648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.070647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>0.069504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.067953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.067439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.065080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.063755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.057900</td>\n",
       "      <td>0.062421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>0.060605</td>\n",
       "      <td>0.011142</td>\n",
       "      <td>0.015023</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048, 0.0, 0.0, 0.143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024, 0.0, 0.0, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.060801</td>\n",
       "      <td>0.036212</td>\n",
       "      <td>0.064721</td>\n",
       "      <td>[0.0, 0.0, 0.4, 0.316, 0.0, 0.385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044, 0.0, 0.0, 0.214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.25, 0.214, 0.0, 0.263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024, 0.0, 0.0, 0.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.6, 0.0, 0.714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.060822</td>\n",
       "      <td>0.050139</td>\n",
       "      <td>0.107715</td>\n",
       "      <td>[0.5, 0.286, 0.545, 0.316, 0.0, 0.387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.085, 0.0, 0.0, 0.143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.375, 0.167, 0.375, 0.214, 0.0, 0.316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049, 0.0, 0.0, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.75, 1.0, 1.0, 0.6, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.333, 0.0, 0.0, 0.667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.060135</td>\n",
       "      <td>0.038997</td>\n",
       "      <td>0.069683</td>\n",
       "      <td>[0.0, 0.286, 0.4, 0.25, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.085, 0.0, 0.0, 0.077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032]</td>\n",
       "      <td>[0.0, 0.167, 0.25, 0.143, 0.0, 0.211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016]</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.058897</td>\n",
       "      <td>0.147632</td>\n",
       "      <td>0.134989</td>\n",
       "      <td>[0.4, 0.6, 0.222, 0.316, 0.0, 0.438, 0.222, 0.0, 0.0, 0.0, 0.0, 0.12, 0.0, 0.0, 0.214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.303]</td>\n",
       "      <td>[0.25, 0.5, 0.125, 0.214, 0.0, 0.368, 0.125, 0.0, 0.0, 0.0, 0.0, 0.073, 0.0, 0.0, 0.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18]</td>\n",
       "      <td>[1.0, 0.75, 1.0, 0.6, 0.0, 0.538, 1.0, 0.0, 0.0, 0.0, 0.0, 0.333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.943]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.059334</td>\n",
       "      <td>0.320334</td>\n",
       "      <td>0.194307</td>\n",
       "      <td>[0.615, 0.6, 0.667, 0.222, 0.0, 0.429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.115, 0.364, 0.0, 0.207, 0.0, 0.25, 0.0, 0.0, 0.0, 0.612]</td>\n",
       "      <td>[0.5, 0.5, 0.5, 0.143, 0.0, 0.316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073, 0.222, 0.0, 0.12, 0.0, 0.176, 0.0, 0.0, 0.0, 0.486]</td>\n",
       "      <td>[0.8, 0.75, 1.0, 0.5, 0.0, 0.667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.273, 1.0, 0.0, 0.75, 0.0, 0.429, 0.0, 0.0, 0.0, 0.824]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.063723</td>\n",
       "      <td>0.387187</td>\n",
       "      <td>0.183007</td>\n",
       "      <td>[0.222, 0.5, 0.667, 0.25, 0.0, 0.516, 0.222, 0.0, 0.0, 0.0, 0.5, 0.077, 0.0, 0.0, 0.207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.682]</td>\n",
       "      <td>[0.125, 0.333, 0.5, 0.143, 0.0, 0.421, 0.125, 0.0, 0.0, 0.0, 0.333, 0.049, 0.0, 0.0, 0.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.645]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.667, 1.0, 0.0, 0.0, 0.0, 1.0, 0.182, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.724]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.060695</td>\n",
       "      <td>0.334262</td>\n",
       "      <td>0.237220</td>\n",
       "      <td>[0.364, 0.6, 0.545, 0.381, 0.0, 0.412, 0.222, 0.0, 0.0, 0.5, 0.5, 0.148, 0.0, 0.0, 0.2, 0.0, 0.514, 0.0, 0.0, 0.0, 0.595]</td>\n",
       "      <td>[0.25, 0.5, 0.375, 0.286, 0.0, 0.368, 0.125, 0.0, 0.0, 0.333, 0.333, 0.098, 0.0, 0.0, 0.12, 0.0, 0.529, 0.0, 0.0, 0.0, 0.47]</td>\n",
       "      <td>[0.667, 0.75, 1.0, 0.571, 0.0, 0.467, 1.0, 0.0, 0.0, 1.0, 1.0, 0.308, 0.0, 0.0, 0.6, 0.0, 0.5, 0.0, 0.0, 0.0, 0.811]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.060246</td>\n",
       "      <td>0.389972</td>\n",
       "      <td>0.170951</td>\n",
       "      <td>[0.545, 0.0, 0.667, 0.316, 0.0, 0.533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.207, 0.0, 0.0, 0.194, 0.0, 0.435, 0.0, 0.0, 0.0, 0.693]</td>\n",
       "      <td>[0.375, 0.0, 0.5, 0.214, 0.0, 0.421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.146, 0.0, 0.0, 0.12, 0.0, 0.294, 0.0, 0.0, 0.0, 0.612]</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.6, 0.0, 0.727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.353, 0.0, 0.0, 0.5, 0.0, 0.833, 0.0, 0.0, 0.0, 0.8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>0.061619</td>\n",
       "      <td>0.409471</td>\n",
       "      <td>0.258910</td>\n",
       "      <td>[0.615, 0.6, 0.545, 0.222, 0.0, 0.514, 0.0, 0.0, 0.0, 0.0, 0.5, 0.306, 0.0, 0.286, 0.207, 0.0, 0.3, 0.667, 0.0, 0.0, 0.675]</td>\n",
       "      <td>[0.5, 0.5, 0.375, 0.143, 0.0, 0.474, 0.0, 0.0, 0.0, 0.0, 0.333, 0.268, 0.0, 0.167, 0.12, 0.0, 0.176, 0.5, 0.0, 0.0, 0.596]</td>\n",
       "      <td>[0.8, 0.75, 1.0, 0.5, 0.0, 0.562, 0.0, 0.0, 0.0, 0.0, 1.0, 0.355, 0.0, 1.0, 0.75, 0.0, 1.0, 1.0, 0.0, 0.0, 0.779]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.417827</td>\n",
       "      <td>0.277503</td>\n",
       "      <td>[0.545, 0.667, 0.667, 0.4, 0.0, 0.444, 0.0, 0.0, 0.0, 0.5, 0.5, 0.2, 0.2, 0.286, 0.207, 0.0, 0.111, 0.4, 0.0, 0.0, 0.701]</td>\n",
       "      <td>[0.375, 0.5, 0.5, 0.286, 0.0, 0.421, 0.0, 0.0, 0.0, 0.333, 0.333, 0.146, 0.111, 0.167, 0.12, 0.0, 0.059, 0.25, 0.0, 0.0, 0.639]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.667, 0.0, 0.471, 0.0, 0.0, 0.0, 1.0, 1.0, 0.316, 1.0, 1.0, 0.75, 0.0, 1.0, 1.0, 0.0, 0.0, 0.775]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.062536</td>\n",
       "      <td>0.417827</td>\n",
       "      <td>0.259884</td>\n",
       "      <td>[0.571, 0.667, 0.667, 0.222, 0.0, 0.513, 0.0, 0.0, 0.0, 0.0, 0.5, 0.222, 0.2, 0.286, 0.235, 0.0, 0.286, 0.4, 0.0, 0.0, 0.689]</td>\n",
       "      <td>[0.5, 0.5, 0.5, 0.143, 0.0, 0.526, 0.0, 0.0, 0.0, 0.0, 0.333, 0.171, 0.111, 0.167, 0.16, 0.0, 0.176, 0.25, 0.0, 0.0, 0.623]</td>\n",
       "      <td>[0.667, 1.0, 1.0, 0.5, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.318, 1.0, 1.0, 0.444, 0.0, 0.75, 1.0, 0.0, 0.0, 0.77]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.063003</td>\n",
       "      <td>0.437326</td>\n",
       "      <td>0.324469</td>\n",
       "      <td>[0.571, 0.667, 0.615, 0.476, 0.0, 0.5, 0.222, 0.0, 0.0, 0.5, 0.5, 0.265, 0.364, 0.286, 0.207, 0.0, 0.286, 0.667, 0.0, 0.0, 0.689]</td>\n",
       "      <td>[0.5, 0.5, 0.5, 0.357, 0.0, 0.474, 0.125, 0.0, 0.0, 0.333, 0.333, 0.22, 0.222, 0.167, 0.12, 0.0, 0.176, 0.5, 0.0, 0.0, 0.628]</td>\n",
       "      <td>[0.667, 1.0, 0.8, 0.714, 0.0, 0.529, 1.0, 0.0, 0.0, 1.0, 1.0, 0.333, 1.0, 1.0, 0.75, 0.0, 0.75, 1.0, 0.0, 0.0, 0.762]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.064323</td>\n",
       "      <td>0.451253</td>\n",
       "      <td>0.346510</td>\n",
       "      <td>[0.571, 0.667, 0.615, 0.522, 0.0, 0.5, 0.222, 0.5, 0.0, 0.5, 0.5, 0.27, 0.2, 0.286, 0.222, 0.0, 0.348, 0.667, 0.0, 0.0, 0.687]</td>\n",
       "      <td>[0.5, 0.5, 0.5, 0.429, 0.0, 0.474, 0.125, 0.333, 0.0, 0.333, 0.333, 0.244, 0.111, 0.167, 0.16, 0.0, 0.235, 0.5, 0.0, 0.0, 0.628]</td>\n",
       "      <td>[0.667, 1.0, 0.8, 0.667, 0.0, 0.529, 1.0, 1.0, 0.0, 1.0, 1.0, 0.303, 1.0, 1.0, 0.364, 0.0, 0.667, 1.0, 0.0, 0.0, 0.757]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.065815</td>\n",
       "      <td>0.462396</td>\n",
       "      <td>0.359513</td>\n",
       "      <td>[0.571, 0.667, 0.615, 0.522, 0.0, 0.529, 0.222, 0.5, 0.0, 0.5, 0.5, 0.31, 0.364, 0.286, 0.263, 0.0, 0.348, 0.667, 0.0, 0.0, 0.686]</td>\n",
       "      <td>[0.5, 0.5, 0.5, 0.429, 0.0, 0.474, 0.125, 0.333, 0.0, 0.333, 0.333, 0.317, 0.222, 0.167, 0.2, 0.0, 0.235, 0.5, 0.0, 0.0, 0.634]</td>\n",
       "      <td>[0.667, 1.0, 0.8, 0.667, 0.0, 0.6, 1.0, 1.0, 0.0, 1.0, 1.0, 0.302, 1.0, 1.0, 0.385, 0.0, 0.667, 1.0, 0.0, 0.0, 0.748]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e31640690854ad7b99d0ee452d1a270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.75, 'macro_f1': 0.18483245149911817, 'class_f1': [0.0, 0.0, 0.0, 1.0, 0.0, 0.667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.815], 'class_recall': [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.917], 'class_precision': [0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.733]}\n",
      "-----------------Fold: 2-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64765b52dd541fcb1af6ebe95380a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/717 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebae6bcd4bcf4bc78850bd2a6102e218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a46d6a3abe2485eb09029218b9ed44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112350184056494, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1440' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1440/4500 08:11 < 17:26, 2.93 it/s, Epoch 32/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Class F1</th>\n",
       "      <th>Class Recall</th>\n",
       "      <th>Class Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.659700</td>\n",
       "      <td>0.505458</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.023366</td>\n",
       "      <td>[0.01, 0.085, 0.0, 0.029, 0.049, 0.061, 0.017, 0.0, 0.0, 0.0, 0.0, 0.138, 0.0, 0.0, 0.0, 0.0, 0.07, 0.0, 0.0, 0.0, 0.032]</td>\n",
       "      <td>[0.111, 0.333, 0.0, 0.071, 0.5, 0.053, 0.111, 0.0, 0.0, 0.0, 0.0, 0.146, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.016]</td>\n",
       "      <td>[0.005, 0.049, 0.0, 0.019, 0.026, 0.071, 0.009, 0.0, 0.0, 0.0, 0.0, 0.13, 0.0, 0.0, 0.0, 0.0, 0.049, 0.0, 0.0, 0.0, 0.75]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.332300</td>\n",
       "      <td>0.190807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>0.118237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.115800</td>\n",
       "      <td>0.093527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.083187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.091600</td>\n",
       "      <td>0.077879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.074821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>0.072791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.071454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.070913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.070019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>0.069260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.067191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.066028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.064388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.063011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.061566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>0.061376</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.007055</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.063101</td>\n",
       "      <td>0.131285</td>\n",
       "      <td>0.070905</td>\n",
       "      <td>[0.4, 0.0, 0.2, 0.222, 0.0, 0.0, 0.182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.342]</td>\n",
       "      <td>[0.333, 0.0, 0.125, 0.143, 0.0, 0.0, 0.111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.212]</td>\n",
       "      <td>[0.5, 0.0, 0.5, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.886]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.057848</td>\n",
       "      <td>0.053073</td>\n",
       "      <td>0.055220</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.133, 0.0, 0.273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.074, 0.0, 0.0, 0.4, 0.0, 0.0, 0.113]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.071, 0.0, 0.158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.098, 0.0, 0.0, 0.04, 0.0, 0.0, 0.25, 0.0, 0.0, 0.06]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.571, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.058433</td>\n",
       "      <td>0.256983</td>\n",
       "      <td>0.087103</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.235, 0.0, 0.25, 0.2, 0.0, 0.0, 0.0, 0.0, 0.163, 0.0, 0.0, 0.133, 0.0, 0.273, 0.0, 0.0, 0.0, 0.575]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.143, 0.0, 0.158, 0.111, 0.0, 0.0, 0.0, 0.0, 0.098, 0.0, 0.0, 0.08, 0.0, 0.188, 0.0, 0.0, 0.0, 0.429]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.667, 0.0, 0.6, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.4, 0.0, 0.5, 0.0, 0.0, 0.0, 0.868]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.057718</td>\n",
       "      <td>0.304469</td>\n",
       "      <td>0.109354</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.25, 0.0, 0.19, 0.2, 0.0, 0.0, 0.0, 0.0, 0.275, 0.0, 0.0, 0.071, 0.0, 0.273, 0.4, 0.0, 0.0, 0.637]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.143, 0.0, 0.105, 0.111, 0.0, 0.0, 0.0, 0.0, 0.171, 0.0, 0.0, 0.04, 0.0, 0.188, 0.25, 0.0, 0.0, 0.511]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.0, 0.0, 0.333, 0.0, 0.5, 1.0, 0.0, 0.0, 0.847]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.059101</td>\n",
       "      <td>0.329609</td>\n",
       "      <td>0.099331</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.25, 0.0, 0.182, 0.2, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.133, 0.0, 0.333, 0.0, 0.0, 0.0, 0.662]</td>\n",
       "      <td>[0.111, 0.0, 0.0, 0.143, 0.0, 0.105, 0.111, 0.0, 0.0, 0.0, 0.0, 0.073, 0.0, 0.0, 0.08, 0.0, 0.25, 0.0, 0.0, 0.0, 0.571]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 0.0, 0.667, 1.0, 0.0, 0.0, 0.0, 0.0, 0.429, 0.0, 0.0, 0.4, 0.0, 0.5, 0.0, 0.0, 0.0, 0.789]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.029100</td>\n",
       "      <td>0.060281</td>\n",
       "      <td>0.368715</td>\n",
       "      <td>0.153668</td>\n",
       "      <td>[0.4, 0.0, 0.364, 0.333, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.353, 0.0, 0.0, 0.235, 0.0, 0.0, 0.667, 0.0, 0.0, 0.675]</td>\n",
       "      <td>[0.333, 0.0, 0.25, 0.214, 0.0, 0.0, 0.111, 0.0, 0.0, 0.0, 0.0, 0.293, 0.0, 0.0, 0.16, 0.0, 0.0, 0.5, 0.0, 0.0, 0.576]</td>\n",
       "      <td>[0.5, 0.0, 0.667, 0.75, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.444, 0.0, 0.0, 0.444, 0.0, 0.0, 1.0, 0.0, 0.0, 0.815]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.059088</td>\n",
       "      <td>0.321229</td>\n",
       "      <td>0.176063</td>\n",
       "      <td>[0.444, 0.0, 0.364, 0.333, 0.0, 0.333, 0.2, 0.0, 0.0, 0.0, 0.0, 0.405, 0.0, 0.0, 0.188, 0.0, 0.174, 0.667, 0.0, 0.0, 0.589]</td>\n",
       "      <td>[0.444, 0.0, 0.25, 0.214, 0.0, 0.211, 0.111, 0.0, 0.0, 0.0, 0.0, 0.366, 0.0, 0.0, 0.12, 0.0, 0.125, 0.5, 0.0, 0.0, 0.44]</td>\n",
       "      <td>[0.444, 0.0, 0.667, 0.75, 0.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 0.455, 0.0, 0.0, 0.429, 0.0, 0.286, 1.0, 0.0, 0.0, 0.89]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.063395</td>\n",
       "      <td>0.430168</td>\n",
       "      <td>0.114570</td>\n",
       "      <td>[0.375, 0.0, 0.364, 0.25, 0.0, 0.182, 0.2, 0.0, 0.0, 0.0, 0.0, 0.048, 0.0, 0.0, 0.133, 0.0, 0.111, 0.0, 0.0, 0.0, 0.743]</td>\n",
       "      <td>[0.333, 0.0, 0.25, 0.143, 0.0, 0.105, 0.111, 0.0, 0.0, 0.0, 0.0, 0.024, 0.0, 0.0, 0.08, 0.0, 0.062, 0.0, 0.0, 0.0, 0.772]</td>\n",
       "      <td>[0.429, 0.0, 0.667, 1.0, 0.0, 0.667, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.5, 0.0, 0.0, 0.0, 0.717]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.059073</td>\n",
       "      <td>0.368715</td>\n",
       "      <td>0.198982</td>\n",
       "      <td>[0.5, 0.0, 0.5, 0.4, 0.0, 0.333, 0.182, 0.0, 0.0, 0.0, 0.0, 0.237, 0.0, 0.25, 0.125, 0.0, 0.32, 0.667, 0.0, 0.0, 0.665]</td>\n",
       "      <td>[0.444, 0.0, 0.375, 0.286, 0.0, 0.211, 0.111, 0.0, 0.0, 0.0, 0.0, 0.171, 0.0, 0.167, 0.08, 0.0, 0.25, 0.5, 0.0, 0.0, 0.56]</td>\n",
       "      <td>[0.571, 0.0, 0.75, 0.667, 0.0, 0.8, 0.5, 0.0, 0.0, 0.0, 0.0, 0.389, 0.0, 0.5, 0.286, 0.0, 0.444, 1.0, 0.0, 0.0, 0.817]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.396648</td>\n",
       "      <td>0.214933</td>\n",
       "      <td>[0.5, 0.286, 0.5, 0.4, 0.0, 0.429, 0.2, 0.0, 0.0, 0.0, 0.0, 0.218, 0.0, 0.25, 0.121, 0.0, 0.25, 0.667, 0.0, 0.0, 0.693]</td>\n",
       "      <td>[0.444, 0.167, 0.375, 0.286, 0.0, 0.316, 0.111, 0.0, 0.0, 0.0, 0.0, 0.146, 0.0, 0.167, 0.08, 0.0, 0.188, 0.5, 0.0, 0.0, 0.614]</td>\n",
       "      <td>[0.571, 1.0, 0.75, 0.667, 0.0, 0.667, 1.0, 0.0, 0.0, 0.0, 0.0, 0.429, 0.0, 0.5, 0.25, 0.0, 0.375, 1.0, 0.0, 0.0, 0.796]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.061209</td>\n",
       "      <td>0.427374</td>\n",
       "      <td>0.215263</td>\n",
       "      <td>[0.4, 0.5, 0.5, 0.4, 0.0, 0.261, 0.2, 0.0, 0.0, 0.0, 0.0, 0.204, 0.0, 0.25, 0.129, 0.0, 0.273, 0.667, 0.0, 0.0, 0.737]</td>\n",
       "      <td>[0.333, 0.333, 0.375, 0.286, 0.0, 0.158, 0.111, 0.0, 0.0, 0.0, 0.0, 0.122, 0.0, 0.167, 0.08, 0.0, 0.188, 0.5, 0.0, 0.0, 0.701]</td>\n",
       "      <td>[0.5, 1.0, 0.75, 0.667, 0.0, 0.75, 1.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.5, 0.333, 0.0, 0.5, 1.0, 0.0, 0.0, 0.777]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.060652</td>\n",
       "      <td>0.418994</td>\n",
       "      <td>0.230899</td>\n",
       "      <td>[0.444, 0.5, 0.5, 0.4, 0.0, 0.444, 0.2, 0.0, 0.0, 0.0, 0.0, 0.214, 0.0, 0.25, 0.129, 0.0, 0.4, 0.667, 0.0, 0.0, 0.7]</td>\n",
       "      <td>[0.444, 0.333, 0.375, 0.286, 0.0, 0.316, 0.111, 0.0, 0.0, 0.0, 0.0, 0.146, 0.0, 0.167, 0.08, 0.0, 0.312, 0.5, 0.0, 0.0, 0.647]</td>\n",
       "      <td>[0.444, 1.0, 0.75, 0.667, 0.0, 0.75, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.5, 0.333, 0.0, 0.556, 1.0, 0.0, 0.0, 0.763]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.060602</td>\n",
       "      <td>0.416201</td>\n",
       "      <td>0.200197</td>\n",
       "      <td>[0.5, 0.0, 0.462, 0.4, 0.0, 0.333, 0.2, 0.0, 0.0, 0.0, 0.0, 0.29, 0.0, 0.25, 0.121, 0.0, 0.273, 0.667, 0.0, 0.0, 0.708]</td>\n",
       "      <td>[0.444, 0.0, 0.375, 0.286, 0.0, 0.211, 0.111, 0.0, 0.0, 0.0, 0.0, 0.22, 0.0, 0.167, 0.08, 0.0, 0.188, 0.5, 0.0, 0.0, 0.647]</td>\n",
       "      <td>[0.571, 0.0, 0.6, 0.667, 0.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 0.429, 0.0, 0.5, 0.25, 0.0, 0.5, 1.0, 0.0, 0.0, 0.783]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.060765</td>\n",
       "      <td>0.402235</td>\n",
       "      <td>0.219594</td>\n",
       "      <td>[0.471, 0.5, 0.364, 0.4, 0.0, 0.4, 0.182, 0.0, 0.0, 0.0, 0.0, 0.323, 0.0, 0.25, 0.176, 0.0, 0.19, 0.667, 0.0, 0.0, 0.689]</td>\n",
       "      <td>[0.444, 0.333, 0.25, 0.286, 0.0, 0.263, 0.111, 0.0, 0.0, 0.0, 0.0, 0.244, 0.0, 0.167, 0.12, 0.0, 0.125, 0.5, 0.0, 0.0, 0.609]</td>\n",
       "      <td>[0.5, 1.0, 0.667, 0.667, 0.0, 0.833, 0.5, 0.0, 0.0, 0.0, 0.0, 0.476, 0.0, 0.5, 0.333, 0.0, 0.4, 1.0, 0.0, 0.0, 0.794]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c284cf4e3b482389a97a6b2d680bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.75, 'macro_f1': 0.19177489177489176, 'class_f1': [0.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.182, 0.0, 0.0, 0.5, 0.0, 0.667, 0.0, 0.0, 0.0, 0.879], 'class_recall': [0.0, 0.0, 0.0, 1.0, 0.0, 0.667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.111, 0.0, 0.0, 0.667, 0.0, 1.0, 0.0, 0.0, 0.0, 0.967], 'class_precision': [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.4, 0.0, 0.5, 0.0, 0.0, 0.0, 0.806]}\n",
      "-----------------Fold: 3-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff42f02bb585458ca5db874c3db9177f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/717 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f04e2896e7c4499bf930dfb94a82162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1278f2f344984fc1b088d477bd544799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111231493867106, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1530' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/4500 08:30 < 16:32, 2.99 it/s, Epoch 34/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Class F1</th>\n",
       "      <th>Class Recall</th>\n",
       "      <th>Class Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.592800</td>\n",
       "      <td>0.471905</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.035027</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.126, 0.03, 0.0, 0.0, 0.0, 0.105, 0.0, 0.0, 0.218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.256]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.429, 0.333, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.175]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.074, 0.016, 0.0, 0.0, 0.0, 0.077, 0.0, 0.0, 0.152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.478]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.330600</td>\n",
       "      <td>0.205577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.168900</td>\n",
       "      <td>0.125926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.117800</td>\n",
       "      <td>0.098020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.097200</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.081738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.086100</td>\n",
       "      <td>0.078864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>0.076986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.075807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.074639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.073158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.071690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.070789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.068945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.067638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.068096</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>0.064823</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.133, 0.0, 0.095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.071, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>0.064479</td>\n",
       "      <td>0.013966</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.5, 0.0, 0.182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.357, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.833, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.063253</td>\n",
       "      <td>0.069832</td>\n",
       "      <td>0.054576</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.133, 0.0, 0.444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.168]</td>\n",
       "      <td>[0.111, 0.0, 0.0, 0.071, 0.0, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.093]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 0.0, 0.857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.895]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.063211</td>\n",
       "      <td>0.192737</td>\n",
       "      <td>0.047057</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.128, 0.0, 0.0, 0.077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.488]</td>\n",
       "      <td>[0.111, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.071, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.344]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.061969</td>\n",
       "      <td>0.251397</td>\n",
       "      <td>0.100227</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.444, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.118, 0.0, 0.0, 0.077, 0.0, 0.381, 0.0, 0.0, 0.0, 0.551]</td>\n",
       "      <td>[0.111, 0.0, 0.0, 0.286, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.071, 0.0, 0.0, 0.04, 0.0, 0.25, 0.0, 0.0, 0.0, 0.41]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.333, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.843]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>0.335196</td>\n",
       "      <td>0.132081</td>\n",
       "      <td>[0.182, 0.25, 0.364, 0.235, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.122, 0.0, 0.0, 0.267, 0.0, 0.3, 0.0, 0.0, 0.0, 0.654]</td>\n",
       "      <td>[0.111, 0.143, 0.222, 0.143, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.071, 0.0, 0.0, 0.16, 0.0, 0.188, 0.0, 0.0, 0.0, 0.557]</td>\n",
       "      <td>[0.5, 1.0, 1.0, 0.667, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.429, 0.0, 0.0, 0.8, 0.0, 0.75, 0.0, 0.0, 0.0, 0.791]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.061885</td>\n",
       "      <td>0.349162</td>\n",
       "      <td>0.196087</td>\n",
       "      <td>[0.182, 0.25, 0.615, 0.235, 0.0, 0.4, 0.222, 0.0, 0.0, 0.0, 0.0, 0.16, 0.222, 0.286, 0.412, 0.0, 0.524, 0.0, 0.0, 0.0, 0.61]</td>\n",
       "      <td>[0.111, 0.143, 0.444, 0.143, 0.0, 0.25, 0.125, 0.0, 0.0, 0.0, 0.0, 0.095, 0.125, 0.167, 0.28, 0.0, 0.688, 0.0, 0.0, 0.0, 0.486]</td>\n",
       "      <td>[0.5, 1.0, 1.0, 0.667, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.778, 0.0, 0.423, 0.0, 0.0, 0.0, 0.817]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.061057</td>\n",
       "      <td>0.354749</td>\n",
       "      <td>0.201634</td>\n",
       "      <td>[0.308, 0.25, 0.5, 0.4, 0.0, 0.4, 0.222, 0.0, 0.0, 0.667, 0.0, 0.262, 0.0, 0.0, 0.375, 0.0, 0.222, 0.0, 0.0, 0.0, 0.628]</td>\n",
       "      <td>[0.222, 0.143, 0.333, 0.286, 0.0, 0.25, 0.125, 0.0, 0.0, 0.5, 0.0, 0.19, 0.0, 0.0, 0.24, 0.0, 0.125, 0.0, 0.0, 0.0, 0.536]</td>\n",
       "      <td>[0.5, 1.0, 1.0, 0.667, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.421, 0.0, 0.0, 0.857, 0.0, 1.0, 0.0, 0.0, 0.0, 0.76]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.357542</td>\n",
       "      <td>0.182267</td>\n",
       "      <td>[0.2, 0.25, 0.364, 0.476, 0.0, 0.385, 0.222, 0.0, 0.0, 0.0, 0.0, 0.265, 0.0, 0.286, 0.457, 0.0, 0.3, 0.0, 0.0, 0.0, 0.623]</td>\n",
       "      <td>[0.111, 0.143, 0.222, 0.357, 0.0, 0.25, 0.125, 0.0, 0.0, 0.0, 0.0, 0.214, 0.0, 0.167, 0.32, 0.0, 0.188, 0.0, 0.0, 0.0, 0.525]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.714, 0.0, 0.833, 1.0, 0.0, 0.0, 0.0, 0.0, 0.346, 0.0, 1.0, 0.8, 0.0, 0.75, 0.0, 0.0, 0.0, 0.768]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.062976</td>\n",
       "      <td>0.427374</td>\n",
       "      <td>0.258072</td>\n",
       "      <td>[0.429, 0.25, 0.615, 0.4, 0.0, 0.37, 0.4, 0.0, 0.0, 0.667, 0.0, 0.143, 0.0, 0.286, 0.444, 0.0, 0.316, 0.4, 0.0, 0.0, 0.7]</td>\n",
       "      <td>[0.333, 0.143, 0.444, 0.286, 0.0, 0.25, 0.25, 0.0, 0.0, 0.5, 0.0, 0.095, 0.0, 0.167, 0.32, 0.0, 0.188, 0.25, 0.0, 0.0, 0.656]</td>\n",
       "      <td>[0.6, 1.0, 1.0, 0.667, 0.0, 0.714, 1.0, 0.0, 0.0, 1.0, 0.0, 0.286, 0.0, 1.0, 0.727, 0.0, 1.0, 1.0, 0.0, 0.0, 0.75]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.061888</td>\n",
       "      <td>0.424581</td>\n",
       "      <td>0.256104</td>\n",
       "      <td>[0.308, 0.25, 0.714, 0.5, 0.0, 0.5, 0.222, 0.0, 0.0, 0.667, 0.0, 0.258, 0.222, 0.286, 0.471, 0.0, 0.3, 0.0, 0.0, 0.0, 0.681]</td>\n",
       "      <td>[0.222, 0.143, 0.556, 0.357, 0.0, 0.35, 0.125, 0.0, 0.0, 0.5, 0.0, 0.19, 0.125, 0.167, 0.32, 0.0, 0.188, 0.0, 0.0, 0.0, 0.617]</td>\n",
       "      <td>[0.5, 1.0, 1.0, 0.833, 0.0, 0.875, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.889, 0.0, 0.75, 0.0, 0.0, 0.0, 0.758]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.062928</td>\n",
       "      <td>0.413408</td>\n",
       "      <td>0.234869</td>\n",
       "      <td>[0.308, 0.25, 0.615, 0.476, 0.0, 0.333, 0.222, 0.0, 0.0, 0.667, 0.0, 0.222, 0.0, 0.286, 0.364, 0.0, 0.519, 0.0, 0.0, 0.0, 0.671]</td>\n",
       "      <td>[0.222, 0.143, 0.444, 0.357, 0.0, 0.2, 0.125, 0.0, 0.0, 0.5, 0.0, 0.167, 0.0, 0.167, 0.24, 0.0, 0.438, 0.0, 0.0, 0.0, 0.612]</td>\n",
       "      <td>[0.5, 1.0, 1.0, 0.714, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.333, 0.0, 1.0, 0.75, 0.0, 0.636, 0.0, 0.0, 0.0, 0.742]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.066504</td>\n",
       "      <td>0.449721</td>\n",
       "      <td>0.252274</td>\n",
       "      <td>[0.308, 0.25, 0.5, 0.476, 0.0, 0.385, 0.222, 0.0, 0.0, 0.667, 0.0, 0.241, 0.0, 0.286, 0.364, 0.0, 0.222, 0.667, 0.0, 0.0, 0.711]</td>\n",
       "      <td>[0.222, 0.143, 0.333, 0.357, 0.0, 0.25, 0.125, 0.0, 0.0, 0.5, 0.0, 0.167, 0.0, 0.167, 0.24, 0.0, 0.125, 0.5, 0.0, 0.0, 0.705]</td>\n",
       "      <td>[0.5, 1.0, 1.0, 0.714, 0.0, 0.833, 1.0, 0.0, 0.0, 1.0, 0.0, 0.438, 0.0, 1.0, 0.75, 0.0, 1.0, 1.0, 0.0, 0.0, 0.717]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.063784</td>\n",
       "      <td>0.430168</td>\n",
       "      <td>0.264905</td>\n",
       "      <td>[0.333, 0.25, 0.5, 0.476, 0.0, 0.4, 0.2, 0.0, 0.0, 0.667, 0.0, 0.29, 0.0, 0.286, 0.412, 0.0, 0.4, 0.667, 0.0, 0.0, 0.682]</td>\n",
       "      <td>[0.222, 0.143, 0.333, 0.357, 0.0, 0.25, 0.125, 0.0, 0.0, 0.5, 0.0, 0.214, 0.0, 0.167, 0.28, 0.0, 0.312, 0.5, 0.0, 0.0, 0.634]</td>\n",
       "      <td>[0.667, 1.0, 1.0, 0.714, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.45, 0.0, 1.0, 0.778, 0.0, 0.556, 1.0, 0.0, 0.0, 0.739]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.064569</td>\n",
       "      <td>0.438547</td>\n",
       "      <td>0.286800</td>\n",
       "      <td>[0.308, 0.25, 0.615, 0.476, 0.5, 0.4, 0.222, 0.0, 0.0, 0.667, 0.0, 0.295, 0.222, 0.286, 0.323, 0.0, 0.364, 0.4, 0.0, 0.0, 0.695]</td>\n",
       "      <td>[0.222, 0.143, 0.444, 0.357, 0.333, 0.25, 0.125, 0.0, 0.0, 0.5, 0.0, 0.214, 0.125, 0.167, 0.2, 0.0, 0.25, 0.25, 0.0, 0.0, 0.661]</td>\n",
       "      <td>[0.5, 1.0, 1.0, 0.714, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.474, 1.0, 1.0, 0.833, 0.0, 0.667, 1.0, 0.0, 0.0, 0.733]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.063760</td>\n",
       "      <td>0.432961</td>\n",
       "      <td>0.295184</td>\n",
       "      <td>[0.333, 0.25, 0.5, 0.476, 0.5, 0.462, 0.2, 0.0, 0.0, 0.667, 0.0, 0.286, 0.222, 0.286, 0.514, 0.0, 0.429, 0.4, 0.0, 0.0, 0.675]</td>\n",
       "      <td>[0.222, 0.143, 0.333, 0.357, 0.333, 0.3, 0.125, 0.0, 0.0, 0.5, 0.0, 0.214, 0.125, 0.167, 0.36, 0.0, 0.375, 0.25, 0.0, 0.0, 0.617]</td>\n",
       "      <td>[0.667, 1.0, 1.0, 0.714, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.429, 1.0, 1.0, 0.9, 0.0, 0.5, 1.0, 0.0, 0.0, 0.743]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.064310</td>\n",
       "      <td>0.435754</td>\n",
       "      <td>0.286676</td>\n",
       "      <td>[0.308, 0.25, 0.615, 0.455, 0.5, 0.462, 0.2, 0.0, 0.0, 0.667, 0.0, 0.267, 0.0, 0.286, 0.513, 0.0, 0.417, 0.4, 0.0, 0.0, 0.682]</td>\n",
       "      <td>[0.222, 0.143, 0.444, 0.357, 0.333, 0.3, 0.125, 0.0, 0.0, 0.5, 0.0, 0.19, 0.0, 0.167, 0.4, 0.0, 0.312, 0.25, 0.0, 0.0, 0.628]</td>\n",
       "      <td>[0.5, 1.0, 1.0, 0.625, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.444, 0.0, 1.0, 0.714, 0.0, 0.625, 1.0, 0.0, 0.0, 0.747]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.065091</td>\n",
       "      <td>0.460894</td>\n",
       "      <td>0.344923</td>\n",
       "      <td>[0.333, 0.25, 0.5, 0.476, 0.5, 0.563, 0.2, 0.0, 0.0, 0.8, 0.0, 0.303, 0.0, 0.286, 0.526, 0.0, 0.467, 0.857, 0.5, 0.0, 0.682]</td>\n",
       "      <td>[0.222, 0.143, 0.333, 0.357, 0.333, 0.45, 0.125, 0.0, 0.0, 1.0, 0.0, 0.238, 0.0, 0.167, 0.4, 0.0, 0.438, 0.75, 0.333, 0.0, 0.628]</td>\n",
       "      <td>[0.667, 1.0, 1.0, 0.714, 1.0, 0.75, 0.5, 0.0, 0.0, 0.667, 0.0, 0.417, 0.0, 1.0, 0.769, 0.0, 0.5, 1.0, 1.0, 0.0, 0.747]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6fc588e64a498d8dcb7cb9c016ec14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8103448275862069, 'macro_f1': 0.30558040567825306, 'class_f1': [0.667, 0.0, 0.0, 1.0, 0.0, 0.75, 0.0, 0.0, 0.667, 0.0, 0.0, 0.6, 0.0, 0.0, 0.857, 0.0, 1.0, 0.0, 0.0, 0.0, 0.877], 'class_recall': [0.5, 0.0, 0.0, 1.0, 0.0, 0.75, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.941], 'class_precision': [1.0, 0.0, 0.0, 1.0, 0.0, 0.75, 0.0, 0.0, 0.5, 0.0, 0.0, 0.75, 0.0, 0.0, 0.75, 0.0, 1.0, 0.0, 0.0, 0.0, 0.821]}\n"
     ]
    }
   ],
   "source": [
    "PATIENCE=10\n",
    "result = Classifier_model_21.cross_validation(dataset, test_data, MAX_LEN, NUM_EPOCHS, LEARNING_RATE, BATCH_SIZE, PATIENCE, NUM_FOLDS, output_dir, project_name='ChatGPT_data_21class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.77\n",
      "Average Macro f1: 0.227\n",
      "Average Class f1: [0.222, 0.0, 0.0, 1.0, 0.0, 0.739, 0.0, 0.0, 0.222, 0.0, 0.0, 0.461, 0.0, 0.0, 0.719, 0.0, 0.556, 0.0, 0.0, 0.0, 0.857]\n",
      "Average Class recall: [0.167, 0.0, 0.0, 1.0, 0.0, 0.806, 0.0, 0.0, 0.333, 0.0, 0.0, 0.37, 0.0, 0.0, 0.778, 0.0, 0.667, 0.0, 0.0, 0.0, 0.942]\n",
      "Average Class precision: [0.333, 0.0, 0.0, 1.0, 0.0, 0.75, 0.0, 0.0, 0.167, 0.0, 0.0, 0.667, 0.0, 0.0, 0.717, 0.0, 0.5, 0.0, 0.0, 0.0, 0.787]\n"
     ]
    }
   ],
   "source": [
    "# 重みありの場合の結果（cv=5）解答\n",
    "average_accuracy = round(sum(d['accuracy'] for d in result)/len(result), 3)\n",
    "average_macro_f1 = round(sum(d['macro_f1'] for d in result)/len(result), 3)\n",
    "# クラスごとの平均値を計算\n",
    "average_class_f1 = [round(sum(d['class_f1'][i] for d in result) / len(result), 3) for i in range(len(result[0]['class_f1']))]\n",
    "average_class_recall = [round(sum(d['class_recall'][i] for d in result) / len(result), 3) for i in range(len(result[0]['class_recall']))]\n",
    "average_class_precision = [round(sum(d['class_precision'][i] for d in result) / len(result), 3) for i in range(len(result[0]['class_precision']))]\n",
    "print(\"Average accuracy:\", average_accuracy)\n",
    "print(\"Average Macro f1:\", average_macro_f1)\n",
    "print(\"Average Class f1:\", average_class_f1)\n",
    "print(\"Average Class recall:\", average_class_recall)\n",
    "print(\"Average Class precision:\", average_class_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.697\n",
      "Average Macro f1: 0.205\n",
      "Average Class f1: [0.0, 0.0, 0.0, 1.0, 0.0, 0.611, 0.0, 0.0, 0.0, 0.0, 0.0, 0.342, 0.0, 0.0, 0.764, 0.0, 0.483, 0.0, 0.333, 0.0, 0.775]\n",
      "Average Class recall: [0.0, 0.0, 0.0, 1.0, 0.0, 0.556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.889, 0.0, 0.611, 0.0, 0.333, 0.0, 0.767]\n",
      "Average Class precision: [0.0, 0.0, 0.0, 1.0, 0.0, 0.722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.341, 0.0, 0.0, 0.681, 0.0, 0.4, 0.0, 0.333, 0.0, 0.791]\n"
     ]
    }
   ],
   "source": [
    "# 重みありの場合の結果（cv=5）\n",
    "average_accuracy = round(sum(d['accuracy'] for d in result)/len(result), 3)\n",
    "average_macro_f1 = round(sum(d['macro_f1'] for d in result)/len(result), 3)\n",
    "# クラスごとの平均値を計算\n",
    "average_class_f1 = [round(sum(d['class_f1'][i] for d in result) / len(result), 3) for i in range(len(result[0]['class_f1']))]\n",
    "average_class_recall = [round(sum(d['class_recall'][i] for d in result) / len(result), 3) for i in range(len(result[0]['class_recall']))]\n",
    "average_class_precision = [round(sum(d['class_precision'][i] for d in result) / len(result), 3) for i in range(len(result[0]['class_precision']))]\n",
    "print(\"Average accuracy:\", average_accuracy)\n",
    "print(\"Average Macro f1:\", average_macro_f1)\n",
    "print(\"Average Class f1:\", average_class_f1)\n",
    "print(\"Average Class recall:\", average_class_recall)\n",
    "print(\"Average Class precision:\", average_class_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.711\n",
      "Average Macro f1: 0.184\n",
      "Average Class f1: [0.0, 0.0, 0.0, 0.952, 0.0, 0.622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.443, 0.0, 0.0, 0.547, 0.0, 0.478, 0.0, 0.0, 0.0, 0.826]\n",
      "Average Class recall: [0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.396, 0.0, 0.0, 0.556, 0.0, 0.667, 0.0, 0.0, 0.0, 0.887]\n",
      "Average Class precision: [0.0, 0.0, 0.0, 0.917, 0.0, 0.833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.522, 0.0, 0.0, 0.556, 0.0, 0.406, 0.0, 0.0, 0.0, 0.775]\n"
     ]
    }
   ],
   "source": [
    "# # 重みなしの場合の結果（cv=5）\n",
    "# average_accuracy = round(sum(d['eval_accuracy'] for d in result)/len(result), 3)\n",
    "# average_macro_f1 = round(sum(d['eval_macro_f1'] for d in result)/len(result), 3)\n",
    "# # クラスごとの平均値を計算\n",
    "# average_class_f1 = [round(sum(d['eval_class_f1'][i] for d in result) / len(result), 3) for i in range(len(result[0]['eval_class_f1']))]\n",
    "# average_class_recall = [round(sum(d['eval_class_recall'][i] for d in result) / len(result), 3) for i in range(len(result[0]['eval_class_recall']))]\n",
    "# average_class_precision = [round(sum(d['eval_class_precision'][i] for d in result) / len(result), 3) for i in range(len(result[0]['eval_class_precision']))]\n",
    "# print(\"Average accuracy:\", average_accuracy)\n",
    "# print(\"Average Macro f1:\", average_macro_f1)\n",
    "# print(\"Average Class f1:\", average_class_f1)\n",
    "# print(\"Average Class recall:\", average_class_recall)\n",
    "# print(\"Average Class precision:\", average_class_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### major class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 26  19  25  42   7  58  25  10  17   7  10 124  25  18  75  12  49  12\n",
      "  10   5 550]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(dataset['labels']).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストサイズ×マルチラベル数の二次元リスト\n",
    "majority_pred = [[0 for i in range(21)] for j in range(len(test_data['labels']))]\n",
    "for i in range(len(test_data['labels'])):\n",
    "    majority_pred[i][-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.488\n",
      "Average Macro f1: 0.031\n",
      "Average Class f1: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.656]\n",
      "Average Class recall: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "Average Class precision: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.488]\n"
     ]
    }
   ],
   "source": [
    "# accuracyを計算\n",
    "accuracy = round(accuracy_score(y_true=test_data['labels'], y_pred=majority_pred), 3)\n",
    "# macro f1を計算\n",
    "macro_f1 = round(f1_score(y_true=test_data['labels'], y_pred=majority_pred, average='macro', zero_division=0), 3)\n",
    "# クラス毎のF1値を計算\n",
    "class_f1 = [round(score, 3) for score in f1_score(y_true=test_data['labels'], y_pred=majority_pred, average=None, zero_division=0)]\n",
    "# クラス毎のrecallを計算\n",
    "class_recall = [round(score, 3) for score in recall_score(y_true=test_data['labels'], y_pred=majority_pred, average=None, zero_division=0)]\n",
    "# クラス毎のprecisionを計算\n",
    "class_precision = [round(score, 3) for score in precision_score(y_true=test_data['labels'], y_pred=majority_pred, average=None, zero_division=0)]\n",
    "print(\"Average accuracy:\", accuracy)\n",
    "print(\"Average Macro f1:\", macro_f1)\n",
    "print(\"Average Class f1:\", class_f1)\n",
    "print(\"Average Class recall:\", class_recall)\n",
    "print(\"Average Class precision:\", class_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "data, class_name = load_multiclass_dataset(f\"{DATASET_PATH}/act_classification_final_ChatGPT4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testデータと訓練に使用するデータに分割\n",
    "dataset, test_data = split_multilabel_data(data=data, test_size=0.1, SEED=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 26  19  25  42   7  58  25  10  17   7  10 124  25  18  75  12  49  12\n",
      "  10   5 550]\n",
      "[ 3  2  3  5  1  6  3  1  2  1  1 14  3  2  8  1  5  1  1  1 61]\n"
     ]
    }
   ],
   "source": [
    "# dataset['labels']とtest_data['labels']の各列の合計値を出力\n",
    "dataset_labels_np = np.array(dataset['labels'])\n",
    "test_data_labels_np = np.array(test_data['labels'])\n",
    "print(dataset_labels_np.sum(axis=0))\n",
    "print(test_data_labels_np.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 東北大BERT-v3\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-v3'\n",
    "# クラス数\n",
    "NUM_LABELS = 21\n",
    "Classifier_model = MultiClassClassifier(model_name=MODEL_NAME, num_labels=NUM_LABELS, seed=SEED, thresh=THRESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Fold: 1-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Parameter 'fn_kwargs'={'tokenizer': BertJapaneseTokenizer(name_or_path='cl-tohoku/bert-base-japanese-v3', vocab_size=32768, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}, 'max_len': 128} of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f1387eb9cc445680da647a23a126e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/716 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69046dd5f9094934bf05aac1b1792746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/359 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='91' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  91/4500 00:18 < 15:21, 4.78 it/s, Epoch 2/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.619700</td>\n",
       "      <td>0.466773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 21)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mClassifier_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_LEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_FOLDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m4Classification_cross_validation_class_weights_v2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my-project/src/my_project/train_v2.py:341\u001b[0m, in \u001b[0;36mMultiClassClassifier.cross_validation\u001b[0;34m(self, data, test_data, MAX_LEN, NUM_EPOCHS, LEARNIG_RATE, BATCH_SIZE, PATIENCE, NUM_FOLDS, output_dir, project_name)\u001b[0m\n\u001b[1;32m    336\u001b[0m eval_dataset \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtexts\u001b[39m\u001b[38;5;124m'\u001b[39m: [data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtexts\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m eval_index],\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: [data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m eval_index]\n\u001b[1;32m    339\u001b[0m }\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# モデル学習\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_LEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLEARNIG_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfold_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# 評価\u001b[39;00m\n\u001b[1;32m    343\u001b[0m eval_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation(trainer, test_data, MAX_LEN)\n",
      "File \u001b[0;32m~/my-project/src/my_project/train_v2.py:277\u001b[0m, in \u001b[0;36mMultiClassClassifier.train_model\u001b[0;34m(self, train_dataset, eval_dataset, MAX_LEN, NUM_EPOCHS, LEARNIG_RATE, BATCH_SIZE, PATIENCE, output_dir, project_name, run_name)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# Trainerの定義\u001b[39;00m\n\u001b[1;32m    269\u001b[0m trainer \u001b[38;5;241m=\u001b[39m MultilabelTrainer(\n\u001b[1;32m    270\u001b[0m     model \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m    271\u001b[0m     args \u001b[38;5;241m=\u001b[39m training_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m [EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39mPATIENCE)]\n\u001b[1;32m    276\u001b[0m )\n\u001b[0;32m--> 277\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/transformers/trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/transformers/trainer.py:1929\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1929\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   1933\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/transformers/trainer.py:2268\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         metrics\u001b[38;5;241m.\u001b[39mupdate(dataset_metrics)\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2268\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/transformers/trainer.py:3019\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3016\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3018\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3019\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3020\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3023\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3027\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3029\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/transformers/trainer.py:3310\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3306\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3307\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[1;32m   3308\u001b[0m         )\n\u001b[1;32m   3309\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3310\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3312\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/my-project/src/my_project/train_v2.py:211\u001b[0m, in \u001b[0;36mMultiClassClassifier.compute_metrics\u001b[0;34m(self, eval_pred)\u001b[0m\n\u001b[1;32m    209\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(accuracy_score(y_true\u001b[38;5;241m=\u001b[39mvalid_labels, y_pred\u001b[38;5;241m=\u001b[39mvalid_predictions), \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# macro f1を計算\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m macro_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(\u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# # クラス毎のF1値を計算\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# class_f1 = [round(score, 3) for score in f1_score(y_true=valid_labels, y_pred=valid_predictions, average=None, zero_division=0)]\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# # クラス毎のrecallを計算\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# class_recall = [round(score, 3) for score in recall_score(y_true=valid_labels, y_pred=valid_predictions, average=None, zero_division=0)]\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# # クラス毎のprecisionを計算\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# class_precision = [round(score, 3) for score in precision_score(y_true=valid_labels, y_pred=valid_predictions, average=None, zero_division=0)]\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: accuracy, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro_f1\u001b[39m\u001b[38;5;124m'\u001b[39m: macro_f1}\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1238\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1071\u001b[0m     {\n\u001b[1;32m   1072\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1096\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1097\u001b[0m ):\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \n\u001b[1;32m   1100\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1411\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1251\u001b[0m     {\n\u001b[1;32m   1252\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1279\u001b[0m ):\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \n\u001b[1;32m   1282\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;124;03m    0.38...\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1411\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1413\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1417\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1721\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m \n\u001b[1;32m   1565\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m zero_division_value \u001b[38;5;241m=\u001b[39m _check_zero_division(zero_division)\n\u001b[0;32m-> 1721\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1502\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1499\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m-> 1502\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m \u001b[43munique_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/sklearn/utils/multiclass.py:91\u001b[0m, in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     85\u001b[0m label_type \u001b[38;5;241m=\u001b[39m ys_types\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Check consistency for the indicator format\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m     89\u001b[0m     label_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m---> 91\u001b[0m         \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     )\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     96\u001b[0m ):\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMulti-label binary indicator input with different numbers of labels\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Get the unique set of labels\u001b[39;00m\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/sklearn/utils/multiclass.py:92\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     85\u001b[0m label_type \u001b[38;5;241m=\u001b[39m ys_types\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Check consistency for the indicator format\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m     89\u001b[0m     label_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28mset\u001b[39m(\n\u001b[0;32m---> 92\u001b[0m             \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys\n\u001b[1;32m     93\u001b[0m         )\n\u001b[1;32m     94\u001b[0m     )\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     96\u001b[0m ):\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMulti-label binary indicator input with different numbers of labels\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Get the unique set of labels\u001b[39;00m\n",
      "File \u001b[0;32m~/my-project/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:969\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 969\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    970\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    971\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    972\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    973\u001b[0m         )\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    976\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 21)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "result = Classifier_model.cross_validation(dataset, test_data, MAX_LEN, NUM_EPOCHS, LEARNING_RATE, BATCH_SIZE, PATIENCE, NUM_FOLDS, output_dir, project_name='4Classification_cross_validation_class_weights_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'eval_loss': 0.06489665806293488,\n",
       "  'eval_accuracy': 0.516260162601626,\n",
       "  'eval_f1': 0.19292948191055528,\n",
       "  'eval_runtime': 0.8932,\n",
       "  'eval_samples_per_second': 275.412,\n",
       "  'eval_steps_per_second': 17.913,\n",
       "  'epoch': 25.0},\n",
       " {'eval_loss': 0.06510759890079498,\n",
       "  'eval_accuracy': 0.5528455284552846,\n",
       "  'eval_f1': 0.3209843153703635,\n",
       "  'eval_runtime': 0.7542,\n",
       "  'eval_samples_per_second': 326.194,\n",
       "  'eval_steps_per_second': 21.216,\n",
       "  'epoch': 26.0},\n",
       " {'eval_loss': 0.06674114614725113,\n",
       "  'eval_accuracy': 0.532520325203252,\n",
       "  'eval_f1': 0.19560974371084755,\n",
       "  'eval_runtime': 0.7671,\n",
       "  'eval_samples_per_second': 320.689,\n",
       "  'eval_steps_per_second': 20.858,\n",
       "  'epoch': 23.0}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.5338753387533876\n",
      "Average f1: 0.23650784699725547\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = sum(d['eval_accuracy'] for d in result)/len(result)\n",
    "average_f1 = sum(d['eval_f1'] for d in result)/len(result)\n",
    "print(\"Average accuracy:\", average_accuracy)\n",
    "print(\"Average f1:\", average_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全て０の場合を除かなかった場合の予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 東北大BERT-v3\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-v3'\n",
    "# クラス数\n",
    "NUM_LABELS = 21\n",
    "Classifier_model_21 = MultiClassClassifier(model_name=MODEL_NAME, num_labels=21, seed=SEED, thresh=THRESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Fold: 1-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Parameter 'fn_kwargs'={'tokenizer': BertJapaneseTokenizer(name_or_path='cl-tohoku/bert-base-japanese-v3', vocab_size=32768, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}, 'max_len': 128} of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96130f77a3fd4b78b21c34be63145be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/716 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0339188a17dd402887203a1c8297e4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/359 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1080' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1080/4500 04:26 < 14:05, 4.04 it/s, Epoch 24/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Class F1</th>\n",
       "      <th>Class Recall</th>\n",
       "      <th>Class Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.586100</td>\n",
       "      <td>0.463071</td>\n",
       "      <td>0.016713</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.042, 0.053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.267, 0.0, 0.0, 0.011]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.5, 0.316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.005]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.022, 0.029, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.182, 0.0, 0.0, 0.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.324100</td>\n",
       "      <td>0.196512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.116295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.092641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.082812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>0.077796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.074941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.072949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>0.071685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.070463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.069357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.068164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>0.066260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.065465</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.111, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.064306</td>\n",
       "      <td>0.011142</td>\n",
       "      <td>0.018141</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.381, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.235, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.062092</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.211, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.118, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.060872</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>0.032381</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.48, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12, 0.0, 0.353, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.061729</td>\n",
       "      <td>0.041783</td>\n",
       "      <td>0.066407</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.476, 0.0, 0.348, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.207, 0.0, 0.364, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.357, 0.0, 0.211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12, 0.0, 0.235, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.714, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.058724</td>\n",
       "      <td>0.103064</td>\n",
       "      <td>0.091381</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.4, 0.0, 0.182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.5, 0.4, 0.0, 0.0, 0.187]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.286, 0.0, 0.105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16, 0.0, 0.412, 0.25, 0.0, 0.0, 0.104]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.667, 0.0, 0.667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.571, 0.0, 0.636, 1.0, 0.0, 0.0, 0.95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.059991</td>\n",
       "      <td>0.325905</td>\n",
       "      <td>0.086061</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.25, 0.0, 0.19, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.276, 0.0, 0.435, 0.0, 0.0, 0.0, 0.656]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.143, 0.0, 0.105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16, 0.0, 0.294, 0.0, 0.0, 0.0, 0.568]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.833, 0.0, 0.0, 0.0, 0.776]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>0.058782</td>\n",
       "      <td>0.292479</td>\n",
       "      <td>0.146167</td>\n",
       "      <td>[0.364, 0.0, 0.545, 0.222, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043, 0.2, 0.0, 0.294, 0.0, 0.483, 0.0, 0.0, 0.0, 0.585]</td>\n",
       "      <td>[0.25, 0.0, 0.375, 0.143, 0.0, 0.211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024, 0.111, 0.0, 0.2, 0.0, 0.412, 0.0, 0.0, 0.0, 0.454]</td>\n",
       "      <td>[0.667, 0.0, 1.0, 0.5, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 1.0, 0.0, 0.556, 0.0, 0.583, 0.0, 0.0, 0.0, 0.822]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.060736</td>\n",
       "      <td>0.392758</td>\n",
       "      <td>0.213391</td>\n",
       "      <td>[0.364, 0.0, 0.545, 0.316, 0.0, 0.571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.157, 0.2, 0.0, 0.286, 0.0, 0.519, 0.857, 0.0, 0.0, 0.667]</td>\n",
       "      <td>[0.25, 0.0, 0.375, 0.214, 0.0, 0.421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.098, 0.111, 0.0, 0.2, 0.0, 0.412, 0.75, 0.0, 0.0, 0.585]</td>\n",
       "      <td>[0.667, 0.0, 1.0, 0.6, 0.0, 0.889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.5, 0.0, 0.7, 1.0, 0.0, 0.0, 0.775]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.065557</td>\n",
       "      <td>0.401114</td>\n",
       "      <td>0.118957</td>\n",
       "      <td>[0.0, 0.0, 0.545, 0.444, 0.0, 0.444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17, 0.0, 0.0, 0.207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.687]</td>\n",
       "      <td>[0.0, 0.0, 0.375, 0.286, 0.0, 0.316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.098, 0.0, 0.0, 0.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.689]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.667, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.685]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.061358</td>\n",
       "      <td>0.409471</td>\n",
       "      <td>0.214172</td>\n",
       "      <td>[0.222, 0.5, 0.667, 0.4, 0.0, 0.519, 0.0, 0.0, 0.0, 0.0, 0.0, 0.218, 0.2, 0.0, 0.312, 0.0, 0.381, 0.4, 0.0, 0.0, 0.679]</td>\n",
       "      <td>[0.125, 0.333, 0.5, 0.286, 0.0, 0.368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.146, 0.111, 0.0, 0.2, 0.0, 0.235, 0.25, 0.0, 0.0, 0.623]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.667, 0.0, 0.875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.429, 1.0, 0.0, 0.714, 0.0, 1.0, 1.0, 0.0, 0.0, 0.745]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cbcd31621341edb3fa5221e5175eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0631701648235321, 'eval_accuracy': 0.08, 'eval_macro_f1': 0.07984396555825127, 'eval_class_f1': [0.0, 0.0, 0.0, 0.571, 0.0, 0.286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.364, 0.0, 0.364, 0.0, 0.0, 0.0, 0.092], 'eval_class_recall': [0.0, 0.0, 0.0, 0.4, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.4, 0.0, 0.0, 0.0, 0.049], 'eval_class_precision': [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.667, 0.0, 0.333, 0.0, 0.0, 0.0, 0.75], 'eval_runtime': 0.4732, 'eval_samples_per_second': 264.155, 'eval_steps_per_second': 16.906, 'epoch': 24.0}\n",
      "-----------------Fold: 2-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe945e1849a476f92571ab574b59ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/717 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c547444b444d12ab8768c47735841d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fd269ff73b4b45bf988537d4549699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112307881315548, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1305' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1305/4500 05:09 < 12:39, 4.21 it/s, Epoch 29/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Class F1</th>\n",
       "      <th>Class Recall</th>\n",
       "      <th>Class Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.597000</td>\n",
       "      <td>0.461796</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>0.013709</td>\n",
       "      <td>[0.06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.077, 0.07, 0.0, 0.0, 0.0, 0.0, 0.081, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 1.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.032, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041, 0.036, 0.0, 0.0, 0.0, 0.0, 0.051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.313800</td>\n",
       "      <td>0.186706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.158200</td>\n",
       "      <td>0.117727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.092949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.082832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.077592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>0.074551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.072591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.081800</td>\n",
       "      <td>0.071396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.070310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.068899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.067436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.066549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.065582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.063340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.061249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>0.060095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.058975</td>\n",
       "      <td>0.013966</td>\n",
       "      <td>0.053320</td>\n",
       "      <td>[0.364, 0.286, 0.222, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.222, 0.167, 0.125, 0.0, 0.0, 0.053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.058528</td>\n",
       "      <td>0.022346</td>\n",
       "      <td>0.097304</td>\n",
       "      <td>[0.364, 0.5, 0.2, 0.133, 0.0, 0.261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048, 0.0, 0.0, 0.138, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.222, 0.333, 0.125, 0.071, 0.0, 0.158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024, 0.0, 0.0, 0.08, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 0.5, 1.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.057422</td>\n",
       "      <td>0.022346</td>\n",
       "      <td>0.080582</td>\n",
       "      <td>[0.364, 0.286, 0.222, 0.0, 0.0, 0.19, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045, 0.0, 0.0, 0.0, 0.0, 0.174, 0.4, 0.0, 0.0, 0.011]</td>\n",
       "      <td>[0.222, 0.167, 0.125, 0.0, 0.0, 0.105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024, 0.0, 0.0, 0.0, 0.0, 0.125, 0.25, 0.0, 0.0, 0.005]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.286, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.057317</td>\n",
       "      <td>0.223464</td>\n",
       "      <td>0.158858</td>\n",
       "      <td>[0.615, 0.286, 0.4, 0.235, 0.0, 0.261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.138, 0.0, 0.111, 0.667, 0.0, 0.0, 0.498]</td>\n",
       "      <td>[0.444, 0.167, 0.25, 0.143, 0.0, 0.158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073, 0.0, 0.0, 0.08, 0.0, 0.062, 0.5, 0.0, 0.0, 0.348]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.667, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.429, 0.0, 0.0, 0.5, 0.0, 0.5, 1.0, 0.0, 0.0, 0.877]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.057853</td>\n",
       "      <td>0.329609</td>\n",
       "      <td>0.151296</td>\n",
       "      <td>[0.4, 0.286, 0.333, 0.125, 0.0, 0.417, 0.0, 0.0, 0.0, 0.0, 0.0, 0.154, 0.0, 0.0, 0.138, 0.0, 0.0, 0.667, 0.0, 0.0, 0.658]</td>\n",
       "      <td>[0.333, 0.167, 0.25, 0.071, 0.0, 0.263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.098, 0.0, 0.0, 0.08, 0.0, 0.0, 0.5, 0.0, 0.0, 0.554]</td>\n",
       "      <td>[0.5, 1.0, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.364, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.81]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.057979</td>\n",
       "      <td>0.301676</td>\n",
       "      <td>0.182692</td>\n",
       "      <td>[0.556, 0.5, 0.429, 0.333, 0.0, 0.385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.222, 0.0, 0.0, 0.25, 0.0, 0.182, 0.4, 0.0, 0.0, 0.58]</td>\n",
       "      <td>[0.556, 0.333, 0.375, 0.214, 0.0, 0.263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.146, 0.0, 0.0, 0.16, 0.0, 0.125, 0.25, 0.0, 0.0, 0.451]</td>\n",
       "      <td>[0.556, 1.0, 0.5, 0.75, 0.0, 0.714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.462, 0.0, 0.0, 0.571, 0.0, 0.333, 1.0, 0.0, 0.0, 0.814]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>0.056248</td>\n",
       "      <td>0.321229</td>\n",
       "      <td>0.199857</td>\n",
       "      <td>[0.5, 0.5, 0.4, 0.333, 0.0, 0.385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.255, 0.0, 0.0, 0.303, 0.0, 0.25, 0.667, 0.0, 0.0, 0.605]</td>\n",
       "      <td>[0.333, 0.333, 0.375, 0.214, 0.0, 0.263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.171, 0.0, 0.0, 0.2, 0.0, 0.188, 0.5, 0.0, 0.0, 0.478]</td>\n",
       "      <td>[1.0, 1.0, 0.429, 0.75, 0.0, 0.714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.625, 0.0, 0.375, 1.0, 0.0, 0.0, 0.822]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.059708</td>\n",
       "      <td>0.351955</td>\n",
       "      <td>0.163247</td>\n",
       "      <td>[0.5, 0.286, 0.4, 0.235, 0.0, 0.32, 0.0, 0.0, 0.0, 0.0, 0.0, 0.154, 0.0, 0.0, 0.2, 0.0, 0.0, 0.667, 0.0, 0.0, 0.667]</td>\n",
       "      <td>[0.444, 0.167, 0.375, 0.143, 0.0, 0.211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.098, 0.0, 0.0, 0.12, 0.0, 0.0, 0.5, 0.0, 0.0, 0.582]</td>\n",
       "      <td>[0.571, 1.0, 0.429, 0.667, 0.0, 0.667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.364, 0.0, 0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 0.0, 0.781]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.060313</td>\n",
       "      <td>0.405028</td>\n",
       "      <td>0.196434</td>\n",
       "      <td>[0.588, 0.5, 0.5, 0.316, 0.0, 0.385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.118, 0.0, 0.0, 0.343, 0.0, 0.0, 0.667, 0.0, 0.0, 0.709]</td>\n",
       "      <td>[0.556, 0.333, 0.5, 0.214, 0.0, 0.263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073, 0.0, 0.0, 0.24, 0.0, 0.0, 0.5, 0.0, 0.0, 0.663]</td>\n",
       "      <td>[0.625, 1.0, 0.5, 0.6, 0.0, 0.714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 0.0, 0.762]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.058878</td>\n",
       "      <td>0.385475</td>\n",
       "      <td>0.199824</td>\n",
       "      <td>[0.588, 0.5, 0.4, 0.316, 0.0, 0.385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.218, 0.0, 0.0, 0.258, 0.0, 0.182, 0.667, 0.0, 0.0, 0.683]</td>\n",
       "      <td>[0.556, 0.333, 0.375, 0.214, 0.0, 0.263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.146, 0.0, 0.0, 0.16, 0.0, 0.125, 0.5, 0.0, 0.0, 0.609]</td>\n",
       "      <td>[0.625, 1.0, 0.429, 0.6, 0.0, 0.714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.429, 0.0, 0.0, 0.667, 0.0, 0.333, 1.0, 0.0, 0.0, 0.778]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.059722</td>\n",
       "      <td>0.399441</td>\n",
       "      <td>0.216112</td>\n",
       "      <td>[0.588, 0.5, 0.5, 0.316, 0.0, 0.37, 0.0, 0.0, 0.0, 0.0, 0.0, 0.226, 0.2, 0.0, 0.312, 0.0, 0.182, 0.667, 0.0, 0.0, 0.677]</td>\n",
       "      <td>[0.556, 0.333, 0.5, 0.214, 0.0, 0.263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.146, 0.125, 0.0, 0.2, 0.0, 0.125, 0.5, 0.0, 0.0, 0.62]</td>\n",
       "      <td>[0.625, 1.0, 0.5, 0.6, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.714, 0.0, 0.333, 1.0, 0.0, 0.0, 0.745]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.059198</td>\n",
       "      <td>0.393855</td>\n",
       "      <td>0.210925</td>\n",
       "      <td>[0.615, 0.5, 0.588, 0.286, 0.0, 0.385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16, 0.0, 0.0, 0.294, 0.0, 0.25, 0.667, 0.0, 0.0, 0.685]</td>\n",
       "      <td>[0.444, 0.333, 0.625, 0.214, 0.0, 0.263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.098, 0.0, 0.0, 0.2, 0.0, 0.188, 0.5, 0.0, 0.0, 0.62]</td>\n",
       "      <td>[1.0, 1.0, 0.556, 0.429, 0.0, 0.714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.444, 0.0, 0.0, 0.556, 0.0, 0.375, 1.0, 0.0, 0.0, 0.765]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed3580b500744aa959e43dda242e445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06025061011314392, 'eval_accuracy': 0.336, 'eval_macro_f1': 0.13770356627499483, 'eval_class_f1': [0.0, 0.0, 0.0, 0.333, 0.0, 0.667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.0, 0.0, 0.333, 0.0, 0.667, 0.0, 0.0, 0.0, 0.606], 'eval_class_recall': [0.0, 0.0, 0.0, 0.2, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.214, 0.0, 0.0, 0.25, 0.0, 0.6, 0.0, 0.0, 0.0, 0.492], 'eval_class_precision': [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.429, 0.0, 0.0, 0.5, 0.0, 0.75, 0.0, 0.0, 0.0, 0.789], 'eval_runtime': 0.4953, 'eval_samples_per_second': 252.374, 'eval_steps_per_second': 16.152, 'epoch': 29.0}\n",
      "-----------------Fold: 3-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43475b8ebd1443e992294af76f475093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/717 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1839155350b470c9ad4dfc85faa5294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72803cab2f3a4e08b8e440930a15824c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112335117326842, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1440' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1440/4500 05:44 < 12:12, 4.18 it/s, Epoch 32/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Class F1</th>\n",
       "      <th>Class Recall</th>\n",
       "      <th>Class Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.647200</td>\n",
       "      <td>0.494113</td>\n",
       "      <td>0.103352</td>\n",
       "      <td>0.040485</td>\n",
       "      <td>[0.0, 0.051, 0.0, 0.0, 0.051, 0.0, 0.0, 0.0, 0.033, 0.0, 0.026, 0.0, 0.0, 0.065, 0.0, 0.026, 0.0, 0.0, 0.0, 0.0, 0.599]</td>\n",
       "      <td>[0.0, 0.143, 0.0, 0.0, 0.667, 0.0, 0.0, 0.0, 0.333, 0.0, 0.25, 0.0, 0.0, 0.167, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.656]</td>\n",
       "      <td>[0.0, 0.031, 0.0, 0.0, 0.026, 0.0, 0.0, 0.0, 0.017, 0.0, 0.014, 0.0, 0.0, 0.04, 0.0, 0.014, 0.0, 0.0, 0.0, 0.0, 0.55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>0.187065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.119123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.113900</td>\n",
       "      <td>0.096045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.086605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.090900</td>\n",
       "      <td>0.081802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.078951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.077149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.076071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.075075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.080200</td>\n",
       "      <td>0.074081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.073525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.072237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.071305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.074100</td>\n",
       "      <td>0.070420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.069078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.067685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.066456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.064741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.063737</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.015524</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.105, 0.0, 0.0, 0.0, 0.103]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.062, 0.0, 0.0, 0.0, 0.055]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.333, 0.0, 0.0, 0.0, 0.909]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.064866</td>\n",
       "      <td>0.240223</td>\n",
       "      <td>0.033867</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.586]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.464]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.794]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.064950</td>\n",
       "      <td>0.346369</td>\n",
       "      <td>0.080161</td>\n",
       "      <td>[0.0, 0.25, 0.0, 0.316, 0.0, 0.095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.089, 0.0, 0.0, 0.133, 0.0, 0.105, 0.0, 0.0, 0.0, 0.695]</td>\n",
       "      <td>[0.0, 0.143, 0.0, 0.214, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048, 0.0, 0.0, 0.08, 0.0, 0.062, 0.0, 0.0, 0.0, 0.628]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.6, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.667, 0.0, 0.0, 0.4, 0.0, 0.333, 0.0, 0.0, 0.0, 0.777]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>0.063147</td>\n",
       "      <td>0.346369</td>\n",
       "      <td>0.119071</td>\n",
       "      <td>[0.0, 0.25, 0.0, 0.4, 0.0, 0.174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.089, 0.0, 0.0, 0.133, 0.0, 0.375, 0.4, 0.0, 0.0, 0.679]</td>\n",
       "      <td>[0.0, 0.143, 0.0, 0.286, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048, 0.0, 0.0, 0.08, 0.0, 0.375, 0.25, 0.0, 0.0, 0.585]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.667, 0.0, 0.667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.667, 0.0, 0.0, 0.4, 0.0, 0.375, 1.0, 0.0, 0.0, 0.811]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.061462</td>\n",
       "      <td>0.351955</td>\n",
       "      <td>0.125011</td>\n",
       "      <td>[0.0, 0.25, 0.0, 0.4, 0.0, 0.25, 0.222, 0.0, 0.0, 0.0, 0.0, 0.163, 0.0, 0.0, 0.258, 0.0, 0.4, 0.0, 0.0, 0.0, 0.682]</td>\n",
       "      <td>[0.0, 0.143, 0.0, 0.286, 0.0, 0.15, 0.125, 0.0, 0.0, 0.0, 0.0, 0.095, 0.0, 0.0, 0.16, 0.0, 0.312, 0.0, 0.0, 0.0, 0.579]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.667, 0.0, 0.75, 1.0, 0.0, 0.0, 0.0, 0.0, 0.571, 0.0, 0.0, 0.667, 0.0, 0.556, 0.0, 0.0, 0.0, 0.828]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.063242</td>\n",
       "      <td>0.396648</td>\n",
       "      <td>0.209120</td>\n",
       "      <td>[0.2, 0.25, 0.2, 0.4, 0.0, 0.37, 0.222, 0.0, 0.0, 1.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.444, 0.4, 0.0, 0.0, 0.704]</td>\n",
       "      <td>[0.111, 0.143, 0.111, 0.286, 0.0, 0.25, 0.125, 0.0, 0.0, 1.0, 0.0, 0.119, 0.0, 0.0, 0.0, 0.0, 0.375, 0.25, 0.0, 0.0, 0.645]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.667, 0.0, 0.714, 1.0, 0.0, 0.0, 1.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.545, 1.0, 0.0, 0.0, 0.776]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.062552</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.179392</td>\n",
       "      <td>[0.333, 0.25, 0.364, 0.4, 0.0, 0.24, 0.222, 0.0, 0.0, 0.0, 0.0, 0.163, 0.0, 0.0, 0.194, 0.0, 0.4, 0.0, 0.5, 0.0, 0.701]</td>\n",
       "      <td>[0.222, 0.143, 0.222, 0.286, 0.0, 0.15, 0.125, 0.0, 0.0, 0.0, 0.0, 0.095, 0.0, 0.0, 0.12, 0.0, 0.438, 0.0, 0.333, 0.0, 0.628]</td>\n",
       "      <td>[0.667, 1.0, 1.0, 0.667, 0.0, 0.6, 1.0, 0.0, 0.0, 0.0, 0.0, 0.571, 0.0, 0.0, 0.5, 0.0, 0.368, 0.0, 1.0, 0.0, 0.793]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.059825</td>\n",
       "      <td>0.321229</td>\n",
       "      <td>0.203841</td>\n",
       "      <td>[0.308, 0.25, 0.364, 0.4, 0.0, 0.24, 0.222, 0.0, 0.0, 0.0, 0.0, 0.122, 0.0, 0.0, 0.465, 0.0, 0.414, 0.4, 0.5, 0.0, 0.596]</td>\n",
       "      <td>[0.222, 0.143, 0.222, 0.286, 0.0, 0.15, 0.125, 0.0, 0.0, 0.0, 0.0, 0.071, 0.0, 0.0, 0.4, 0.0, 0.375, 0.25, 0.333, 0.0, 0.459]</td>\n",
       "      <td>[0.5, 1.0, 1.0, 0.667, 0.0, 0.6, 1.0, 0.0, 0.0, 0.0, 0.0, 0.429, 0.0, 0.0, 0.556, 0.0, 0.462, 1.0, 1.0, 0.0, 0.848]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.062770</td>\n",
       "      <td>0.405028</td>\n",
       "      <td>0.198811</td>\n",
       "      <td>[0.364, 0.25, 0.5, 0.316, 0.0, 0.24, 0.222, 0.0, 0.0, 0.0, 0.0, 0.122, 0.0, 0.0, 0.462, 0.0, 0.5, 0.0, 0.5, 0.0, 0.699]</td>\n",
       "      <td>[0.222, 0.143, 0.333, 0.214, 0.0, 0.15, 0.125, 0.0, 0.0, 0.0, 0.0, 0.071, 0.0, 0.0, 0.36, 0.0, 0.562, 0.0, 0.333, 0.0, 0.623]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.6, 0.0, 0.6, 1.0, 0.0, 0.0, 0.0, 0.0, 0.429, 0.0, 0.0, 0.643, 0.0, 0.45, 0.0, 1.0, 0.0, 0.797]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.064079</td>\n",
       "      <td>0.424581</td>\n",
       "      <td>0.238246</td>\n",
       "      <td>[0.333, 0.25, 0.615, 0.4, 0.0, 0.357, 0.222, 0.0, 0.0, 0.667, 0.0, 0.231, 0.0, 0.0, 0.421, 0.0, 0.4, 0.4, 0.0, 0.0, 0.707]</td>\n",
       "      <td>[0.222, 0.143, 0.444, 0.286, 0.0, 0.25, 0.125, 0.0, 0.0, 0.5, 0.0, 0.143, 0.0, 0.0, 0.32, 0.0, 0.375, 0.25, 0.0, 0.0, 0.645]</td>\n",
       "      <td>[0.667, 1.0, 1.0, 0.667, 0.0, 0.625, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6, 0.0, 0.0, 0.615, 0.0, 0.429, 1.0, 0.0, 0.0, 0.781]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.069605</td>\n",
       "      <td>0.455307</td>\n",
       "      <td>0.261757</td>\n",
       "      <td>[0.333, 0.25, 0.615, 0.4, 0.0, 0.25, 0.2, 0.0, 0.0, 1.0, 0.0, 0.218, 0.0, 0.0, 0.235, 0.0, 0.37, 0.4, 0.5, 0.0, 0.724]</td>\n",
       "      <td>[0.222, 0.143, 0.444, 0.286, 0.0, 0.15, 0.125, 0.0, 0.0, 1.0, 0.0, 0.143, 0.0, 0.0, 0.16, 0.0, 0.312, 0.25, 0.333, 0.0, 0.732]</td>\n",
       "      <td>[0.667, 1.0, 1.0, 0.667, 0.0, 0.75, 0.5, 0.0, 0.0, 1.0, 0.0, 0.462, 0.0, 0.0, 0.444, 0.0, 0.455, 1.0, 1.0, 0.0, 0.717]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.065973</td>\n",
       "      <td>0.424581</td>\n",
       "      <td>0.270847</td>\n",
       "      <td>[0.308, 0.25, 0.615, 0.4, 0.0, 0.24, 0.2, 0.0, 0.0, 0.8, 0.0, 0.122, 0.0, 0.0, 0.419, 0.0, 0.438, 0.4, 0.8, 0.0, 0.696]</td>\n",
       "      <td>[0.222, 0.143, 0.444, 0.286, 0.0, 0.15, 0.125, 0.0, 0.0, 1.0, 0.0, 0.071, 0.0, 0.0, 0.36, 0.0, 0.438, 0.25, 0.667, 0.0, 0.645]</td>\n",
       "      <td>[0.5, 1.0, 1.0, 0.667, 0.0, 0.6, 0.5, 0.0, 0.0, 0.667, 0.0, 0.429, 0.0, 0.0, 0.5, 0.0, 0.438, 1.0, 1.0, 0.0, 0.756]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.067516</td>\n",
       "      <td>0.449721</td>\n",
       "      <td>0.297804</td>\n",
       "      <td>[0.308, 0.25, 0.615, 0.4, 0.0, 0.24, 0.615, 0.0, 0.0, 1.0, 0.0, 0.16, 0.0, 0.0, 0.389, 0.0, 0.4, 0.667, 0.5, 0.0, 0.71]</td>\n",
       "      <td>[0.222, 0.143, 0.444, 0.286, 0.0, 0.15, 0.5, 0.0, 0.0, 1.0, 0.0, 0.095, 0.0, 0.0, 0.28, 0.0, 0.375, 0.5, 0.333, 0.0, 0.689]</td>\n",
       "      <td>[0.5, 1.0, 1.0, 0.667, 0.0, 0.6, 0.8, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.636, 0.0, 0.429, 1.0, 1.0, 0.0, 0.733]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e7b8dfce5e484098b3a50907b270e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.058311909437179565, 'eval_accuracy': 0.272, 'eval_macro_f1': 0.1902841007402109, 'eval_class_f1': [0.0, 0.0, 0.0, 0.571, 0.0, 0.444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.625, 0.0, 0.545, 0.0, 1.0, 0.0, 0.41], 'eval_class_recall': [0.0, 0.0, 0.0, 0.4, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.0, 0.0, 0.625, 0.0, 0.6, 0.0, 1.0, 0.0, 0.279], 'eval_class_precision': [0.0, 0.0, 0.0, 1.0, 0.0, 0.667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.667, 0.0, 0.0, 0.625, 0.0, 0.5, 0.0, 1.0, 0.0, 0.773], 'eval_runtime': 0.4707, 'eval_samples_per_second': 265.588, 'eval_steps_per_second': 16.998, 'epoch': 32.0}\n"
     ]
    }
   ],
   "source": [
    "PATIENCE=5\n",
    "result = Classifier_model_21.cross_validation(dataset, test_data, MAX_LEN, NUM_EPOCHS, LEARNING_RATE, BATCH_SIZE, PATIENCE, NUM_FOLDS, output_dir, project_name='ChatGPT_data_21class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.229\n",
      "Average Macro f1: 0.136\n",
      "Average Class f1: [0.0, 0.0, 0.0, 0.492, 0.0, 0.466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.229, 0.0, 0.0, 0.441, 0.0, 0.525, 0.0, 0.333, 0.0, 0.369]\n",
      "Average Class recall: [0.0, 0.0, 0.0, 0.333, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.375, 0.0, 0.533, 0.0, 0.333, 0.0, 0.273]\n",
      "Average Class precision: [0.0, 0.0, 0.0, 1.0, 0.0, 0.889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.365, 0.0, 0.0, 0.597, 0.0, 0.528, 0.0, 0.333, 0.0, 0.771]\n"
     ]
    }
   ],
   "source": [
    "# 重みなしの場合の結果（cv=5）\n",
    "average_accuracy = round(sum(d['eval_accuracy'] for d in result)/len(result), 3)\n",
    "average_macro_f1 = round(sum(d['eval_macro_f1'] for d in result)/len(result), 3)\n",
    "# クラスごとの平均値を計算\n",
    "average_class_f1 = [round(sum(d['eval_class_f1'][i] for d in result) / len(result), 3) for i in range(len(result[0]['eval_class_f1']))]\n",
    "average_class_recall = [round(sum(d['eval_class_recall'][i] for d in result) / len(result), 3) for i in range(len(result[0]['eval_class_recall']))]\n",
    "average_class_precision = [round(sum(d['eval_class_precision'][i] for d in result) / len(result), 3) for i in range(len(result[0]['eval_class_precision']))]\n",
    "print(\"Average accuracy:\", average_accuracy)\n",
    "print(\"Average Macro f1:\", average_macro_f1)\n",
    "print(\"Average Class f1:\", average_class_f1)\n",
    "print(\"Average Class recall:\", average_class_recall)\n",
    "print(\"Average Class precision:\", average_class_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
