{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import cuda\n",
    "from src.my_project.dataset import load_dataset, load_text_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from src.my_project.dataset import preprocess_dataset, preprocess_multiclass_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットパス\n",
    "DATASET_PATH = Path('/home/is/akiyoshi-n/my-project/data')\n",
    "# 出力パス\n",
    "output_dir = Path('/home/is/akiyoshi-n/my-project/outputs')\n",
    "# パラメータの設定\n",
    "MAX_LEN = 128 # 最大トークン数．本データでは最大トークン数が105なので，全て符号化できる．\n",
    "# DROP_RATE = 0.4\n",
    "# バッチサイズ：分割した時の一つのデータ数．一回で学習するデータ数\n",
    "BATCH_SIZE = 16\n",
    "# エポック数：何周学習させるか．\n",
    "NUM_EPOCHS = 100\n",
    "# 学習率\n",
    "LEARNING_RATE = 2e-5\n",
    "# クロスバリデーションの分割数\n",
    "num_folds = 5\n",
    "# 乱数シード\n",
    "SEED = 2023\n",
    "# ラベル数\n",
    "num_labels = 2\n",
    "\n",
    "# デバイスの指定\n",
    "device = \"cuda:1\" if cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# データの読み込み\n",
    "data = load_dataset(f\"{DATASET_PATH}/act_classification_final.xlsx\")\n",
    "# 損失関数の定義\n",
    "CRITERION = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texts': ['あたしのダイスキな姉御のパパは85歳で現役歯科医。そのパパが去年突然倒れた。胃癌。手術もして一度は仕事復帰。しかし。今日、再手術が。無事済んでＩＣＵ。頑張って！癌と闘う全ての人に安らぎを神様おねがいします☆',\n",
       "  'テストしに歩いてたら１、２年生対象のアンケートしてるんですか…って言われたのだがすみません見た目若くて…と返してしまった嫌味みたい！\\u3000童顔ってこと',\n",
       "  '教授最高だった。何度も言うが、1996が大好きだ！生美貌の青空(と思い込んでる曲)と千のナイフ(と思い込んでる曲)に感動した。',\n",
       "  '「ありがとう」「嬉しい」というような言葉は、かけられた側にもその気持ちが伝播する。感謝の心は、人間関係を円滑に保つ最大の潤滑油だろう。感謝の心は常日頃忘れないようにしたい。改めて、強くそう思う。',\n",
       "  'さて、お家帰ってご飯にしよう。今夜は焼肉。昼間届いた豚肉で焼肉。備蓄してある肉が大量にあるから、明後日まで三日連続焼肉して、明明後日からは鍋にして三日ほど続け、それからまた焼肉という、肉々しい日々を過ごすことも可能……毎日、ちゃんとお家帰って食事が出来れば（ﾉ∀｀）',\n",
       "  '今日は砂川→新青梅街道→R16二本木→飯能阿須→飯能駅→東飯能駅→小曾木街道→青梅市民会館前→新青梅街道→イオンモールむさし村山ミュー→砂川とクルマを動かしてきました。クルマの運転はそれはもう楽しいです！',\n",
       "  'うちのおかぁちゃんは旧姓澤田なんやけど昔家に『沢田研二さんのお宅ですか？』って電話があったそうな\\u3000たまたまそこに居合わせたうちのおとぉちゃんが『研二はいま外出しております』っていったからもう大変ｗ\\u3000いくら京都出身やからって沢田に片っ端からかけてたんすかね？',\n",
       "  'リプライ送って帰ってこないときの大体の例\\u3000\\u3000①自分の発言が流された\\u3000②たまたま離籍した\\u3000③返事しにくい\\u3000④返しにくい\\u3000⑤返信が思いつかなかった\\u3000⑥一応ふぁぼった ヮ＜',\n",
       "  'こんな時でも\\u3000ＪＡＬは安全性・定時性・快適性を貫くべく\\u3000現場は全力で頑張ってほしい！現場の力が今こそ問われる。それが企業の底力だ！！',\n",
       "  '忘れたい恥ずかしい過去を黒歴史と言うが、今言ったりやったりしている事柄も、少し未来にゃ黒歴史。黒歴史の生産は死ぬまで止まらない。生まれ落ちてから、くたばるまで、ずっとずっと黒歴史は減ることなく増えてゆく。生きるってことは恥を重ねることと同義である。',\n",
       "  'ちょっと、久しぶりにお参りしてパワーもらって、違う駅まで散歩して帰ろう。羽根木公園に寄るのもいいなぁ。まだ祭やってないけど。',\n",
       "  '洗い物しながらオリンピック出場までにかかる費用のことをずっと考えていたよ\\u3000トリノの頃ってスケート場の助成金がどうこうっていう話盛り上がってた気がするんだが…',\n",
       "  '深夜キムチを実践。美味いのなんの。我が家では「妻家房」というお店のキムチがお気に入り。結構良くなって身体ポッカポカ。とってもヘルシーですし、この時期夜食にキムチはよさげですよー。',\n",
       "  '「射手座はなんか、痛快さがある感じかもしれない、「ほら、オレが言ったとおりだろ！」みたいな。悲観的だった相手にそれを言ってる感じ。」（ゆかりさん）言いたいね、ほら、オレが言ったとおりだろ！',\n",
       "  '「都営一日乗車券で東京一周プラン第一弾」を本日決行。700円で南千住・浅草・スカイツリー・晴海トリトン/晴海埠頭・バス車窓からの銀座/皇居界隈・都庁周辺を巡ってまいりました。おかげさまでとっても楽しんでまいりましたよー！これは本当におとくな楽しみ方だと思います。',\n",
       "  'ちょいとヤニが不足したので、喫煙所へ行きヤニ補給した。肺から全身にに染み渡るニコチンは、身体に毒だが美味い。っつか、ふかさず肺まで入れてしばし転がしてから、煙をゆっくり吐くのが美味い。完全に中毒である。 【例大祭 え05b「かもひゃく」】',\n",
       "  'そう言えば、今日の打ち合わせ帰りに西友のペットショップ寄って、五万円で売られているうさぎさんを眺めながら、「ふわふぁ～うさうさ～ふぁ～」とか呟いていたら、周囲から人が居なくなった。私とうさぎさんがお話しするにあたって、周りの人間どもが気を利かせてくれたようで、大変結構(*´▽`)',\n",
       "  '今日はかなりスムーズに大学から帰宅できそう。モノレールの駅から我が家まで85分コース。すなわち法学部棟から100分弱コース。‥やっぱり遠いわ！笑',\n",
       "  '友達の彼氏の兄さんがチャラいイケメンメイクアップアーティストで素敵にメイクしてもらうけど席外した隙に携帯いじられて勝手にパスワード設定される夢みた',\n",
       "  '4月から宮城に移るにあたって、改めて東京と言う街、練馬と言う街を見つめなおしているわけだが、新たな発見が以前に増して多い。意識の変化で、視界に入る光景は大きく違ってみえるのですね、本当に。',\n",
       "  '親父が札幌出張から帰宅。親父のお土産のししゃも×俺が以前買った米沢の地酒「東光」の小瓶で軽く晩酌。あぶったししゃもが油のってて最高のお酒のツマミでした。そして、日本酒はもはや自分の生き甲斐のひとつです。',\n",
       "  'ここの大学教授でも英語しゃべれへん人いぱいいんのにうちのBossはほんと流暢♪\\u3000かっこええわぁ\\u3000頭はラーメン小池さんやし\\u3000靴はさきんちょとがってるしｗｗｗ\\u3000酒飲んだらただのよっぱなおさんやけろｗｗ',\n",
       "  'ゆるく固執せず、日々楽しく、しかし機敏な行動力はもちあわせ、現地で考え、南東北を拠点に走り回り、地域の現状をより良くすべく動いていく。現地から、東北の食文化を常に発信することもしていきたい。職住近接で働けるうまみを徹底的に活かし、自分なりの「個性」がにじみでた生き方をしたいな。',\n",
       "  '「米沢牛×どまんなかという夢のコラボレーション駅弁」＝「牛肉どまんなか」＠米沢駅弁。「観光とは夢を売るモノ」とうかがい共感した私ですが、このような形で「旅」にも様々な「ワクワク」を仕掛けていきたいですね。',\n",
       "  'わーいぃ\\u3000研究室に英国人くるかもーｗｗ\\u3000夏たのしみｗ\\u3000クィーンズイングリッシュを叩き込んで戴こうぢゃないのっ！でもあたしの英語は壊れてるから受け入れてもらえへんかもｗｗ',\n",
       "  '彼女いわく\\u3000『ぱんついはいてガードルはいてパンストはくやろ？顔も一緒やっ!!』\\u3000つまり\\u3000ぱんつ＝日焼け止め（下地）\\u3000ガードル＝ファンデーション\\u3000パンスト＝パウダーなんやって',\n",
       "  '先日開けた生樽10L結局飲みきれなかったところに勘のイイ友人からメール、飲みの話断れない(^^ゞ今年最後のお家忘年会♪急遽開催決定なう～。来年のテーマ「お酒との上手な付き合い方」～今年いっぱいはOK！',\n",
       "  'どっかたるんでたなゃ…ギリギリ始業に滑り込めるか 激走にて汗が流れてとまらない。ローカル線が異様にゆっくりに感じる。どこでもドア ほしい！…このタイミングではもうアウトだなう(i_i)＼(^_^)ヨシヨシ自分',\n",
       "  '今日お隣さん終日不在。こんなにも精神が疲れてないのはそのせいだと実感。クレーム対応などが主な精神疲労じゃないんだ。はぁ…。スキップで退社なう♪',\n",
       "  '40日目か･･・ここまで何かを続けられた事があっただろうか\\u3000\\u3000まぁどうせ夜間遺精があったから出来てるんでしょうけどね｡\\u3000\\u3000実際出さずに耐えたのは2週間が限度だったし',\n",
       "  'サンドイッチが食べたい！！って言われてこんな時間にツナタマゴチーズサンド作ってるなう～よぱっらいだから美味しいのデキルゾ！！',\n",
       "  'ちなみにシナリオライターは「こなたからかなたまで」の人です。「こなたから」が面白かった方にもいけると思います→シークレットゲーム',\n",
       "  '食糞や飲尿に限らず飲精もそうですが、身体の部位に口付けて直食いや直飲みと比べると別の器へ出した物を、飲んだり食べたりはハードルが高まりますね。ペニスしゃぶって精液ちゅうちゅうごくごく出来ても、グラスに射精された精液ごっくんは、フツーに抵抗感強いですしｗ',\n",
       "  '司馬遼太郎は東條さんのことを「集団的政治発狂組合の事務局長」と言ったが、最近のニュースを見ると、小沢一郎こそが集団的政治発狂組合の事務総長って感じ。っつか、不正や操作が無い世論調査したら「衆議院解散」を求める人が、結構な割合で居てもおかしくないな、と。',\n",
       "  'ふぁぼれよ\\u300010fav\\u3000いけよ\\u3000ふぁぼれよ\\u300020fav\\u3000いけよ\\u3000ふぁぼれよ\\u300030fav\\u3000いけよ\\u3000ふぁぼれよ\\u300040fav\\u3000いけよ\\u3000ふぁぼれよ\\u300050fav\\u3000いけよ\\u3000ふぁぼれよ\\u3000100fav\\u3000いけよ',\n",
       "  '山形は今ではそれはもう大好きな土地。山形駅に初めて降り立ったのは、小学校低学年の父とのふたり旅のとき。時を経ていま、自分自身の手で山形の観光の一端を担うかもしれない立場に。人生とは、わからぬものよ。',\n",
       "  '小学生の頃サッカー見に行った時に丁度フリューゲルスの存続がかかってて署名したのを思い出した\\u3000 で 近鉄が無くなる頃2chのどこかで元フリューゲルスファンだって人がチーム存続の話をしてて 署名したけど力になれなくてごめんね→その時はありがとうって会話したのも思い出した 泣きそうだぜ',\n",
       "  'ありま、前提条件の明記不足のためにそのまま二重表現込みのリプライをしてしまった。日頃それなりに日本語の文法を意識しているつもりなのですが、こりゃ不覚。140文字にエッセンスを込めるのは、まさしく推敲の一端ですな。',\n",
       "  '日本に於いては、かつてそれが美徳だったんですがねぇ。今はセルフプロデュースと申しますか、隠すべき頑張る姿なども宣伝材料にしないと……作品だけではなく作家そのものも\"売る\"時代に。ある意味では表現者として、それも正しい姿なのかも知れませんね、と。 【例大祭 え05b「かもひゃく」】',\n",
       "  'パワポ資料の作成にあたり、今まで色々試してきたフォントですが、日本語で資料を作る時は「 MS P ゴシック(漢字+ひらがな)」+「 Tahoma (英数字)」で落ち着いています。明朝派にはなれなかったなあ',\n",
       "  'おはようございます！福島駅から東北旅行、今日も出発です。まずは山形方面に北上します。米沢ゆき普通列車なう。 #touhokutrip',\n",
       "  '今日はすごい空腹なの\\u3000朝パン二枚食べて昼うどん食べて夕方もうどん食べて中華まん食べて\\u3000飲みはおつまみ程度だったから恨めしくメニュー眺めてた\\u3000腹ペコあおむし',\n",
       "  '未だにホームズとアイリーンのパスティーシュを読んだことない\\u3000面白いんだと思うし誰もが惹かれる題材ではあるのだがホームズの恋愛とか想像がつかないどころか自分の中のキャラクタ崩壊してしまいそうでこわい',\n",
       "  'Billy Elliot観てAdam CooperのSwan Lake見に行った\\u3000男ばっかの白鳥の湖\\u3000色もんの方じゃなくてマジバレエ\\u3000かっこいいってそんな単純なもんじゃなかった',\n",
       "  '「あのフォローしたのになんでフォロー返してくれないんですか？」「え？」「自己紹介にフォロー返しお願いしますって書いてあるじゃないですか」「いや・・・そんな事いわれても・・・」「じゃあフォローできないんですか？」「いや、出来ないって事は無いけど…」「じゃあフォローしてくださいよ」',\n",
       "  '息子とサシ。「毎日たいくつな日々を淡々と頑張ってるんだよね、オレ、共学だったら違ったのにな！」と。たまげた。なう。処置なし。だけど、学園祭ではじけろ！と言った。。。',\n",
       "  'フレプリそんなにオモチャ売れなかったの…私がパッションハープを買わなかったのが悪いの…だが新プリキュアは変身前の方が可愛いな\\u3000ハートキャッチなんてついてるからピンクのハートは愛ある印の続きだと信じていたのに！',\n",
       "  'そーじかきらいな人はクリエイティブなんやって 心理学者が言ってたってさ  いー事言うなぁ  その人と結婚したらそーじしなくてもおこらりないね',\n",
       "  '少し飲み過ぎたってか焼酎濃くし過ぎたかしら。戻ってきて早々眠い。っつか、もうそろそろアマラン100位内から落ちそうだな。想定以上の更に上ぐらい動いたとは言え、一抹の淋しさを覚えるというか、他社が後追いするってわかってんなら、続編を書けとのオーダーをくださいと言いたい（ﾉ∀｀）',\n",
       "  '仕事しなきゃ。でもさぁ、とんでもないクレームに対応していると、間をとらないと、崩されてしまう。そんな時、私の楽しそうなＴＬ！ほっとします！',\n",
       "  'ぁー！せっかくの日曜日なのにママゴンが朝からガタガタバタバタ騒々しくて目が覚めた静かにしてほしい(-_-;)しかたない、おきようかな…',\n",
       "  'もう年内のゴミ収集終わっているのに、大掃除というか古雑誌処分。まめに雑誌は処分しないと大変だなと思いつつも、数ヶ月に一度ぐらいしかやらないので、かなり大量の山が出来る（ﾉ∀｀）\\u3000あと、不要なカタログとか郵便物というかダイレクトメールなども。',\n",
       "  'なんで、目ってあるのかなぁ。人って、ほとんど視力に頼ってるって。なにかで見たことあったり。犬とかは、目よりも。耳とか、鼻のほうが頼りになったり。どうしてなのかなぁ。',\n",
       "  'やべぇ、気付いたらもう15時だ。そろそろ出かけないと……地図をとりあえず印刷しつつ、他の準備急ごう。っつか、渋谷か……こわいことに巻き込まれないよう祈ろう。きっと、私が良く行っていた頃よりも治安悪化して、モヒカンがヒャッハーしてる街になってるだろうし。',\n",
       "  '最近の小旅行のコース：11/10チャリ旅 出発→千川通り→井草４→新青梅街道→西東京北原→ひばりヶ丘二郎→志木街道→新座栗原→新座馬場→R254→朝霞膝折→新座馬場→新座栄→大泉学園町→大泉IC脇→谷原→高野台→富士見台駅商店街→中村橋→帰還。',\n",
       "  '中野から帰宅のバスなう。深夜だから道も空いてるし、運転手もしっかりアクセルを踏んでくれます。今日も行き帰りいつものバスにお世話になったなぁ。',\n",
       "  '除湿モードが陰湿モードに見えた。ンなエアコンあったら嫌だなぁ、などと思いつつ、とりあえず目薬を探す。っつか、ちょいと目を酷使しすぎたせいか眼精疲労がかなりひどいってか、首と肩にも疲労が来て痛みつつある。目薬さして、首と肩には湿布を貼っておこう。 【例大祭 え05b「かもひゃく」】',\n",
       "  'オセロと将棋を、いっしょにしたゲームを考えたけど。そうすると。王さまのまわりの金とかを仲間にしたら。すぐに、王手でおわっちゃうことに気づいたり。',\n",
       "  '旅に出る機会は、基本「思いつき」。近場だっていいんです。その思いつきから、たくさんの街を巡り、明日のじぶんにつなげていく。一生涯、そのサイクルは続けていくつもりです。',\n",
       "  'ふむ。「手の中になにかざくざくいろーーーーんなものがある感じ。手の中がいっぱいになってる感じ。「掴む」。引き続き。」（byゆかりさん）掴むよ！',\n",
       "  '唐突に思い付いた。プラグ固定は包帯使えば簡単か。安価で肌に優しく伸縮性もあるし、切ったり縛ったりできる。汚れても軽く手洗いしてから洗濯機で大丈夫だし、どうしようもないときは処分。今度100円ショップで包帯買ってきて、どんな風にすればちょうど良いか調べてみよう(*´▽`)',\n",
       "  '青梅街道を杉並区梅里（起点）～山梨県塩山市（終点）まで通しで自分の手で運転してみたいな。以前は家族で砂川～奥多摩街道～青梅～柳沢峠～塩山と親父の運転で行ったのが懐かしい。',\n",
       "  '23日がバイトだったんだけど、両手におもちゃを持ったお父さんや、女児向けゲームのメモを持って売り場を聞いてくるおばあちゃんなどを見て、そういうクリスマスらしさは許されてもいいよね\\u3000などと思い',\n",
       "  '寝れるかどうかわからないけど試してみる。ある中はドリエル飲めないから、だめだったら戻ってくる。はらへって寝れないかもなぁ。ぐぅ',\n",
       "  '別に無私の善行を為してるとは思わない。私は下心ありまくり。此度の地震で被災したが募金により助かり、日本に興味を持ったハイチの人が、日本語を勉強して使いこなせるようになり、私の著作や趣味作品の読者さんになってくれる可能性もございますし。っつか、むしろそれ期待してる薄汚い募金ですわｗ',\n",
       "  'あぶない、品川から東京行き新幹線乗ろうとしてた…。ホームがらがらだなぁと思ったんだ…。出る時間が全く同じだったから行き先見てなかった。',\n",
       "  '昔付き合ってた男が『フランス語で知ってる単語ある?』って聞いたら『フランスパ～ン』って真剣に答えやがりましたのでどんびきしてその後別れてやりました\\u3000パンは英語ですらねーよ',\n",
       "  'それに意味不明なリプライに対する返事の内容を考える事の大変さ。\\u3000ある程度他のパターンにも対応できるようにしなくてはいけないしさらにその返事に対して違和感が無いようにセリフを考えないといけない。\\u3000\\u3000本当大変だ',\n",
       "  '21日の動き：家→中野（友人と合流） 中野～新井薬師前駅～上高田～西落合～落合南長崎駅～目白駅～都電鬼子母神前電停＜この間徒歩＞ 鬼子母神前→王子駅前（飲み→ゲーセン→バッセン） 王子→赤羽（解散）→池袋→練馬→帰宅\\u3000こんな感じ。こうみると、今日も結構歩いたな！まち歩き楽しい！',\n",
       "  'もんじゃ食べたい→一人安心出来る席埋まってる→ラーメン食べよう→予備校の近くのコンビニで美味しそうだと思ったカップ麺売り切れ→泣きそうになりながら焼きそば買って帰',\n",
       "  'どう言うわけだか、食物のことを考えると、いつの間にか性的な事柄に結びつけている。やはり食欲と性欲は近い欲求なんだなと思う冬の夜。',\n",
       "  '3月はSBR20巻と、イカ娘6巻と、WORKING!!7巻と、放浪息子10巻と、ディエンビエンフー7巻かぁ。楽しみかもー。',\n",
       "  '今日のガイダンス1、2年以外禁止！って至るところにあるから何でだろと思ったら某選手が来るからなのか！付属の同級生今3年だろ可哀想じゃないか…',\n",
       "  \"May [Can] I buy you a drink?; I'll buy you a drink.; Let me get [buy] you a drink. ; Allow me to buy you a drink. 1杯おごるよ。...やっぱり朝のポスト間違ってたな\",\n",
       "  'うさぎOFFのお店を予約した。最初の「もしもし、○○です」がチャイ語で返ってきて面白かった。こちらは当然のごとく余裕で日本語で対応。その後は日本語で何の問題なくやりとり。電話からして面白い雰囲気がプンプンと。こりゃ、楽しみだ！！',\n",
       "  '「（６）変換したiTunes Music Library.xmlをiTunesでインポート インポートはこれまた４時間ぐらいかかった。」と言うことは、ファイルの変更の他に何か作業が必要？これで最後？',\n",
       "  'Echoとmixiaにmixiボイスの\"自分への返信\"が一覧でみれる機能がついたら、より一層利便性が増しそう。現状でもかなり重宝していますが。',\n",
       "  'カービィの「技コピー」は、かなり好きかもー。でも。複数の敵を吸い込んだときは、ルーレットじゃなくて。組みあわせだったら、もっとおもしろいかもー。ビーム＋ソードとか。すごく、おもしろい組みあわせかもー。',\n",
       "  'Twitter での名前やハンドル、iddy や taco3 にあるデータ、Bio に書かれている情報など、分かる範囲でほぼ全てググってから「そういえば xxx に書かれてましたよね」とか言うと更にひかれる。場合によっては「何で知ってるんですかw」とか。いや、公開してるじゃん……',\n",
       "  '4月から宮城を拠点にし始めたら、慣れ親しんだ東京もまた違った形で見えてくるのだろうか。そのあたりも非常に楽しみだったりします。そのあたりの気づきも、今後引き続き気ままにツイートしていけたらと思っております。',\n",
       "  '8月半ばからつけてなかった家計簿（というか出費帳）をつけるなう\\u30009月で預金がガンと一気に減ってる原因を追究する…買い物し過ぎたせいなのはわかってます＾＾',\n",
       "  'わーー来週節分祭かぃっ\\u3000雪降るジンクスは守らりるでしょーか？\\u3000今年あったかいからなぁ・・・\\u3000でも不思議と雪降るんよねぇ・・・2/2-3',\n",
       "  'チンする時にラップをかけるのと、繰り返し使える加熱蓋使うのとでいつも迷う。ゴミ出さないならふたやし、水使わないならラップやし...',\n",
       "  '南東北移住後は、自分の足としてクルマを買って、いろいろと駆け巡りたい。これは第一に、自分が純粋に楽しむため。それと同時に、現状の公共交通の「改善すべき点」を見出す目的もある。どちらの良さも、不便なところも知っておくべきだから。',\n",
       "  '今日、母の誕生日でした。おめでとう＆ありがとう！をもいっかいここで言う～ママゴン、元気でこれからもよろしくね！！ありがとう！！',\n",
       "  '仕方ないから今日はウィルキンソンだけにする。ちぇっ。買い込んだウィルキンソンを床に落とした。割れなかったけど床がへこんだ。こっちのほうがまずいぞ。',\n",
       "  'ハイビジョンテレビでサザエさん見ても何に満足していいかわからんんん！BShiでやる蜷川幸雄の舞台誰か録画してくれ帝政ロシア末期でツルゲーネフとか出るの石丸幹二にーなの舞台に出てるのか',\n",
       "  '父親が「重要な忘れ物」(明日の伊勢出張の列車チケット)をしたため、会社の運転手さんが我が家までその忘れ物を取りにくるので待機なう。オレが起きてて＆オフで家にいてよかった。。眠いけど＼(^o^)／',\n",
       "  '起床して郵便物を見る。例大祭の参加案内が届いていた。っつか、チケットってか通行証、今回は左胸などに貼り付けるシールなのか。宅配便搬入は３月５日～３月11日必着、と。コミケよりも宅配便送り先住所が短く良い感じ。コミケもヤマト運輸にすりゃ良いのに。 【例大祭 え05b「かもひゃく」】',\n",
       "  '【とある冬の日のサイクリングルート】練馬～目白～池袋駅東口～王子駅～三ノ輪～白鬚橋～東向島～葛飾白鳥～北松戸駅～柏駅～柏呼塚～大島田～高柳～船橋法典駅～鬼越～本八幡駅～市川駅～小岩～奥戸新道～葛飾立石～東向島～王子～北区神谷～環七経由～練馬',\n",
       "  'よし、今夜の夕飯はフライドチキンとホルモン焼きにしよう。チキンはケンタッキー混んでるというか、まるで昔のドラクエ発売日量販店や、ソ連のお店並みの行列だろうから回避。ファミリーマートのフライドチキンで良いや。安いし。ケーキは昨日ってか今日未明に食べたから、今日は止めておこう。',\n",
       "  'twilog\\u300012月10日(木) (112) 12月11日(金) (215) \\u300012月12日(土) (339) \\u3000\\u3000つまり今日は400行くか',\n",
       "  'へんだ！開栓して無造作に冷蔵庫保管・・・２００９ｳﾞｫｼﾞｮﾚｰ・ﾇｰｳﾞｫｰ変身☆ﾔﾊﾞｲ！本日、木曜、よっぱらちゃえーーー！',\n",
       "  'お金で情熱ではなく劣情を表現するのは可能。具体的には、萎えた状態のペニスに紙幣を巻き付け、しかる後に肉槍を屹立させ紙幣を破いて熱り立った牡茎を露出させ誇示すれば、溢れんばかりの劣情を思う存分示せるでしょう。もっとも、貨幣を故意に毀損するのは確か犯罪ですがね、とｗ',\n",
       "  '那須は箱根と並んで我が家馴染みの観光地。いとこの家の別荘が那須にあった関係で、親戚共々東北道を使ってよく行ったものでした。当時は大宮栗橋線→久喜ICを経由し、東北道を那須ICで下りて那須高原に行ったんだったな。懐かしい。',\n",
       "  '部長が、私が仕事をリジェクトしてる、って言ったらしい。あんたから仕事やらされたことないですけど。あんたがプロジェクト管理できなかっただけじゃん。',\n",
       "  '不毛地帯久しぶりに見た\\u3000ＥＤすっごい声だなと思った人が他にもいたらしく新聞の投書に載っていたけど\\u3000それがいいんだ！って意見もあったなー',\n",
       "  '「能率が悪い」って！絶対許さん！！！！！！！！！！！！！！お前に言われたくない！てか、そんな悪口を教えるリストラ男が一番ばかなんじゃ？',\n",
       "  'さて、どのタイミングで、どこのケーキ屋さんにケーキ買いに行こうかしら……こう、フランボワーズの紅っぽい粘液状の物がかかってるのが、良いな。形を保ったままのイチゴとか木イチゴとかも、いっぱい乗っかってるのだと、もっと良い。レミリア様と妹様にお供えしつつ一緒に賞味するから色は紅、と。',\n",
       "  '飯後は、練馬駅近くのボロっちいゲーセンでカーゲーム。とうとうカードを買ってしまった。でもめっちゃ楽しいんだよなー。間もなく帰宅うぃる。',\n",
       "  '[USR] [USR] ただいまー！明日の朝が恐い…',\n",
       "  '塩中盛り、麺固め、なう。 ([USR] ラーメン湘家) [URL]',\n",
       "  'ﾆﾔﾆﾔ RT [USR] そんなTLがっ。じゃあネタ投下。大木くんはエロい RT [USR] 若干ACIDMAN TL。',\n",
       "  'M-1出る相談。RT [USR] 呼んだ？ RT [USR] [USR] つっこみができる女の人。',\n",
       "  'the HIATUSもクリップ流れてる。',\n",
       "  'Now Playing: \"ニラカイナリィリヒ\" from \"Merry Andrew\" (安藤裕子) いいホールで生で聴きたい！！',\n",
       "  'ザスパ草津、今日の必勝祈願。戸田とたぶん熊林。Photo by 嫁  [URL] #thespa',\n",
       "  '[USR] おはようございます。',\n",
       "  '[USR] おはようございますっ！TLが賑やかになってくると楽しいですよね～！達成おめ！',\n",
       "  'Now playing  on iTunes : \"Never Know\" from \"In Between Dreams\" (Jack Johnson)',\n",
       "  'ついったーみながらライブ映像流せるアプリいれたけど、どういう時使えるだろう。一度別アカでテストしないとこわいか',\n",
       "  'いのちのコストパフォーマンスと考えると、鯨が最強なんじゃないの？捨てるところ無いし。',\n",
       "  'クリスマスケーキ買ってきてくださいね(ｷﾗﾝ RT [USR] ソフトサラダやっと見つけた。入部できるかな…最初はやっぱパシリかな…クリスマスケーキ買ってこいとか…',\n",
       "  '右の頬の内側を1日で５回噛んだ。血が止まらない。',\n",
       "  'これからも自信を持って職務を遂行する(ｷﾘｯ RT [USR] ちょｗ 部長ｗ さすがですｗ RT [USR] あぶない、品川から東京行き新幹線乗ろうとしてた…。ホームがらがらだなぁと思ったんだ…。出る時間が全く同じだったから行き先見てなかった。',\n",
       "  'あさって出発とか…うそだろ…',\n",
       "  'えっ...RT [USR] えーっ！絵本のほのぼの世界とは相容れない展開。RT [USR] 確かピーターラビットのお母さんも食べられてしまうんですよね。RT [USR] 料理用に皮を剥かれたウサギを見たときはびびった。ちびってはいない。',\n",
       "  '[USR] TBS-BSが見られる環境でしたら、横浜のベンチに注目ですｗ',\n",
       "  '[USR] 甲子園のとこだったよ。あそこじゃなくても、うちの前とかツルツルだよ。気を付けて！',\n",
       "  'やっぱりレッドブルは、体に吸収しやすいようにできてるから、それにアルコール合わせたら死亡すると思うんだ...',\n",
       "  'ゲームやる時間＜昼間のＴＬ読む時間…',\n",
       "  '完全に酔いがまわって、postすることを迷わなくなってきた。もう駄文の連続だ！',\n",
       "  'あ。iPodの充電忘れてた…車の中だ…',\n",
       "  '[USR] 俺は上京したとき、喧嘩腰みたいに思われてね．．．あとは、かんます、たまげる、うまげ、あたりは笑われたw',\n",
       "  '日本シリーズに興味はなかったが、一阪神ファンとしてはやはり気に入らない。',\n",
       "  'これNYのセントラルパークみたいでいいすね。機会があれば夜滑ってみたい。 [URL]',\n",
       "  'きゃーうれしいー！RT [USR] [USR] なんでも聞いてるよー - バニーボーイ/CLASSIC',\n",
       "  'おわた......ahirukumaさんのモテ期が終わった度は95.7%です。 [URL]',\n",
       "  'ごろごろごろー！きゃっきゃうふふ、だ。RT [USR] 陽だまりの草原で転げまわるんだよ、風船で冒険の後。(僕はヤングボーイより） QT [USR] じゃあ半ズボンも準備する！RT [USR] ベンジーを見習うんだ、あひるたん！ QT [USR]',\n",
       "  '[USR] あれっ、どういう意味でナイショですか？',\n",
       "  'そそそ！扉が開く感じ！みなさんそれぞれ面白い！ QT [USR] #favorites50 見ながらTSUTAYAで10枚くらい借りたら楽しいかも！',\n",
       "  '[USR] 東京はポツポツ降っております。冬眠から目覚めた彼らの目撃情報もTL上にチラホラ。',\n",
       "  '帝王切開の日付決定。18日。がんばろう，嫁。',\n",
       "  '午後暇かも…先週あれだけ忙しかったのは何なんだ。半分くらい今週に回ればちょうどよかったのに',\n",
       "  'どうしてこうなった...ゆうたんのせいやろ...',\n",
       "  'やっぱり牡蠣がなくちゃね～♪',\n",
       "  'モヤイきたーー！ RT [USR] [20tweets] 「行方不明」のモヤイ像、戻る－ルパン三世「犯行声明」から2週間 - シブヤ経済新聞 [URL]',\n",
       "  '[USR] リスケします!!1\\u3000どうしてもダメだったらごめんなさい＞＜\\u3000サイボウズ Live 大好き!!1',\n",
       "  '[USR] デコが似合いそうなメタリックピンクなんです（泣',\n",
       "  '新しいのをかうから、積みゲーは結局ずっとプレイしない。RT [USR] え。「経済的」にではなく？何が精神的にアレなんですか？ RT [USR] そんなものやらないほうがいいと思いますｗ 精神的にorz RT [USR] 積みゲー、私',\n",
       "  'そうか、アイコンを作ってみるとか。',\n",
       "  'えっ！それマジ欲しい！アタマからきのこが生えてもいいほどきのこ愛好家にはたまらん！ QT [USR] きのこの雑誌「きのこる。」が #C77 でコミケデビューするそうな。間違いなくこの先生きのこる雑誌。',\n",
       "  '確かに生のことばの方がメディアに乗ったことばより信憑性を感じます。 QT [USR] RT [USR] [news] - 若年層の8割が「口コミ」を参考にする〜口コミ投稿は4人に1人 → [URL]',\n",
       "  '帰るなうー怒涛のデータ入力業務で肩と目が疲れすぎてしぬ＞＜明日あたりマッサージ行こうかな～',\n",
       "  '今から三重に帰ります！明日は朝から保育園の発表会なんでぇ♪',\n",
       "  'やべぇ、腰くだける。RT [USR] うお、やべ、大音量ヘドホンのコード抜いちまったぁ！ しかもスロウレインで。',\n",
       "  'ハルヒ映画って160分もあるの＞＜どうしようくじけそう',\n",
       "  '[USR] こないだチバ、なんかやったっけ？',\n",
       "  'カメラの横の点々？RT [USR] カメラしか見当たらぬ...RT [USR] 液晶のパネルの上の真ん中じゃなかった？カメラの近所に RT [USR] マックブック使ってる人〜マイクってどこにあるの〜？',\n",
       "  '社長、太っ腹やね。群馬には無いけどね…',\n",
       "  '武蔵野うどんなう。かやくご飯つき。 [URL]',\n",
       "  'もうむり、今日はあきらめる...',\n",
       "  'しまった、職務経歴書、今日中に送るって昼間メールしちゃったから、送るまで寝れない。あぁぁぁぁ。',\n",
       "  'さてARIに時間が残りました。ラッカーズの心中やいかに？ #nfljapan',\n",
       "  'ISSCC10個条そのはち\\u3000ISSCCの真の役割は昼の講演ではなく、夜の飲み会にある',\n",
       "  '新春大道芸、傘廻し＠東京都児童会館まえ [URL]',\n",
       "  'とうほぐ来てみっせ！RT [USR] ここ九州ｗ遠いｗｗ [USR] [URL]',\n",
       "  '今週末は地元でピカチュウとのあくしゅ会があるんだった。ただし、先着30名様。',\n",
       "  'SONGS見ちゃうと好感度高まっちゃうんだよね。あまり興味のない音楽家でさえも。見せ方巧いよなぁ。#nhk',\n",
       "  '確かにカーリング綺麗な選手が多い気がする RT [USR] 容姿選考アリですか⁇',\n",
       "  'コーヒー飲みに行こうと思ったが、激しい雨に萎えるなど。',\n",
       "  '[USR] パスワードなしだと「接続できません」ってなる。',\n",
       "  '佐藤隆太は、さんまに稲川淳二に似てきた、と言われてた。声とか。RT [USR] 佐藤隆太はパンチ佐藤に似てる。人類を516色の色鉛筆に例えたら、同じ色。',\n",
       "  '[USR] がぁ。公園、高低差あるから、飛ぶ練習してる。',\n",
       "  '後のやつありえないっしょw 生まれて半年ですよ～。RT [USR] ハーフバースデー？ はー ふばー すでー！？ RT [USR] 今日は赤ん坊のハーフバースデー。仕事片付いたら、直帰しようかプール寄ろうか悩む．．．',\n",
       "  '2:00をやるだけのために起きてたのに、なんだかんだ2:30だ。',\n",
       "  '赤ん坊と風呂に入るとどうも浸かりすぎてのぼせてしまう。湯上りは健康的に牛乳で！そして胃壁に膜を作っておいてウイスキーでもいくか。',\n",
       "  '普通の海苔は柔らかいので味付け海苔に醤油ゆけてご飯を巻いて食べるのが美味かと♪  RT [USR] [USR] 味付けのりじゃなくて普通の海苔でも大丈夫ですか？',\n",
       "  '他の求人、方向が近いのがあるけど、TOEICでだめだ。ここまで書いてるのは、ミーティングで英語を使うレベルと見た。',\n",
       "  '[USR] [USR] なんでみんなして酒出してくるねん！',\n",
       "  '目wwwwRT [USR] できたー！ [URL]',\n",
       "  'ナニはこの試合、ずいぶんキレてんなー。戦術うんぬんより、自由にやらせたほうがイイみたい。先輩のクリロナと同様。',\n",
       "  'ハマコー先生！そのハッシュタグは...',\n",
       "  '[USR] ほんとに東京に人口が減ってるか表参道に調査に行くんだ。そこにSBと無印がある(ｷﾗｷﾗ',\n",
       "  '今更ながらトラバター可愛いなー。 [URL]',\n",
       "  '味の表示もおこげ味？？RT [USR] おこげ味の飴を舐めてる。嵌まる。',\n",
       "  '[USR] おやすみなさいませ、よき夢を！',\n",
       "  'RT [USR] 本当に知られていないのが年金運用の実態です。「少子高齢化で年金が少なくなっている」という説明は、一面的でしかありません。高度経済成長時代を超えてきた日本の年金基金がどうしてこんなに減っているのか？4.1%を約束している年金運用が、このところ ...',\n",
       "  '[USR] ハジメマシテ！まずは100にんぐらいフォローすると面白くなってきますよ！',\n",
       "  '.[USR] ノープロブレムよ、ありがとう！',\n",
       "  '愛だね、愛。ほんと、愛だ。RT [USR] バタフライ・エフェクトを見た、とんでもなく感動した。愛だよ、愛。・・・愛だねぇ、愛。いやぁ、ここウン十年で一番いい映画でした。',\n",
       "  '[USR] カスタードないけど、チョコレートのヤツがあるよん。',\n",
       "  '[USR] よかったよかった。その場に行くことなんて重要じゃない、思いが重要。',\n",
       "  '[USR] ごりさん、またいいこと言った。ありがとう。でも明日からってw',\n",
       "  '最初はフォロー数あんまり増やすのもどうかなと思ってたけど、ある程度多いほうがなんか気楽にコメントできていいね。束縛されないっつーか。',\n",
       "  '聖者の行進、生で聴きたい。ほんと、あの声はすごい。いいホールで聴きたい。',\n",
       "  '[USR] おはヨーロピアン！よき一日でありますよう！',\n",
       "  '[USR] [USR] 誕生日おめでとうございますー！！！',\n",
       "  '弱いひとは自分より弱い獲物を見つける嗅覚が鋭い。小、中学校の頃にいじめられっ子だったから、すごくよくわかる。彼らは優位に立つのに必死だから。',\n",
       "  'GGTVのベンジーの回（10月放送）なう。このなまり好きじゃ。',\n",
       "  'なくもんか、観に行きたいなー',\n",
       "  '大根の炊けるいい匂い。ほわほわ。',\n",
       "  '[USR] テナーのアコースティックライブじゃない。シンペイもアコースティックってきた、とかポストしてた。',\n",
       "  'いますね、やっかいだから関わるの遠慮したいところ。 QT [USR] 謝りながらケンカ売ってくる奴って、実にたちが悪い。',\n",
       "  '[USR] そりゃ早寝だからですよ！あとウチの猫どもが起こしに来ますｗ',\n",
       "  '[USR] バ、バレた？そーゆー趣味ではない筈なんですが、必ず食い付く話題ですね。もしかしたら未だに肛門期なのかも知れません。',\n",
       "  '[USR] 中央線！いいな！私も中央線住みたかったんだ。',\n",
       "  'リアクションは、パッと浮かばないことならしなくていい、と最近思ってる。無視じゃなくてさ、ありがとう、と心の中にしまえばいい。',\n",
       "  'もちろんりあじゅうだぜ RT [USR] りあじゅうだ RT [USR] 今日はチェ・ゲバラを見てたか、ソリティアをやってました。',\n",
       "  '腹が減っていらいらなう、なので、早いけどとっとと食べることにした。みそ汁。ビールなし。',\n",
       "  '[USR] 群馬のはかなりレベル低い争いだけど…ｗ',\n",
       "  'やっと、ついに、ハリーポッター1みた。途中からもう、1.3倍速で。2、3も録れてるんだけど、いつみるかなぁ。',\n",
       "  'また今日もみとどけ人だ（byバクホン松田語録、ノブオのこと）',\n",
       "  '今川焼き美味しかったですｗｗ RT [USR] 明日成人病検診だから終わるまで絶食やんけ。きっついわー。',\n",
       "  '殺意を抱く程、他者に情念を向けられるなんて！',\n",
       "  'そうか、そろそろ羽根木公園の梅祭りなのかー。行かないと。',\n",
       "  '[USR] 肝機能の数値が悪いんですけど、何か良案ありませんか',\n",
       "  'もう、りおさんとのチャット状態になってきたな．．．俺もベッド行くべ。',\n",
       "  '宮崎あおいって、だんだん若がえってないか？ｗ',\n",
       "  'とりあえずチェブラーシカ豆を購入。 [URL]',\n",
       "  '[USR] 長風呂ご苦労様でちた',\n",
       "  '[USR] そうそう クレーマーにはなれんのですww',\n",
       "  '[USR] へぇ、英語の歌役立つんだ。すごいなぁ、好きだと覚えるもんだね。確かに、留学では相槌とか発音を覚えればそれでいいかもしれない。他は日本でもできるしね。（昨日、英語間違えてつっこまれたから、私、やるよ！）',\n",
       "  'ケイゾクフリーク発見！RT [USR] あーさーくーらああああぁぁ！！！(言ってみたかった RT [USR] あ、ご祝儀300万は私じゃないですよ、あさくらみなみさんですよ。',\n",
       "  'こども図書館まで歩いて行き,読み聞かせ会の後,サブウェイでめしを食っているなう。',\n",
       "  'と思ったら早く帰ってきた・・・',\n",
       "  'うわ！餃子がすごい行列で40分待ちだって！',\n",
       "  'シェリー！！！！これだ！もう1つ。',\n",
       "  '[USR] [USR] [USR] [USR] おやすみなさーい',\n",
       "  '短気の私にはこのTLはひとつの試練。耐えろ！',\n",
       "  'あれ？アメリカのスーパーマリオは帽子かぶってないんやな [URL]',\n",
       "  'はい！大好物です！ロックはブリテンです！つか、その本は間口があまりにもｗｗｗ  QT [USR] [USR]\\u3000おおおーXTCお好きなんですね！わたしも大好きなんすー！次回はXTC本のイタリア版、仏版とかをブクブクにもってこーかな（大迷惑）',\n",
       "  '返信していきたいところだけど、こんな時間になってしまったのでいい加減寝ます。過去話ＴＬ楽しかったです',\n",
       "  'Now Playing: \"ジュブナイル\" from \"Sing\" (GRAPEVINE) そんな映画なかったっけ。',\n",
       "  '会社設立日の新聞を頂いた。いろいろ波乱があった日に設立したん だなぁってしみじみと読んでみた (´ω｀) [URL]',\n",
       "  '[USR] だって、あんなに昼間に深夜便深夜便言ってたから気になるじゃんw',\n",
       "  '[USR] 4200円！？誰が買うんだろう...ボジョレーはもう、ねぇ。',\n",
       "  '[USR] そうそう、ナイアガラだ。',\n",
       "  'どうしろと？「インターネットプロバイダが IP アドレスを 1 つしか割り当てない場合Ethernet クライアントを接続するには、AirMac Express を WDS リモートベースステーションまたはブリッジ（NAT 機能オフ）に設定する必要があります。」',\n",
       "  'OCR 機能が付いているから ScanSnap が良いのかな。でも Mac だと日本語か英語か、どちらかしか使えないってのは寂しいな。',\n",
       "  'ニトリでもないんですねｗ RT [USR] わたしもIKEAだと思いました。RT [USR] せいゆうにとりあえずいけあ♬ってことで、IKEAに行きます。',\n",
       "  '[USR] ライブラリ、みたいなファイルをインポートしたら読み込むかも？',\n",
       "  'これまた合掌。今のうちにカルフールPB買いに行かなくては！魚缶がンまいのです。 QT [USR] 【企業】「カルフール」ブランド、日本から消滅…３月１０日から別の名前に: [URL]',\n",
       "  '５円安いから遠くのスーパーに歩いて買いに行くんじゃない！運動も兼ねて行くからトータル的には５円以上の安い買い物になるんだ！しかし、歩いてお腹が空いた分、もっとたくさん食べてしまうかも…。。',\n",
       "  'しゃちょは行くのか、ずるい RT [USR] ルートによっては実際にあひるさんにいってもらうことになりますよ！しかし先方の方が行くかもしれません。企画次第ですね。面白いルートをお願いしますよ！(どっちにしてもおらは行くもんね)',\n",
       "  '[USR] 違うの、さくらちゃんが、のんべえリスト作ってるのw くまさんはもちろん招待よ。',\n",
       "  'じゃあごめん、常に踊り狂ってたら、周りの人の邪魔だな。ACIDMANはバラードでも爆音なもんで。',\n",
       "  '横浜駅きれいになってるしー',\n",
       "  '小娘に煽られて恥ずいポストをした上に、寝落ちされた…軽く鬱なので寝ます。バイバイキーン！',\n",
       "  'うわさの納豆たまごかけごはんを食べた',\n",
       "  'どうせなら座席もうちょい選べはよかったかな～まあいっか',\n",
       "  'Σ(ﾟдﾟ;)RT [USR] 獣が何を言う RT [USR] 獣使いだって。強そう、うけるww。ahirukumaはレベル176の獣使いです。武器はブーメラン(+35)、盾は勇者の盾(+10)を装備中。 #twiQuester [URL]',\n",
       "  '今夜は早く帰って自宅で晩飯っす( ・∀・)ノ [URL]',\n",
       "  'ワロタｗ  たしかにｗｗ   QT [USR] 愛媛においてもネブルは通用致します。が、喧嘩のとき舐めとんか！とは言うも、ねぶっとんか！とは言いませんな〜 RT [USR] 舐めるって言う単語を「ねぶる」ってゆうてまいます。これは三重弁やろか？ #miemo',\n",
       "  '[USR] ひどい会社だ。10年前のあひるに教えてあげて＞＜',\n",
       "  '眠い、寒い、おしっこ、とゆー三重苦と闘っているところ。',\n",
       "  '[USR] 昼辛味噌ラーメンくった...いつもいつも、私もラーメンばっか食べてるんだな...',\n",
       "  'ようやく眼レフで撮った雪ヨシュパソコンに入れた。',\n",
       "  'たしかにｗｗｗRT [USR] 一眼でタッチパネルか',\n",
       "  '[USR] おかありです！寒かったー！',\n",
       "  'うっかり片付けスイッチいれてしまった。諦めて寝ることにする',\n",
       "  '僕は寿がきやの、肉入りセットが好きっすｗ  あの味が薄い味ご飯付きのｗｗ QT [USR] アピタ加納店  ⇒  寿がきや  ⇒  ラーメン＆牛丼食べる  ⇒  [USR] 社長のつぶやきのせいです・・・  ⇒  #sougofollow #followmeJP',\n",
       "  '[USR] バイオリン弾くのか。マスオってすごいんだ！標準語上手だね。',\n",
       "  'あしたの尿！放尿、聖水プレイができる店ですかねーｗ   QT [USR] [USR] すすきのに「あしたのニョー（尿）」ってありましたよ',\n",
       "  '「僕の小規模な生活」第3巻を完了。薄かった第2巻に比べるとずっと好印象',\n",
       "  '10キロまでならスクワットできます。5分ぐらい。',\n",
       "  'うどんとなめことクレソンもらったので、クレソン鍋にする。',\n",
       "  'アイスワインうまくてぺろんぺろんなう。帰りの電車で寝れますように。',\n",
       "  'ライブ中にタオル広げる人、何だろうね。後ろにいるとステージが見えねぇ。',\n",
       "  '都倉ＦＫ直接!みんなでゆりかごダンス',\n",
       "  '[USR] 養老の滝って他にもあるらしいよ。だからあの養老かどうかはわからないな。',\n",
       "  '最近買う福袋は紅茶か石鹸。服飾関係は遠ざかったなぁ。実用優先ｗ チーズ王国の福袋、復活して欲しいんだがなぁ。',\n",
       "  '[USR] へぇ、効率よく食べたいよね。バナナ以外で。',\n",
       "  '五角マグカップつきキットカット、100円也。千歳船橋のお菓子ディスカウントストアにて購入。 [URL]',\n",
       "  '[USR] あら、いつのまに。さくらちゃ、おやすみー',\n",
       "  'いまいち想像できねえw RT [USR] バンバンをオフっぽくいぢってあるっていうw RT [USR] ２００でも全然OKですよん。って２００だとオフ系なのかな？\\u3000RT [USR] おいらは行くなら200かなー。',\n",
       "  'RT [USR] 忘却 この平和な世界で 生きる喜び忘れた我ら そんな愚かな者の最後には 真っ赤なバラが散るのだろう\\u3000\\u3000：\\u3000\\u3000to live',\n",
       "  '親がテレビ購入検討中。私は無線LANとオーテクの黒のヘッドホン買った。ひまだから見てたらパソコン欲しくなった。',\n",
       "  'それは、ひょっとしてギャグで言ってるのか！？ 岡田監督\\u3000決勝Ｔ見据え仮想パラグアイと対戦 [URL]',\n",
       "  '紅白でキムタクが外人に英語で話しかけたけど通じなかったっておかんに聞いた。',\n",
       "  '[USR] マジで！電車の中で見られない…ぽっちゃり最高！',\n",
       "  'Listening to  -  UNICORN ／ペケペケ／THE VERY BEST OF UNICORN',\n",
       "  'はらドーナッツで幸せおやつタイム。',\n",
       "  '弁当なう。しょうがご飯、焼き野菜、葉っぱサラダなど。#obento [URL]',\n",
       "  '湯たんぽ、まだあったかくて幸せ。',\n",
       "  'オプーナとは - はてなキーワード [[URL] ]',\n",
       "  '近い！武道館でこんなに近いの始めてだ！ビョークなんてかなり上から後頭部しか見れなかった。 #ACIDMAN',\n",
       "  'な、なんと！よいこと聞いた！ QT [USR] スタバで1日1回のオーダーでその日のうちならおかわりが¥100で出来るなんて。今までは、お店に居る間しかだめだったのに。しかも、違う店舗でもおかわりOK。年明け初スタバで知ったの。',\n",
       "  'JCD見てたら、ミッシェル特集してた。歌詞の字幕は別にいらないと思ったけど。',\n",
       "  'フォロー有難うございました～♪僕もフォローさせてもらいました！  RT [USR] [USR] はじめまして！フォローさせて頂きました。よろしくお願いいたします♪',\n",
       "  'もふもふもふサンご無沙汰ですもふ！ RT [USR] [USR] ひょうじょうもふもふ',\n",
       "  '二度寝から生還したなう。「西洋亭\\u3000市」のソースカツ丼食ってくる。',\n",
       "  '小田急線なう。TOSCAの面談に向かう。駄菓子菓子！相談事項を未だまとめていないんだお！',\n",
       "  '[USR] 歌詞なんだ。面白いね。',\n",
       "  'なんだ？全然別な人がリミックスしてるのか、本人達なのか。玉子に聴けばわかりそうだな。',\n",
       "  '今、必死でアップル関連のpostを追っているところ。',\n",
       "  'たろっとさん！酒乱と来たか！なぜバレた！？',\n",
       "  '有難うございます！また何かアドバイス等あれば是非お願いします！ QT [USR] [USR] おめでとうございます。さんかわ社長のご紹介で二度ほど伺いましたがとても素敵なお店ですね！',\n",
       "  'カーリングって、投げたあとカメラにどアップで抜かれるから、今後可愛い子の競技人口がどんどん増える、かも…',\n",
       "  'GG09、ドーパンのスターみたいな声の人が歌ってるバンドはなんだろう。',\n",
       "  '砂糖マヨ、はげしく気になって参りました！今度試してみます。ありがとうございます。 RT [USR] 驚かれる方も多いのですが、これ、けっこういけるんですよ。砂糖とマヨネーズまぜてそのままトーストです。ぜひ！RT [USR] [USR] 砂糖マヨネーズ？！',\n",
       "  '[USR] その辺オープンなお客さんは最近多いんでは？',\n",
       "  '原稿が上がったー。眠いー。眼がしょぼしょぼしてる',\n",
       "  'タイムスリップ、幕末、医療、私の大好物ばかりがてんこ盛りじゃないのさー！ホント、どうしていままでJINを観ずに？たぶんNHKスペシャル観ているからだと思うんだけれどね。',\n",
       "  'ブラジルさんたちも不況につき帰国かぁ。確かに実家界隈のブラジルさんたちも居なくなってしまったしね。 #nhk',\n",
       "  'あざっす！RT [USR] RT\\xa0[USR]\\xa0【RT希望】ツイッター見たよ！と言ってもらえると、バーすがはらオリジナルカクテル本日１杯無料\\xa0[URL]\\xa0#barsugahara',\n",
       "  'Listening to Be My Love ♪ Keith Jarrett',\n",
       "  'ちょｗそれmotorcycleじゃなくてただのcycle。RT [USR] おれも人力バイクでどっかいってくるかなｗ RT [USR] ３連休中に一度はバイクに乗らなきゃだなあ、という義務感を感じるようになったらライダー失格なのかな。',\n",
       "  '[USR] 養老、何もないとこじゃろ。',\n",
       "  '戦友よ！今年も鼻息も荒く突入しようじゃないか！ QT [USR] とうとう開幕ですか。RT [USR] シー・シェパードへの意義申し立ても込めて、長崎鯨カツ弁当は必ず食べる！  # #keioekiben',\n",
       "  '[USR] おはようございますー。遅延の中ぼっとで遊んでしまいましたw',\n",
       "  \"I'm at 住吉駅 (住吉駅, 江東区). [URL]\",\n",
       "  'をを！ QT [USR] RT [USR] RT [USR] やば！ RT [USR] いま東京上空を通ったと思われる国際宇宙ステーションを撮ったなう。 [URL]',\n",
       "  '[USR] びーんず・・・気になる～～～',\n",
       "  '[USR] 忘れ得ぬ日々よ 何を手に入れた？無くして またくり返して/リピート。これ好きです。',\n",
       "  '[USR] [USR] そうそう、ライブは全身で感じるもの！（だから昨日文句ぶつぶつ書いたんだ。人それぞれだからほっとけばいいのにさ。）',\n",
       "  '宣言。土日のうちに必ずバイクに乗ります。いつもの乗る乗るサギじゃないよ！',\n",
       "  '見つからぬ＞＜とりあえずご飯たべる…',\n",
       "  'あ、週刊東洋経済の今週号も買っていた。これを読んでからブログのニュアンスを決めよう',\n",
       "  '同意。RT [USR] ねえ知ってル？\\u3000ニホン語は難しいんだYO！\\u3000HAHAHA！',\n",
       "  'Superflyの達也とひなっちとかが参加した曲流れてる。音が豪華だ。',\n",
       "  '[USR] もう酔ってないです。',\n",
       "  '今日は午後早引きして印鑑登録。不動院前は区役所が不便過ぎ。中区や安佐南区が便利。',\n",
       "  '[USR] 頭痛ですか？！わわわ！どうかお大事に！',\n",
       "  '低さ。今、成績のこと笑われたのかな。きーっヽ(#`Д´)ﾉ',\n",
       "  'さんたさんありがとーって叫んでるわ',\n",
       "  '[USR] あまり母さん寄りな人格形成は諸問題の種ですから、そこでおとんの出番ですよ！',\n",
       "  '[USR] おはヨークシャテリア！よき一日を！',\n",
       "  '私も2人を乗せて自分はおりるって考えたな。選べないし、どっちにしても失ったら喪失感でどうにかなる。残ったものの悲しみは考えてない。自分のため、か。',\n",
       "  '毎朝このくらいゆっくりできればいいのにな。家が遠いからしょうがない',\n",
       "  'この研究者、イケてるなぁ。 #NHK',\n",
       "  'Σ(ﾟдﾟ;) 北京生まれじゃない RT [USR] 北京ダックは今は要らないよ。 RT [USR] 呼んだ？RT [USR] [USR] うん。あひる殿もふくめてミッシェルなTLになりがちですｗ',\n",
       "  'なんだか痒いのでこすりたくなりますねー。。RT [USR] [USR] おめでとうございます！こすらないようにお気を付け、ですねー。',\n",
       "  'ウチのママンは勝間和代がテレビに出る度「残念なひとだ、美人なのに残念なひとだ」と言うけれど、その件について深く突っ込むと黙ってしまうので気になって仕方ない。',\n",
       "  '筋トレ革命って人からフォローされてる...私、ナニモノ...',\n",
       "  '[USR] おはようございますっ！いってらっしゃいませ～！',\n",
       "  'RT [USR] RT : RT  北川景子を抱くぐらいなら、横山健に抱かれたい。',\n",
       "  '今日じゅうに2010年の目標立てる！15時になったら本気出す！',\n",
       "  'ハーゲンダッツ食べたい。高いやつ。',\n",
       "  'Now Playing: \"turn around\" from \"world symphony - Single\" (ACIDMAN) やっぱりsecond lineだと全然意味の印象も違う',\n",
       "  '弁論なら負けませんよ。RT [USR] ちょっと酒を飲みながらじっくりと話しあう必要が有りますね… RT [USR] その通りじゃん！！！RT [USR] いつも飲んでるような言い方だな！ RT [USR] いつも通り飲めばいいじゃない',\n",
       "  'そういえば、もう7年ぐらいカレーを作っていないかも。',\n",
       "  'おかんに「明日帰るかも」ってメールしたら、「仕事は？」と返ってきた。おいおい、この前言ったけど？',\n",
       "  'ついつい落書きしてみるものの、載せずに終わるのであった。',\n",
       "  '[USR] 春コートはまだ早いと思われます',\n",
       "  'WALKING IN THE RHYTHM/FISHMANS:UA。ちゃんとFISHMANS聴いてみたい。',\n",
       "  'ぐるなびの人みたいに頭使って一攫千金を狙ってみたり。世の中のニーズをうまく汲み取って、穴場を実現させれば、うまくいったりしないかな。',\n",
       "  'カナディアンロッキーもいいなぁ。',\n",
       "  '前盗られたから、コンビニでもずぶ濡れのまま持ち込むことにしてる。申し訳ないけど、仕方ない。RT [USR] これ本当窃盗罪だって認識して欲しいよね。 RT [USR] 人の傘持ってくやつふざけんなよまじで。汚い傘おいてくんじゃねぇ',\n",
       "  '先生！その話は8年前から聞いていますｗw      QT [USR] 俺、生で猪苗代、本気で計画しようと思ってるんだ。エアリアルとモーグル観戦。RT [USR] 福島物産展に突入しなくては！',\n",
       "  '[USR] いいですよね、SAKEROCK。そして星野くん、リーダー。映画では頼りなさそうだったのにw',\n",
       "  '[USR] おはようございまっす！',\n",
       "  '[USR] ちょｗどこの相撲部屋ｗｗ',\n",
       "  'そのつっこみΣ(ﾟдﾟ;)RT [USR] バスルームにルージュの伝言...掃除が大変そう。 #nowplaying ルージュの伝言 ♪ 荒井由実 [URL] via [USR]',\n",
       "  'まち針の先端のようにつぶらな目！wRT [USR] ああ、千葉くんのじっとりワルな感じは爬虫類、しかし目はまち針の先端のようにつぶらなんだな、そうだな！今気づいたよ！ ハムスターの目と同質だな！ RT [USR] ばーすでのカレンダーガールを観ながら手拍子するな',\n",
       "  '営業の女の人が、電話で「アハハハハ、アハハハハ」と高い声で言ってるのを聞いてニヤニヤする午前11時半。',\n",
       "  '[USR] 海悠さんのおしのびどせいさんがサンタ帽子に見える件。',\n",
       "  '大晦日朝ではあるが、NHK総合では清志郎番組やってる。でもって観る！\\u3000#nhk',\n",
       "  '東京に戻ってきた！暖かいな…',\n",
       "  'ブログ書きたい。あいぽんで投稿しやすいところに変えようかな…。でも、メール使えば今でもカンタンに投稿できる。',\n",
       "  '花園神社は花園神社で、酔っぱらいウェルカムな雰囲気や、見世物小屋とかまがまがしさがまた好いのだよなぁ。',\n",
       "  'またおっさんの昔ばなしはじまった．．．今日3回目。キレそうなのを抑えて、ヘッドホンして仕事しよ。',\n",
       "  '除湿器を買いました。凄い効果に感動！\\u3000これです\\u3000[URL]',\n",
       "  '無縁社会は嫌、だからと言って血縁を引き寄せたら善き結果になるかと言えはそうでもないとゆー事例。せつないね。 #nhk',\n",
       "  'ラーメン食べ終わったなう。イオン宇品。もうすぐアクタスに。',\n",
       "  '[USR] まだ逃してないけど、気持ち悪い',\n",
       "  'そっか。最低だ。RT [USR] 牛フンだからねぇ… RT [USR] bullよりbullshitのほうが最低な感じ？',\n",
       "  'RT [USR] 11/09 09:18 山手線［品川－］止まっている   埼京線、山手線共にドアコックにて車外にでた者があわせて数十名いる模様。全ての者の安全確認が取れるまで相当時間がかかるとのこと。各社、...',\n",
       "  'き、着たほうがいいのかな...RT [USR] (´･ω･`) RT [USR] ロリィタ着ないし！RT [USR] [USR] ロリィタ服を着たくなったら [USR] に連絡とるといいよ',\n",
       "  'がなりまくりわれまくりだれてはないRT [USR] がなるわれるだれるからいいんだお。。RT [USR] やっぱりそうなのかな。スピーカーもよくないし。RT [USR] 圧縮のせい？RT [USR] iTunesに取り込んだ音は割れるのにCD直',\n",
       "  '[USR] 病院に県民の日って関係あるの？っつかそこまで来たらよれよ！',\n",
       "  '[USR] 寒いかもw家はありません、寝袋で寝てます、だったらアグレッシブな人だなぁ。かっこいいw',\n",
       "  '無印の湯たんぽカバーかわいいよ。持ってないけど。',\n",
       "  'Now playing  on iTunes : \"1/fの感触\" from \"Inspiration is DEAD\" (凛として時雨)',\n",
       "  'おはようございます 今日は採血される＞＜血が足りぬ',\n",
       "  '[USR] 一生会わなくても大事な人ってこと？',\n",
       "  '[USR] いや、そんなに深刻じゃないけどね。師走だからだ。',\n",
       "  'RT [USR] 誰かと人生ゲームをやりたくなってきた。',\n",
       "  '[USR] そっちじゃなくて、ガンダムのうたw',\n",
       "  '[USR] ああ！素敵ですね。まだまだ5時は暗くて寒いでしょうに。よいお話を有り難うございます。',\n",
       "  'Excel2007になってデータベース機能が充実したけど、微妙にAccessしかできないコトあって悩むわい。いっそ統合してくれないかな．．．',\n",
       "  'うどん食べ終わり。帰って仕事…。',\n",
       "  'あれ、マリリン出てるの？',\n",
       "  '[USR] こういうニュース見ると将来の子どもの学費はしっかり貯めておかないと、といまからプレッシャーを感じます。',\n",
       "  '買って食べてみて下さいとしか言えないよ～  RT [USR] [USR] うぉ～たべてみたいよ～',\n",
       "  '[USR] おら、若者じゃないのか...',\n",
       "  'クレイアニメ…作ったなー(懐)RT [USR] ついにあの文字キャラが動き出してます！RT [USR] す、すごい！とおる君のクレイアニメ、感動！ありがとうございます。[URL]',\n",
       "  'ツタヤまでぽんこつのかわりのヘッドホンでお散歩。いろいろ仕入れてくる。仕事行かなくなってから金遣いが荒いなぁ。危険だなぁ。',\n",
       "  'RT [USR] 「大切なことは、たくさんのことをし遂げることでも、何もかもをすることではありません。大切なことは、いつでも何に対しても喜んでする気持ちがあるかどうかなのです」 マザーテレサ',\n",
       "  'タイムアウト。このあとQBが交代か？',\n",
       "  '予想通り離職票はまだ届いてませんでした。今更気付きましたが、CATVの工事日をもっと後ろにずらせば、もっとねこと遊んでられたわけです。',\n",
       "  '[USR] 手間暇掛けて行くからいいってのもありますよね～',\n",
       "  'うまい！！RT [USR] ！！！RT [USR] 目玉焼きとかけて、僕の恋心とときます。その心は「真ん中にきみがいる」 RT [USR] むむむ、難しいぞ。目玉焼きとRT [USR] [USR] 目玉焼きとなにかをかけなさい',\n",
       "  'これをパンに塗るのは、お好み焼きをおかずに白米食べるのに近いものがありますねｗ QT [USR] あ、ちょっと美味しそう RT [USR] お米のジャム。いろいろ。 [URL]',\n",
       "  '横断歩道は歩行者優先だ！とまれ！',\n",
       "  'ちょｗ RT [USR] おお、鳥公、ごめんよう。（仲なおり）\\u3000寸劇おわり',\n",
       "  'もう、昼休みを取るタイミングのことで頭がいっぱいｗ',\n",
       "  '高校の時、友達が言っとった。 RT [USR] なにその黄金差率RT [USR] 身長差は、15cmが一番目が綺麗に見えるらしいぜ。',\n",
       "  'ちょっとシーメーしてきます。',\n",
       "  '[USR] この時間に会社戻りですか！ご苦労様です。',\n",
       "  '[USR] そうそう、メールのドメイン違うね。ずっと使ってるからもう替えられないだけ、そうなんだ。',\n",
       "  'ロビーに独り言しつつチラシをものすごい勢いで漁っているおねいさんがいて怖い。',\n",
       "  'ゆうたん、おっさん疑惑。',\n",
       "  '[URL] - 昼間の国会議事堂を久しぶりに見た',\n",
       "  '[USR] 幼稚園の女の子に勝ったんだ♪',\n",
       "  'ちょｗwｗこれは啜れない！【超幅広うどん人気、Ａ４サイズも\\u3000桐生のめん処】\\u3000[URL]',\n",
       "  'Now Playing: \"海原の月\" from \"The Best 03\\'〜09\\' [Disc 1]\" (安藤裕子) やばい！熱唱！',\n",
       "  '[USR] いい結果が出るといいね！ところで、エージェントとか使ってるんですか？',\n",
       "  '[USR] ドラえもんってシュールですよね。',\n",
       "  '3mLANケーブル買ったから、ソファーでネットできる。500円で幸せ。わーい。（無線LANは仕事が決まるまで我慢します。）',\n",
       "  '[USR] う～ん。マリオも抜け毛を気にしているのか…',\n",
       "  '今ごろ遅いレスになっちゃいました…。両方見れたら便利やのに…。 RT [USR] [USR] ありますね（爆）どっちにつぶやいたか忘れて、レス放置して失礼こいたこと多数（笑）',\n",
       "  '後なんだっけな・・・・。',\n",
       "  'RT [USR] 【サンデーホリデーの日，半ドンの日,財布の日,モスの日,スイーツの日,聖グレゴリウスの祝日,独立記念日 [モーリシャス],菜の花忌】[URL]',\n",
       "  'なんじゃこりゃ！？ QT [USR] ネタ鳥： \"「こんなPostに要注意！？\\u3000結婚相手にふさわしくない男性Twitterユーザーを見分ける5つのポイント」   ...\" - “ 「こんなPostに要注意！？\\u3000結婚相.. → [URL]',\n",
       "  'すごい！ちゃんと届くんですね！ QT [USR] シャトルが運んできてくれた胡瓜と檸檬が、涙が出るほどうまい。どっちも丸かじりです。',\n",
       "  'ほえ～。外仕事で身体が冷えた。もう午前中は流し気味に仕事する。',\n",
       "  'バスセンターのエスカレーターでおじさんが転げ落ちた。',\n",
       "  'ジャッジがどうとかもういいよ。とにかくイイもん見せてもらった。キムヨナも真央もお疲れさん。',\n",
       "  'なん...だと！？行かねば！ QT [USR] 池袋東武でやってる大鹿児島展の丸ぼうろ、もかもかうまい。',\n",
       "  '[USR] （ビジネスなのか...）',\n",
       "  'RT [USR] たぶん書籍の編集者は、質の高い出版物を完成させることに意識があるはずだろう。けど、ネットは違うんだよなあ。ネットが質が低いというわけではなく、作りながら改善していくというサイクルができていない。',\n",
       "  '年始のあいさつくれた人に、そろそろ返事しないといけないと思う、今日このごろ。（実家に帰ってて見てないという設定）',\n",
       "  'なんだかんだついった昼間っからやってることにも焦るよな。',\n",
       "  '電車の外に寄り掛かってる女が相当酔ってると見られる。電車止めるなよ。',\n",
       "  '帰宅。twitter開始',\n",
       "  '[USR] ほー、東京に出て行く大学進学への理由、それだけの大学数があれば、成立しそうな感じですね。ありがとうございます!!1',\n",
       "  '[USR] なんか、酔っぱらってわけもわからず勢いで、安くもなってない、クリスマス仕様でもない、普段からあるケーキを買ってしまった...激しく後悔なう。',\n",
       "  '[USR] アイコンｗｗｗなんかもう感動的だな☆彡',\n",
       "  '[USR] おかん、おめでとうございます！',\n",
       "  '刻め！RT [USR] Now Playing: \"スネークフィンガー\" from \"KARATEKA\" (電気グルーヴ)＜チームマイナス6にささぐ。やせないやせないやせないよーそんだけたべてりゃやせないよ！',\n",
       "  '間違えた、B判定だった。',\n",
       "  'ごめん、失敗した… RT [USR] 飲みすぎに注意とあれほど… RT [USR] 警察署なう。',\n",
       "  'ちょっとみどりの窓口行ってくる。RT [USR] 相変わらず、新潟の女子高生のスカートは短い。群馬より明らかに寒いだろうに…何なのだ？',\n",
       "  'すげ、時間かぶってるw',\n",
       "  'また民生使うなら、チバにも歌わせて！ヒロトにも。スカパラ。',\n",
       "  'ファシーのポテンシャルwwRT [USR] パッと見は高い。だが、そこに秘められたポテンシャルは、土鍋のそれを凌駕すると言えよう。RT [USR] ファシー、安いんでしょうか？RT [USR] ここにもファシー予備軍がw',\n",
       "  '[USR] ひでさん、おかえりー',\n",
       "  '俺もさり気に腹減ってきたなう。',\n",
       "  '[USR] なるほど。チバぐらい、めもめも。',\n",
       "  '木村カエラはもうベスト出すのかよっ、と思ったが倖田來未は10年目で3枚目のベストアルバムを出すらしい．．．',\n",
       "  'あ、明子姐さんのドキュメンタリーやってる！ #nhk',\n",
       "  '祭りに参加してみたｗ 18禁大好きな人フォローミー #followmeJP #followme #sougofollow',\n",
       "  'さて、高校サッカー前橋育英戦の生放送がないので出かけてくるか。競輪やってる群テレ爆発しろ。',\n",
       "  '[USR] 前の会社で仲良かった人がそろそろ辞めようとしてて、元上司がこの前仕事決まって、仕事の話してきたいんだ。追加は、この前の意味わからない人ね。',\n",
       "  '[USR] あれ、ジョークじゃないの？取り締まれないと思うよ、すべてのブログとすべてのついったーとWeb全部なんて。JASRAC、前は曲の一部ならいいって言ってたんだ。',\n",
       "  'ペン忘れた…何死に来たの、ここに。',\n",
       "  'RT [USR] 大木「すぐさまフロントに電話して『ゴキブリが出たんで部屋替えてください！』」(2回目)',\n",
       "  'ジブリ美術館は外からしかのぞいたことない。',\n",
       "  '月曜から寝れるようになった。寝つきも早いし、夜中に起きることもない。ストレスの影響ってでかいんだな。',\n",
       "  '右に同じく。RT [USR] 朕はほろ酔いである。',\n",
       "  '[USR] 30分前だ！おやすみー',\n",
       "  '変な人じゃないよ...',\n",
       "  '2時2分は無理だったからせめて2時に自動ポスト。',\n",
       "  '社長のの濡れない発言キタ！ｗ',\n",
       "  '[USR] おー、真面目な彼氏で安心だね。ところで、土曜あたり歌ってみる？',\n",
       "  'うちは給料日の次の水曜なので毎週水曜にしようかと(笑) RT [USR] [USR] うちも水曜はノー残業デーですー',\n",
       "  '[USR] や、意味がよく分からないんですけど(ﾟνﾟ)ﾆﾎﾝｺﾞﾑｽﾞｶｽｨﾈｰ',\n",
       "  \"I'm at 三島駅 (一番町16-1, 三島市). [URL]\",\n",
       "  'んでも、私の臓器なんか体に入れたら、おっちょこになるかもな。かわいそうに。',\n",
       "  'オランダ？！ #wcdrawjp',\n",
       "  'てかPS3の設定がうまくいってなくてムービー部分の声がずっと出てなかったっていうね＾＾説明書読んで解決したのでまあやたんの声いっぱい聞けてしあわせ',\n",
       "  'もう1回、日付まで確認した！ RT [USR] うんうん、こわいよー！\\u3000ちゃんとあるね？\\u3000ね？ [USR]    [USR] こわいよね！なかったら泣く！',\n",
       "  'シュヴァンクマイエルのアリスもいいよ。異色だけど。RT [USR] ありすありすRT [USR] ティム・バートンアリスにそなえてダラス・バウアーのアリスを観るなどする。かわいい！  [URL]',\n",
       "  '元気があれば子供もできる！できる！RT [USR] おはよーございますっ！元気ですかっ！！[USR] [USR] [USR] [USR] [USR] [USR] [USR] [USR]',\n",
       "  '遅くなりすいません。今夜お願いしまっす♪RT [USR] [USR] お初、コメントでございます♪色々活性化されていて楽しいですね！',\n",
       "  'WebでTwitterしてるとフォロワー数が目に入るからこわいね。キレpostでは減らなかったけど、落ち着いてきたら減ったぞ。',\n",
       "  '（そんな説明...）RT [USR] あひるさんはACIDMANとちばゆうすけが好きなジャイアンです。。RT [USR] や、断片的にみえるツイートからむっちゃ気になってて、あひるさん…笑 RT [USR] ほんものっていわれてる。w RT [USR] わあ、の',\n",
       "  '飲んでるかー？RT [USR] 中島みゆきタイムに突入した俺は強いぜ…（酒に）',\n",
       "  '佐藤浩市が主演の『官僚たちの夏』のＤＶＤ－ＢＯＸをアマゾンで注文した。いま官僚が話題だからタイムリーだし面白ろそうだ♪',\n",
       "  '[USR] おはようございます！枕元にあいぽん状態です！',\n",
       "  '[USR] 今年のCDJにもバスデ出るよ。私もテント一人でできるかも...ホテルまで戻るのが面倒な無精者です。',\n",
       "  '目が疲れてるんじゃない、体がだるいんじゃない、顔から変な脂が出て目がしょぼしょぼしてただけだった!!1\\u3000洗顔により一気に回復。アラフォー',\n",
       "  '[USR] はい。価値観はそれぞれでいいと思います。単純にアスリートとして見てあげたいのです。',\n",
       "  'これいきなり見た人にリムられるかなぁ。',\n",
       "  '[USR] 三日位続いてしまいそうです＾＾；',\n",
       "  '[USR] 温かくして行ってくださいね。',\n",
       "  '今日の断裁でカッター強く握って指つかれた。ハレパネ切るのきっつい。今日は急遽友人と地元イベントに行くことになったから、お昼までのTL読んで寝る。',\n",
       "  '美少年。RT [USR] 自分のアイコンがきもい。',\n",
       "  'さてこれからどうするか… 一人カラオケ入って戦利品読もうかな～いかに金を使わないように過ごすか考える せちがらい月末＞＜',\n",
       "  '[USR] 今からでかけようかとw',\n",
       "  '牛さんって美味しいね。しみじみ。',\n",
       "  '. [USR] [USR] [USR] [USR] 昨夜はおやすみありがとうでした～！',\n",
       "  '[USR] そうなんです。サッカーも変わりそう。',\n",
       "  '[USR] なるほどｗｗｗすばせか好きさんがついったに増えてうれしいです(´ω｀*)',\n",
       "  '[USR] 歌詞botにももだもだしますねw これでもかなり抑えてるww',\n",
       "  'ワインで暖をとるなど。',\n",
       "  '[USR] [USR] [USR] おかありでしただいまー！',\n",
       "  '『とべないほたる』っていう演劇を。障がい者教育でも使われてる 絵本の題材だな [URL]',\n",
       "  'ごめん、赤いモヒカンだと思ってた。 RT [USR] MAJIDE？！巻いて盛ってる感じではないんか？！RT [USR] ごめんオレもパッツパツのイメージです。 RT [USR] まじか！？そんな臭いどこにも出してへんぞ！！',\n",
       "  '萌え死ぬかと思った！ぐはぁ！ QT [USR] うちの愛娘、最新写真。この子と触れ合ってるときがたぶん1番幸せ～(-U-`* [URL]',\n",
       "  '野菜が届いたら長崎サラダを作ろう。',\n",
       "  '年賀状にコンセントにささったエレキッドを入れようとおもったけど、入れづらいからやめた。',\n",
       "  'かっこいいよね！RT [USR] これ好き♪ RT [USR] Now Playing: \"いばらの冠 [Buffalo Daughter mix]\" from \"vague\" (中谷美紀) Buffalo Daughter mixかっこよすぎる。',\n",
       "  'ネスの レベルが\\u3000９７になった！',\n",
       "  '行ってもた...文字入力なれないと難しいね',\n",
       "  '[USR] うん、ばっちり録画した！w',\n",
       "  '[USR] おはよう。こっちは弱い雨で寒くて、うちは結露してる（結露は関係ない...）',\n",
       "  '[USR] えっ、そんな人気？カーキありますか？ QT: [USR] エディバウアーなう(笑)緑のコート、無くなっちゃうよ！',\n",
       "  '[USR] 先生！海苔がえらいことになってしまいますッｗｗｗ',\n",
       "  'テナーとAus、途中ACIDMANのクリップはさみながら全部聴いた。いい夜だ。',\n",
       "  'Listening to  - John Lennon ／Instant Karma! (We All Shine On) [2003 Mix]／Working Class Hero - The Definitive Lennon',\n",
       "  '放流なう。そして渋谷はポツリと雨が。',\n",
       "  '飛んでいきたいぜ！RT [USR] 物投げずにオマエが飛んでこい！！',\n",
       "  '[USR] それは、連休モードから社会復帰できなかったパターンだったり？（汗',\n",
       "  '[USR] ぱっちりじゃないよ、会社で毎日眠そうにしてた時にガチャピンって言われたんだ。高校の時は河相我門に似てたらしい。',\n",
       "  'ちょっと出遅れたけど、初めてちゃんとナウシカを見てみようと思います。',\n",
       "  '[USR] それさ、ゆうたんにも聞いたんだけどみんな、あひる＜白鳥、が美しいと思ってるわけだよね。私あひるなのにさ。',\n",
       "  'えっ！？RT [USR] ちょろっとしらべたら、素敵イベント過ぎて、入場無理そうだ…。',\n",
       "  'RT [USR] 高校の頃は看護師サンが好きでした。5歳年上の。',\n",
       "  '[USR] あ、ごめん&gt;&lt; でもそういう気持ちなんです…',\n",
       "  'Now Playing: \"シンプルストーリー(second line)\" from \"プリズムの夜 - EP\" (ACIDMAN) このジャジーな感じ、めちゃくちゃかっこいい！',\n",
       "  'スーパーカーなう（スペシャ）。',\n",
       "  'TL、酒飲みばっかだ。',\n",
       "  'いろいろあるんでしょうね…(・ω・｀)RT [USR] (;つД｀)ううっ…。 RT [USR] ついに来るべきものが来てしまったのか... SAWA活動停止: [URL]',\n",
       "  'こんな味だったっけなー RT [USR] ジャンジャーエール買ってー飲んだあー\\u3000RT [USR] フレッシュネスのチーズバーガー食べた。こんな味だったけな。',\n",
       "  '音声入力、大寒は変換できなかったなぁ。ここは自力で変換しないとダメか。',\n",
       "  '[USR] 同姓してるカップルも同じだよね。だんだん減るもんだ。でもたまには雰囲気変えてみるのもいいかも。',\n",
       "  'おおお！この「やりきった！」って表情が素敵！ゲデ子！',\n",
       "  '[USR] ＵＳＡ版のWiiっすね～',\n",
       "  '今夜は牡蠣TLになってるｗ',\n",
       "  '[USR] あと、ケータイからやったら、モバツイッターってページのほうが使いやすいかもしれん。',\n",
       "  'ううっ、プレッシャー！w RT [USR] うおおお、期待してます！ RT [USR] がんばってpost、じゃないな。ガンガンpostだな(ﾌﾌﾌ',\n",
       "  '[USR] 7割引以上なら買って正解じゃない！',\n",
       "  'ふろった。パソコンけしてしまった…。そしてうっかりMOTHER2を起動してギーグ倒しに向かってるなう。3でもないのに、リズミカルにボタンを押してしまう。',\n",
       "  '[USR] さくらさんとがあこさんです！',\n",
       "  'RT [USR] ふとダジャレを言いたい、けどブログやミクシの日記に書いても反応されない、誰かにメールしても返事がない。けどtwitterは晒しRTなどで反応してくれたりする。こんなにうれしいことはない…',\n",
       "  'そうですね、お騒がせしました。 RT [USR] あの時は大変だったよこちらはwRT [USR] ドラえもんシリーズの時ですね、わかります。 RT [USR] [USR] あひる&さくらんは一時、どっちやねん！！てなったからw',\n",
       "  '勝間女史のスタイリングに吹いた！',\n",
       "  'あふれかえるパスタの山、終わったなう。',\n",
       "  'おっ、ＮＦＬ、イーグルスＶＳベアーズはじまるな。しかしＰＣに３時間も貼りついてられないので出かけるのです。',\n",
       "  '[USR] 赤ん坊に早朝起こされたついでなので、たまたまです。忘れて弁当買いそうになりましたｗ',\n",
       "  '[USR] ジャケットの写真見たら見たことなかったから、最初から持ってなかったのかも...',\n",
       "  'マーティー・フリードマンかよっ！',\n",
       "  '林檎の樹の店内も田舎風ってゆうか山小屋ちっくで洒落てますな [URL]',\n",
       "  '今日から薬漬けにする。もう我慢ならん。',\n",
       "  '[USR] ありがとー！かんぱーい！！！',\n",
       "  'あと半日ご奉仕すれば、また休みか。テンション上がってきた！[USR] おはありです！',\n",
       "  'Now Playing: \"cps\" from \"equal\" (ACIDMAN) そろそろACIDMANタイムは終わろう。キリがない。',\n",
       "  'せっかくの円高なのでドルを大量に買うか、海外にでも行ってみるか、通販でちょこっと得するか考えちう。',\n",
       "  '[USR] おはようございます！よき一日でありますよう！',\n",
       "  'lListening to  - Caetano Veloso ／Queixa／Brazil Classics 1: Beleza Tropica',\n",
       "  '地図の旅は、某K国で目当てのものが見つけられなかったため、万里の長城を突っ切り、ロシアに入ります。',\n",
       "  'やっぱりウェア取りに帰って、走ろう。走ろう。そして飲む。飲む。飲む。',\n",
       "  '追悼に前田のクラッカー食べる！',\n",
       "  '実在テラキボンヌ！  歯垢削りの激痛がいくらかましに（爆）  RT [USR] 昼食後、歯を磨いていたら、ふと「巨乳歯科衛生士」という言葉が頭をよぎる',\n",
       "  '過去は捨てたらどうだい。',\n",
       "  '読書メーターとかあるんだ [[URL] ]',\n",
       "  '「優し過ぎる世界に気付けなくて、また此処に来て、悲しみに目を閉じて 戻れない 一人きり、嘘に変わるまで」',\n",
       "  '修造、わかったよ！頑張るよ！ RT [USR] [USR] もっと大きく！ 一体どれだけ努力すればよいかという人があるが、 君は人生を何だと思うかと反問したい。努力して創造していく間こそ人生なんだから！',\n",
       "  'もういい、ヤフオク今日は諦めた。きーっ！',\n",
       "  '[USR] でもケーキもデザートもないんだ。あるのはアラポテトとカマンベールチーズのみ。チーズチーズ！これをリア充と呼ばず、何と呼ぶ！？',\n",
       "  '[USR] 今夜クリスマス会の家庭も多いようですね。立駐出るのに15分以上かかった．．．',\n",
       "  '.[USR] 大変なこともあるけど、あひるはいつも元気です（魔女宅より）。ありがとう！',\n",
       "  '19時の回に見たー！RT [USR] あひゃひゃー中村くーん！ [URL]',\n",
       "  'かなり酒がまわってきたので、適当なpostがどんどん増えていきます。',\n",
       "  'おはよ～。眠い～。寒い～。おなかいっぱい(^ .^)y-~~~',\n",
       "  'そのまんまやったんすね(・・;)氷雨とか酔っぱらちゃったとかイロイロ試してました… RT [USR] [USR] まんま「お久しぶりね～」',\n",
       "  'しまった！今月は28日までしかないことに改めて気付いた！！！',\n",
       "  '[USR] たけると瀧がふたり転がってたらどうする。',\n",
       "  'ロキノンの新フェスは春ですか。GWあたりにやるのかな？群馬で開催しても構わないYO！[URL]',\n",
       "  'よし！そろそろＢＡＲに顔出してきます♪\\u3000試験的に今日は”ツイッター見たよ”で２０％ＯＦＦの実験を★\\u3000お店はコチラです ⇒ [URL]',\n",
       "  '私・・・記憶なくさなくなったわ。。大人になったのかな♪',\n",
       "  '. [USR] [USR] [USR] おはよう！今度晴れた時にでもじっくり眺めてみまっす♪',\n",
       "  'ただいま～( ´ ▽ ` )ﾉ',\n",
       "  'Now Playing: \"Private Laghter\" from \"Every Single Day-Complete BONNIE PINK(1995-2006) [Disc 2]\" (Bonnie Pink) 恋人に望むこと\\u3000make me laugh',\n",
       "  '二つあったらそりゃ、一度はやりたくなる。 [URL]',\n",
       "  '[USR] やっぱ喜んでたわ。本人の希望第一よね。お着替え袋はかわいいの勝ったけど。',\n",
       "  '[USR] ハートで感じてみてw',\n",
       "  '[USR] そんなぁ｡･ﾟﾟ(ﾉД`)',\n",
       "  '[USR] うんまじ大人たちに感動した！伝子さんもすごかった… DVD化するといいな＞＜',\n",
       "  '夕方の記者会見の原稿が上がったー！\\u3000はふはふう',\n",
       "  'PTAとか、誰も元ネタ解らねえよw しかし、くるり見るまでは、寝れないかな…[USR]',\n",
       "  '[USR] こんはんは☆ お出かけ？',\n",
       "  '受診終了。特に異常なし。[USR] いってらありでした。',\n",
       "  '今日はココでご飯 mogu2 したよ [[URL] ]',\n",
       "  '[USR] ずっと木星人だと思ってたけど、今調べたら天王星人だった。霊合星人には当てはまってないみたい。霊合星人ってすごいの？（射手座が木星とかそんなだったのかな...）',\n",
       "  '[USR] ちなみに 2006 年頃に僕が作っていたギャルサー関連のページは次の URL です。 [[URL] ] 当時、一番大きかったサークルがアンジェリークで、ちょっと今の状況までは把握してません、ご参考までにどうぞー',\n",
       "  'ハネコマさんのエントリー料が情熱とか…なにそれ萌える',\n",
       "  '[USR] 数字増やしたいのかなぁ。',\n",
       "  '[USR] 1時間も走ったんですか。おつかれさまー',\n",
       "  '[USR] ゆうたん迷走中。理不尽な社会のことわかってる人なら大丈夫。ふうてんのあひるもなかなか社会に受け入れられませんが、好きでやってるから仕方ない。',\n",
       "  '今日は赤ん坊のハーフバースデー。仕事片付いたら、直帰しようかプール寄ろうか悩む．．．',\n",
       "  'これはセーフだ。RT [USR] 鶏ガラスープgokgok RT [USR] (つД`) RT [USR] あぁ！があこたん！あひるたん！ RT [USR] つい女子間で流行ってるのかなトリ。唐揚げmogmog RT [USR] 強烈な',\n",
       "  '[USR] おはようさんでござる♪',\n",
       "  '.[USR]  メンタルヘルスについてはネットの普及で一気に情報が得られ、横の繋がりが出来たことは有難いです。通院の敷居が下がったのはその辺にも要因がらあると思います。ただ、逆にネット環境から遠い人が未だに苦しんでいるのかなと。今や統失の簡易診断テストさえありますから。',\n",
       "  'わかります。 RT [USR] かなり昔のリプライとかPOSTにうまい返しを思いついた時のもどかしさ…',\n",
       "  '晴れてるけど今日は寒いね。おはよう。',\n",
       "  '今､世界は音を立てずに止まり この空を継ぐ者達に告げる',\n",
       "  '幸せのはじまり。 QT [USR] しばいぬを撫でてごらんよ。',\n",
       "  'ありがとう！★  RT [USR] 渋谷。RT\\xa0[USR]\\xa0【RT希望】ツイッター見たよ！と言ってもらえると、バーすがはらオリジナルカクテル本日１杯無料\\xa0[URL]\\xa0#barsugahara',\n",
       "  '意外に、南イギリスなんだよ。もっとスコットランド寄りの田舎だと思ってた。 RT [USR] え。ストーンヘンジってイギリスなの？RT [USR] ワープしてイギリス、ストーンヘンジなう。',\n",
       "  '（じーちゃんがペットボトルに溜めてこぼしまくってて大変だった）RT [USR] 寒いからおしっこにいきたくていきたくてしょうがない。きょうはおまるがほしいくらいだ。',\n",
       "  '軽やかに雲古をひねり出すなど。',\n",
       "  '[USR] おやありー、おはよう！',\n",
       "  'トッテナムとマンチェスター・シティとアストン・ヴィラより順位をあげればいい簡単なお仕事。',\n",
       "  'Σ(ﾟдﾟ;)もう成人式ネタは終わったのに！',\n",
       "  'ネカフェでNARUTOの続き読んだんだけど、おいていかれた気がした…。いつの間にか、初期ですごかった技ぽんぽん出してるんだもの…',\n",
       "  '[USR] そのころまでに説明書も書けるようにがんばりますー！',\n",
       "  'そんな訳で舌下にエチゾラムなう。',\n",
       "  '来月は決算だし，エコカー値引きからの上乗せにさらにどのくらい引いてくれるのか...。ただ，ぶつけたい対抗馬がないんだよね。',\n",
       "  'オーディオテクニカのちっちゃいスピーカー、ちっちゃいくせにやりおる。',\n",
       "  'ブレンダが去り、バレリー登場。今シーズン何なんだろ。',\n",
       "  '.[USR] [USR] [USR] おやありでしたー。',\n",
       "  'ぷ。 RT [USR] ぷ。修造www [URL]',\n",
       "  '[USR] wow! リッチピーボー！ プレミアムモルツウマいよねｗｗ',\n",
       "  'むう、よく寝た。やはり風邪フラグ？',\n",
       "  '青色申告ソフトの入力がようやく完了したようです。これから原稿の仕上げへ',\n",
       "  '[USR] はぐりんさんも良いお年を。夜中の奇跡を！規制ではなくw',\n",
       "  'おおう… RT [USR] [URL] いい天気, コミティア, 天気だ, ボーマス, 洗濯, akb48, 出かけ, ピクマ, 天気が, 掃除',\n",
       "  'お嫁さんいっぱいいるし、ぼっちじゃないし！',\n",
       "  'なんで人生ってセーブポイントないの・・・',\n",
       "  '勾当台公園。iPhoneだと一発変換。iPhoneえらい！',\n",
       "  '閉じ括弧の前に句読点って駄目なんだって… [mb]',\n",
       "  'とりあえず、今日は寝ます！おやすみなさいーのしのし',\n",
       "  '[USR] じゃあにゃんにゃんしよう！',\n",
       "  '[USR] [USR] ねーホント分けてあげたいです\\u30001箱あるもんねｗ\\u3000はーふんとに\\u3000ねー・・・ぽりさくぽりさく',\n",
       "  'いたいけな女子になんたることを｡･ﾟ･(ﾉД｀)･ﾟ･｡ RT [USR] バーカ\\u3000バーカ( ・∀・)キャー( ・∀・)キャー RT [USR] ヘッドフォンしてると見事に外の音が聞こえない。ばかといわれても、聞こえない( ・∀・)キャー( ・∀・)キャー',\n",
       "  '[USR] 「２月から出演を控えます。復帰するかも含めて、先は未定です。」理由も不明らしい。',\n",
       "  '[USR] わっきー！どうやらお仕事大変そうだけどwwでも世界一の祭典に関われるのはきっと楽しい！応援してます！',\n",
       "  'RT [USR] RT [USR] 壊れるほど愛するから1/3も伝わらないんじゃないのかな。',\n",
       "  'RT [USR] 11種類の野菜だったのか！ RT [USR] ★kogure : 「天下一品」こってりスープの謎が明かされる！？ [URL]',\n",
       "  '本田直之さん、出てますな～。 NHK',\n",
       "  '中外選択が無い変わりに中の後絶対ぶっかけるから問題ないな',\n",
       "  '[USR] あぁ、たしかにカタカナにするとそんな感じかもですねwww わたしはなんか英語耳っぽくて…',\n",
       "  '[USR] 昼からすごいっすねｗ',\n",
       "  'ばれんたいんでーに、いぬみみロリ娘がリボン巻いてやってくる           という妄想。',\n",
       "  '緑目萌え。灰色がかってても萌え [mb]',\n",
       "  '……日付・時刻は相対時刻でなく標準時，また受ける時刻は発か着かは書いてないと宜しくない．',\n",
       "  '[USR] どうしてそう、潰し合おうとするのですか？アガペーですよ、お兄さん。',\n",
       "  '[USR] これは見覚えないねぇ．',\n",
       "  '[USR] だしょだしょー！困ったわよ。私も父上は、死ぬまで、パパだった。。パパのバースデーだ！今日☆',\n",
       "  'ツイッターの「つぶやき」監視\\u3000夫の浮気突き止める\\u3000[URL]',\n",
       "  'とりあえず、午前中にやらないといけないことは終了',\n",
       "  '[USR] おかえりこんばんわんです！',\n",
       "  '[USR] そーれーだー！！！！( ﾟДﾟ)ﾊｯ すみません長々とお付き合いさせて；；；；；；；； [mb]',\n",
       "  '幼女botのフォロワ増加ペースが6.7人/日とかそこそこ凄い',\n",
       "  'AT_Personaさんの「徹夜耐久度」は、46%です。 [URL]',\n",
       "  '【速報】\\u3000【押尾容疑者逮捕】ＭＤＭＡを譲渡容疑で押尾容疑者ら３人を逮捕 - MSN産経ニュース [URL]',\n",
       "  'RT [USR] RT [USR] 勝間さんの本、レビューが炎上！ [URL]',\n",
       "  '[USR] 参加したくないって、そんなプロジェクト。',\n",
       "  'あったかいので目的地まで歩きましょぃ',\n",
       "  'デザートが先でもアイスならおｋ',\n",
       "  '[USR] ところが紆余曲折あって量産住宅会社のインハウスデザイナーになったこともw （えー',\n",
       "  '甲府懐かしいです！むかしよく観光で行っていました。お写真から拝察するに、駅舎も改装が進んだのでしょうか？ RT [USR] [URL] - 甲府駅。やや明るくなってきた',\n",
       "  'ほしい\\u3000Amazon.co.jp： ムダヅモ無き改革&lt;デラックス版&gt; [DVD]: 水島努, 小泉ジュンイチロー:森川智之, タイゾー:福山 潤, ゆかりタン:伊藤静, 麻生タロー:有本欽隆, パパブッシュ:玄田哲章: DVD\\u3000\\u3000[URL]',\n",
       "  '[USR] うんうん。分かってないって言うか、内輪だけでやりたいんならはじめからそうしとけばよかったんだよ。内輪だけって書いといてさ。ちょっとでも公にしちゃったんならそこはわきまえないと。',\n",
       "  'それにしても、だいぶフリック入力になれますた！(・∀・)',\n",
       "  '[USR] わぁ！調べてくれてたんや？！かんどー（T T)ｴｴﾋﾄﾔ\\u3000ｻｽｶﾞﾒﾄﾛﾉﾀﾂｼﾞﾝﾔ\\u3000ありやとありやとw\\u3000なんとかしますー\\u3000ごめんね\\u3000夜遅いのに',\n",
       "  'うう、おなかすいた…夕ご飯TLじゅる',\n",
       "  '[USR] あ。もぅ、すぎちゃってたのかぁ。',\n",
       "  'RT [USR] RT [USR] 「ローマ時代の彫刻はなんでみんな包茎なの？」と聞かれた。君のお兄さんにぶら下がっている物もそうだよと言いたくなった。',\n",
       "  '長官の目の色まじで好き [mb]',\n",
       "  '五右衛門あいぽん持ってはる',\n",
       "  'サイゾーの過去記事見てたら\\u3000「お嬢様にイタズラして妊娠させた病院長に世論が激怒」という記事が！\\u3000でも（1923年）なんですけどね85年前の話日刊記事にしてどうすんの',\n",
       "  'いかにも砂川らしい景色なう[USR] [URL] [URL]',\n",
       "  '[USR] [USR] [USR] [USR] [USR] [USR] [USR] [USR] :*:゜  お。*゜か。*゜え。*゜り(人´ω｀*)  ありがとう！',\n",
       "  'ふあああフラン可愛いいいなああああ←親馬鹿 [mb]',\n",
       "  '[USR] 飲み出すの早過ぎwww',\n",
       "  '性の教科書は平安時代からあったのかー',\n",
       "  '[USR] おやすみなさいませー。',\n",
       "  'しゃべったー入れてみるかなぁー。',\n",
       "  '駄目だ神の宣告見ただけで発情する…はあっ、はあっ…！ てか贄の石碑トークンてどれの事だ？ [mb]',\n",
       "  '[USR] ( ノﾟДﾟ)おはよ～',\n",
       "  'とはいえ、買い置きってあんまりすきじゃないんだよなあ。',\n",
       "  '都会では品薄なのかなぁ桃ラー．伊東では捜してみたことないがどうだろう．',\n",
       "  'おめ！ RT [USR] ＼7000postおめでとう！／ RT [USR] ＼全ての変態に捧ぐ7000post！／',\n",
       "  'ＴＯＳＨＩ公式ホームページにＨＯＨ側が反論文掲載\\u3000[URL]',\n",
       "  'ネガティブガッガガ [mb]',\n",
       "  '……けど，コント55号がやる以前にもあったよな．知ってたもんな．',\n",
       "  '[USR] あれ、同意が得られない？Σ(･ω･ﾉ)ﾉ！なんだろう、雰囲気！',\n",
       "  '[USR] 分かりにくっw さんきゅー♫',\n",
       "  'バス賑わってるなー。地元路線はドル箱路線なのですよ。練馬南部から中野まで200円で出られるのは本当に助かるもんね。やはり需要はでかい。',\n",
       "  '[USR] おはおー。無事、午前中起床おめっ！',\n",
       "  'デートしてるひとが多いなーと思ったらホワイトデーだったね。わたしにとっては、ただの休日。そりゃ母にも心配されますよ。',\n",
       "  '萌木せんせ絵とがやろたん絵とクドがTL上にいるとそれだけでかなり癒されう',\n",
       "  '[USR] フリル疲れますよね(´・ω・`)',\n",
       "  '[USR] イーゴ・・？え、イーゴってあのイーゴ・・？ 不動さんでも案外可愛いよねぇ・・・。 １５役とか何それ多過ぎるwwwwww',\n",
       "  'RT [USR] 週刊VOCALOIDランキング\\u3000#111 (23:44) [URL]',\n",
       "  \"[USR] 決戦は金曜日(`･ω･´)ｷﾘｯ  だれになんといわれようと、もうさよならするんだからーーーー←これ今年入ってからずっといってるけど。  だれも追ってないって(●′∀｀)σ)'Д`●)ﾌﾟﾆ\",\n",
       "  '[USR] そのレースはいいなぁと思ったけどｗｗｗでそー。そんで、ホログラムPPでハート加工すんのｗｗｗｗ嘘、願望ｗｗｗ',\n",
       "  '[USR] おはようございまー。',\n",
       "  'ゲェエエルトオオオオオオ！！！！！！',\n",
       "  '[USR] ヾ(･ω･`●)ｮﾁｮﾁ',\n",
       "  'おぉー QT [USR] 14時にニコ生集合です。 RT [USR] 14時からニコ生で反対集会の生放送もあるらしい。 #hijituzai',\n",
       "  '[USR] ペンギン腹の某氏の腹を枕に寝ている姿を想像した．',\n",
       "  '[USR] そうだよきさくん。わたしの友人の超あなろぐ子ちゃんに、ついったーのひとと会ってくる♪ていったら、大丈夫？それ出会い系じゃない？っていわれたのだよ(´ー`)',\n",
       "  '[USR] ネタ元らしきところのfollwerがリロードする度に増えたり減ったりしていてオモシロイw',\n",
       "  '昔のメインフレームに使ってた磁気ドラムメモリってマニ車にソックリだよなぁ．',\n",
       "  'いつも馬路村のゆずぽんを買ってきてたんだけど、そろそろなくなるから買い足すかぁと思ってたら、親にトップバリュのポン酢を買われたなど',\n",
       "  'そうか\\u3000リトは草食系男子なんだ',\n",
       "  '長官はやくお嫁にこないかな… [mb]',\n",
       "  '今までさんざん世話になってきた両親には、これからいろいろと恩返ししていこう。ほんと、何不自由なく育ててもらったからね。感謝してもしきれない。',\n",
       "  '雨が酷すぎて流石に今日は外でLOOX U使えないな… 地下鉄までがまん',\n",
       "  'そうだね。RT [USR] 確かに。RT [USR] 最近のAppleの新製品はリーク多いし、それを超えるほどのインパクトにも欠け、結果がっかりなんだけど、今度のはどうだろう？',\n",
       "  'これは誰もが1度やったことがあると思う RT [USR] 何について調べますか\\u3000お前を消す方法',\n",
       "  'この間連続で卑猥っぽいポストしてたらだいぶリムられたけど、まったく気にしてないよ？(´・ω・｀)',\n",
       "  '♪ Listening Now ♪ Cry Baby / Best of SEAMO by SEAMO  #iTwines',\n",
       "  '[USR] しゅっしゃおつですー',\n",
       "  'おめ！RT [USR] おめ！RT [USR] おめ！RT [USR] [USR] フォロワー数 700 番目は多分 [USR] でした。',\n",
       "  'ホームベーカリー使ってるひといますか？&lt;[ﾟ・◡・]&gt;',\n",
       "  'ショタ萌えなんて夢にも思わなかった罠 [mb]',\n",
       "  'ゆりかもめは遅延のようです [URL]',\n",
       "  '何なのこの展開は…それより予告\\u3000天草は山狗だったのか…',\n",
       "  '[USR] 不節制で最近また痩せましたｗｗ寒いし骨出て痛いしいいとこなしですよｗ\\u3000魅力なっすぃんですよｗ',\n",
       "  '[USR] そーですねっｗ\\u3000いま結構頂点きてますｗｗ\\u3000昇天秒読み段階ですｗｗ',\n",
       "  '釜バター #mandegan [URL]',\n",
       "  '彼の言葉が…指が…、私をどんどん綺麗にしてゆく、まるで生まれ変われるかのような気分になる…。美容院なう♪',\n",
       "  'うぉ…メルバンドってなんだ…メタルバンドね',\n",
       "  '【DQ4】わ。トルネコが、人質になっちゃった。パーティからはずれてるから、別にだいじょぶだけど。',\n",
       "  '[USR] 絵画などの平面作品を観る時は，インスタレーションのような三次元作品に較べるといかにも負荷が軽いというか，脳が難しい事やってないな，という感じはしますよね．そのあたりが「人間の知覚に近い構造」と言えるのかな．',\n",
       "  'RT [USR] 期待ヽ( ･∀･)ﾉ↑age↑頑張ってー\\u3000TweetMeに関して頂いたご質問やご要望、ご感想に対する回答 | FLIGHT iPhoneアプリ開発者BLOG [URL]',\n",
       "  '[USR] そうなるということです．「いまさら静岡くんだりの田舎TVなんか観たくねぇ」ということで市民には大変不評です．',\n",
       "  '凶華様全然すすまねぇ･･･',\n",
       "  '.[USR] とりあえず今夜は「ポニョ」を含む文字列をフィルタリングしたが，なかなか漉し切れないw',\n",
       "  '自動車のシーケンシャルシフトもフロアシフトの場合は論議があるよなぁ．「減速Gが掛った時にダウンがフェイルセーフだ」「いや減速時には次の加速に備えてアップでないと」とかなぁ．',\n",
       "  'クランプラーのカメラバッグも欲しいなぁー。',\n",
       "  'iなんとかって、入力するときって。2文字目が、大文字だから。半角／英数に切り替えるのを、ミスりやすいかもー。',\n",
       "  '二月に仙台は極寒かしらん。',\n",
       "  'そんな近いところに敵がいたとは･･･ RT [USR] 非童貞が敵、つまり父親はいつか超えねばならない敵ということか・・・',\n",
       "  '[USR] 逆に誰も来ないのが想像できないです…ｗｗ\\u3000なんでだろう、長男だから？なのかな。うーん…',\n",
       "  '[USR] 「野毛」という地名から派生したみたいね。下野毛、もあるんだよ。',\n",
       "  '[USR] 濃厚な物が好きな僕にとっては辛いです',\n",
       "  '冬用ワイパー買わないとなぁー。',\n",
       "  '鎖骨に“台所”、上腕二頭筋に“読書感想文”の米兵を生で見たいｗｗｗ',\n",
       "  '年々増えて行く予感(´・ω・`)',\n",
       "  'トリビア！そんな規定があるのですね。RT [USR] 五輪だけは規定で国際映像に加工ができないんですよ。残念ですよね。世界選手権とかではやってます。\\u3000RT [USR] カーリング。  将棋の中継みたいに、マグネット板使って解説してくれたらわかりやすいなぁ。',\n",
       "  'iPhone電池ない。画質荒れあれだった！ので、PCで！必ず！ゆるしてー(つд∩) ｸﾞｼｸﾞｼ RT [USR] なぜ明日？今見ろ！ RT [USR] [USR] ありがとう(´ω｀●) 明日みてみる！！！',\n",
       "  '集団怖い怖い怖い… [mb]',\n",
       "  '[USR] 3千円ぐらい(ヽﾟд)ｸﾚ',\n",
       "  'がっつり寒くなって来たので暫時休憩．',\n",
       "  'あの樹海の…腐海のような自室へ…',\n",
       "  'とてもすてきなニットとジーパンみつけたなう',\n",
       "  '[USR] ようつべあるといいなぁ…；；',\n",
       "  '映画本あるかなぁ～おれねむい…',\n",
       "  '送別会してきた一旦帰る',\n",
       "  '化け猫さんがお化けさんいじめてる画像下さい',\n",
       "  'もー、ホーチキツケテー',\n",
       "  'おめ！☆！RT [USR] 15000',\n",
       "  'RT [USR] RT [USR] 大切なのはどれだけたくさんのオナニーをしたかではなく、どれだけ心を込めたかです。(Mother Teresa)',\n",
       "  'トラ、かわいいーーー。',\n",
       "  '[USR] おはようございますいってきますー',\n",
       "  '((ｶﾞﾀｯ RT [USR] 攻が英国紳士でアーサーって名前で金髪翠眼なBL小説をバイト先で見つけたという報告。',\n",
       "  '[USR] 広島から呉鎮の距離が同じか，ちょっと遠いぐらいだよなぁ．山影にはならないから「あちっ」ぐらいは感じるんじゃないかねぇ．',\n",
       "  '[USR] ナウシカもポニョももののけ姫も録画対応でＴＬには乗れてません(`･ω･´)ｷﾘｯ',\n",
       "  'つ【遅延証明】RT [USR] Twitter遅延証明証をください',\n",
       "  '百鬼夜行のハイスコアが更におかしい件',\n",
       "  '禁断症状がでてきたwww休日は早い時間から飲めるけど、まだ、我慢。。。',\n",
       "  'してみると，平行定規やドラフタの進歩は1990年ぐらいで止まったのだな．最終期には精妙すぎて却って使い辛かったりした．あたかもレシプロ戦闘機の末期のようである．私も当時，最終期より1世代前のパラスケールZを事務器屋に捜させて導入したのだった．',\n",
       "  'まんでがんなう #mandegan  [URL]',\n",
       "  'おはよう＆むくりなう (7:59) #OhayoPanda',\n",
       "  'プロトたんきましたああああ//////ありがとうございますうううう//////',\n",
       "  '[USR] それこそホンモノのハーバマスが機械翻訳のたどたどしい日本語で「エライ先生」に話しかけて来たら面白いだろうなぁ．',\n",
       "  '駄目だプールプレイが頭から抜けねぇ…！後ろと、前にも一人いるとい(ry [mb]',\n",
       "  '抱き枕本体の話かと思った…(＞ω＜；',\n",
       "  '秩序のない現代にドロップキック♪♯♭',\n",
       "  'ビブラートかけて歌ったら喉にたんがつまったみたいになる',\n",
       "  'エグザイル14人どころじゃないんだけど…',\n",
       "  'ちょっとコーラかってくる',\n",
       "  'ままままっま\\u3000まいなす１℃ってｗｗｗｗｗｗｗ',\n",
       "  '新刊は家に帰ってから読む。vassaを家以外で読む勇気ない。',\n",
       "  '[USR] おかえりなさいませー。',\n",
       "  '[USR] 俺のお気に入りは凄まじい、ぜ・・・＾q＾ まちこさんの発言は全ておきにい（ry いいや、俺なんてファージだしな・・・！！（え',\n",
       "  '[USR] メアリー可愛いですよねー！でも本当あのゲーム作ったビッグ５はただの変態ｗｗｗｗ スタッフは病気＼＾＾／ [mb]',\n",
       "  '凄くわかる・・・ RT [USR] 気持ちわかりますヽ(´･ω･｀)ﾉ \\u3000RT [USR] 普通の方からフォローされると戸惑う。ボクはアホですよ？',\n",
       "  '魔道サイエンティストにすると。なんか、科学と魔術が交差しちゃったみたいかもー。',\n",
       "  'oi\\u3000おい\\u3000Operaさんがいないぞ\\u3000紀伊店のかおい RT [USR] Firefox:○ Chrome:○ Safari:○ IE:(笑)',\n",
       "  '[USR] oh･･･次はしっかり選ばねば･･･次があればだけど',\n",
       "  '[USR] サービス悪いのは嫌ですよね～。',\n",
       "  'そういえば今日はもうSUNDAYじゃねーの',\n",
       "  '[USR] ありがとですw 絵かかないとすぐなまるから困る',\n",
       "  '[USR] [USR] 本日は長い時間本当にありがとうございました！いろいろお話できて楽しく、有意義な時間を過ごさせていただきました！これからもいろいろ勉強させてください！！今後とも末永くよろしくお願いします！時節柄、お身体ご自愛ください。おやすみなさい♪',\n",
       "  '[USR] すっぱいのがイイ(・∀・)！\\u3000ないとバーガーじゃない気分になるます。',\n",
       "  '勝手に！失礼すぎるwww RT [USR] [USR] さんのモテ期が終わった度は74.3%です。 [URL]',\n",
       "  '平日休みに天気いーと倍嬉しいとかいったけどそれは体の自由が利く場合のみですね\\u3000病気じゃねーのに外でらんねって2日もいらねーし',\n",
       "  '昨日ママンとメールしてたら同級生がもうお母さんしてるよと言われてがちで驚いた。 [mb]',\n",
       "  '意識すると、なんだかそんな気がしてくる。',\n",
       "  '六本木なぅなぅ♪ネオンで充電。',\n",
       "  'いいなぁーみかんさん宅すきやきオフ… にく…',\n",
       "  '[USR] 人参てんぷら！？おしえて～ぇ。かき揚げみたくするのかな？',\n",
       "  'Heal The World  ♬本日最期の曲に、デュエットでー！いけー！',\n",
       "  '[USR] ほぇー。いつかのメリークリスマスはー？？',\n",
       "  '[USR] う～ん、ちょうさんも騙されてるのかも・・・w',\n",
       "  '日光で買った湯波があるんだった',\n",
       "  '気になる。 RT [USR] リプトンゆずティーてのが売ってたので、買ってみた。',\n",
       "  '……ロボコンの萌えと言えばロビンちゃんだろう．と言うコメントは敢て reply形式では不言．',\n",
       "  '[USR] 料理が上手なのは大事だよw',\n",
       "  '結局今日は何食べるんやろ・・・\\u3000\\u3000帰る・・・\\u3000さいなら',\n",
       "  '[USR] ずーっとこの下手物ピザネタはやりたかったんです＾＾// ありがとうございますwwありそうですよねー！とりあえずブラッドはおこってるっていうww',\n",
       "  '[USR] 誘眠名人が不眠に悩む．てのは何かの寓話ですかなぁ．',\n",
       "  'お風呂あがたー [mb]',\n",
       "  '[USR] それともサザンアイズ？w',\n",
       "  'これで存分に寝正月できるというもの(・∀・)ニヤニヤ',\n",
       "  '[USR] それはシリーズで “日本空目史” というのではどうでしょう．',\n",
       "  '[USR] いつもいつもアホな事していてすみません！！＾＾＾＾＾＾ ちょおかんは皆のおかん！！（え）',\n",
       "  'ショタレクの可愛さは多分加々美が描いてくれたらまじで俺が大変な事になると思われる [mb]',\n",
       "  '素晴らしい場所です。また再訪します！ RT [USR] これはステキ(ﾟ∀ﾟ) RT [USR] タイムスリップしてる！ QT [USR] ジョイフル三ノ輪商店街へ。気ままなお散歩なう。 [URL]',\n",
       "  'ぜったい職場で風邪菌蔓延しとる',\n",
       "  '[USR] はらへがくるでぇ！ちてら(3はーい',\n",
       "  'RT [USR] RT [USR] TLには童貞が多いと聞きますが、それはユーザーの年齢層が若いだけで、これから恋人もできるし好きになった子とイチャイチャできると思うのです。',\n",
       "  '後で相談してみよう。 [mb]',\n",
       "  'いまどき珍しいw QT [USR] うおっ部屋のなかにねずみがっ',\n",
       "  '. [USR] [USR] [USR] [USR] おやすみPOSTありがとうございました～おはようございます＾＾ﾉｼ',\n",
       "  'トミタ『KOSMOS』のConcierto de Aranjuez for guitar & orchestra Aranjuez-Adagio は，いかにも操り人形がぎこちない動作で奏でている感じがするのである．',\n",
       "  '同じ人間とは思えない RT [USR] 全部おk RT [USR] 禿同！レーズンもらめぇ！ RT [USR] 酢豚にパイナップルもサラダにりんごも生ハムメロンも同意！苦手！',\n",
       "  '思わずマツコデラックスぼっとをフォローしちゃったじゃないのよ(笑)',\n",
       "  '他の皆さんは？！RT[USR] [USR] RT [USR] ｢行けたら行くわ｣って、なんパーセントの確率で来るんやろ',\n",
       "  '大阪方面のひと！これ楽しそうだよ！ → 今度は飛行機が舞台、リアル脱出ゲーム第4弾が大阪HEP HALLで開催 [URL]',\n",
       "  '[USR] ぎゃーありがとう！加工に次ぐ加工でメガネもちゃっかり外しました&lt;[ﾟ・◡・]&gt;今度はメガネなしで会いたいの！',\n",
       "  '携帯の充電がついったすると三時間が寿命。  やはりあいぽんか…',\n",
       "  '[USR] 一人飲みは至福のひと時ですが、ワインちゃんは、ダーリンも飲むし、それって、しあわせ～♥',\n",
       "  '[USR] いえいえｗｗｗｗｗｗ',\n",
       "  '[USR] 角の長い奴も居るみたいだが，ずいぶん小さいですなぁ． [URL]',\n",
       "  'なんかエロい RT [USR] [USR] 腹ン中がパンパンだぜ',\n",
       "  'べ！別に嬉しくなんかないんだからねっ！ RT [USR] 悦んでるクセに、何をおっしゃる・・・・ RT [USR] フォローしたらまた変態増えた･･･',\n",
       "  'うちのクリスマスローズが今年はいぱい蕾をつけました♬  [URL]',\n",
       "  'おなペコ〜\\u3000ご飯食べてくる。',\n",
       "  '[USR] ゲームの時間を減らせばおk',\n",
       "  '[USR] 魔理沙のキノコ食べたい！',\n",
       "  '[USR] うん！思い出したよ！！女子の日ぢゃん！！',\n",
       "  '新たに高麗人参じいさんの出現',\n",
       "  'わらたwww RT [USR] これ今すぐサービス化してくだちい！ [URL]',\n",
       "  'でも１月24日OAなんだな！？？\\u3000#mjlarc',\n",
       "  'このようなつながり、絶対後々に活きてくると思うんだ！みんなふぁいとだー！！ RT [USR] .[USR] [USR] [USR] 今から一人で企業研究するのでスカイプで便乗できちゃう人募集！今夜はお菓子ね！＾＾\\u3000私財務方面からみる！',\n",
       "  '1次元は点で。2次元は平面で。3次元は空間。4次元は、ほんとに時間なのかなぁ？？',\n",
       "  'ダメダメだw RT [USR] なぬっ！！....(￣◇￣;)  Sadyさんの「アイコンの可愛さ度」は、14%です。 [URL]',\n",
       "  '[USR] むしろ一から教えてください＾ｐ＾本当ペン入れが私ぶれぶれのぶれぶれでorz 因みフォトショだとA4サイズ/9サイズのペンで下書き→5サイズでペン入れですｗｗ [mb]',\n",
       "  'スコーン入手までブロッコリーで飢えをしのぐ  わくわくっ',\n",
       "  'RT [USR] RT: [USR] 大切なことなのでもう一度。本日16:00－18:00の間、Twitterサイトは一時的に利用できなくなります。ネットワーク機器のアップグレードのためです。ご不便をおかけしますが、よろしくお願いします。',\n",
       "  '[URL] - 兄さんがレクスたんをガグガグブルブルさせて犯そうとしているようにしか私はみえな（ry',\n",
       "  '二人との扱いの差が・・・w',\n",
       "  'ΦωΦ\\u3000の入ってる顔文字見るとみ～こさんのpost来たと思ってしまう',\n",
       "  '[USR] おかえりなさいー [幼女bot作ったらしい\\u3000アイコン募集中\\u3000[USR]',\n",
       "  'おっぽは間違いなくイケメンです！RT [USR] 玉木宏に似てません？？！RT [USR] さっちん、 [USR] RT [USR] スタイリスト・岡部文彦くんが素人デモル募集中～！',\n",
       "  'とりあえずルドレクのえろい妄想から朝が始まる始末 [mb]',\n",
       "  '[USR] だから覚えいて欲しいんだ…彼女の事を･･･',\n",
       "  '青いイルミネーションがいいか、オレンジがいいかで一悶着あった。仕事しろや＞私  ちなみに、わたしはオレンジ推奨。',\n",
       "  '少し遠くのスーパーでDE CECCOが178円らしい．出動すべく身仕度．',\n",
       "  '言うな RT [USR] RT [USR] 「ようじょ」と「まんこ」とか…そんなこと定期的にpostしてて楽しいか。  …そうか、お前のかーちゃんは人の役にたつ立派な大人に育つため、おまえらに何千万という学費を払ってたんだぞ。',\n",
       "  '[USR] なので「予約だけ取って何年も本が出ない」「版組の美しさのために当然書かれて然るべきものが削除されている」「版型に収まらないので嘘を書いている」満載であります(笑)\\u3000ちなみにそれらを無視して完全版邦訳が出たのは90年後の今年w',\n",
       "  'かくれんぼで場所を選ばせて探すとかもいいかな',\n",
       "  '[USR] 変な人……なのか？w',\n",
       "  '２０時就寝かなわず；；；；；でしゅっ RT [USR] お疲れちゃ〜〜〜んのこにゃにゃちはぁあ RT [USR] たりらりら～～～ん、火曜日なのにお疲れMAXで出来上がり帰宅なう♪お風呂→即寝なう',\n",
       "  '[USR] 例えば、食料自給率1％らしいとの話がある東京都。お米やお野菜たちはどこからくるのか。それが、その「きっかけ」のひとつになるかな？',\n",
       "  '[USR] これぞ夜間帯つぶやきの至高(・∀・)ﾆﾖﾆﾖ',\n",
       "  '[USR] なんか、山中にはこんな顔をさせたくな…（笑）下睫毛っていいですよね(*´д｀*)ﾊｧﾊｧ ああじゃああれだ四郎とセットで可愛がってくださ…（笑）ただやはり角刈りは難し、い…（;´Д⊂） オタしか回りにいないけどはずかちい…// [mb]',\n",
       "  'さてと、支度しようー。',\n",
       "  '[USR] うん、想定内(=・ω・)冷房にやられちゃうもんねー♪',\n",
       "  'まず手始めにエア雪合戦でも計画すっか？',\n",
       "  '[USR] さらに面白いのは、熊谷近辺から新幹線通勤・通学で東京まで通う人々も多いということです。そのような経緯から、南関東に属するか北関東に属するかについての論議には、県民内でも境遇/世代などによって差異が発生すると思われます。実に興味深い。',\n",
       "  '濃厚なんだけどさっぱりしているんです。美味しいですよ！ぜひ召し上がってみてください♪RT [USR] 猪ってどんな味なんですか？RT [USR] 猪鍋。 [URL]',\n",
       "  '[USR] 裸割烹着会は親父属性におかんとエロスを無理矢理こすりつける会なのでもちろんおっさんでお願いします(*´Д`)ﾊｧﾊｧ',\n",
       "  '[USR] おもしろいひとって思われるのはうれしいことですな。印象がいいほうに変わってたのならいいなあ＾＾うん、ときどき語りだしたい夜もあるのでw',\n",
       "  '[USR] 打設間違いかと他人事ながらヒヤリとした．',\n",
       "  '＼実はチャコさんのファンだよ／',\n",
       "  'あああああ…。やっぱり問題あるんだ。。そうか。。',\n",
       "  '[USR] あそぶよー＼(^o^)／\\u3000この前の同人誌くれるんですか？',\n",
       "  '[USR] でぶってるのまちがいじゃw',\n",
       "  '[USR] おやすみなさーーーい！',\n",
       "  '[USR] いやー、さすがにしません！妹に至ってはブロックしてます～',\n",
       "  '修造もぽにょTLに参戦だよ',\n",
       "  'QT [USR] 無差別RTbotも十分スパムだと思いますう＞＜ RT [USR] ついったーのbotでパブリック拾うのは慎重になってほしいとは思うよね。。ついったーで宣伝したらspam扱いで謝罪文出す騒ぎもあったしね。',\n",
       "  '今週のワンピ(´；ω；｀)赤犬きさまぁぁぁぁあ！！(´Д⊂ヽ *Tw*',\n",
       "  '[USR] 恋心と母性愛と忠誠心…女性として素晴らし過ぎる…！母性愛はあれですゃね駄目な人だからキュンとするという（笑）牛尾さんが深影さんを好きなのが本当に好きで(*ﾟ∀ﾟ)=3 あのペイントハウスでまさかのお茶会ｗｗｗ [mb]',\n",
       "  'iPhoneでスト4なんてやるものではないよね。',\n",
       "  '……でも「そういうものがある」と知ってるだけで見え方は変わってしまうからなぁ．だめか',\n",
       "  '[USR] 透過処理していない主線レイヤー一番下にして、乗算色塗り乗算色塗りしてました＾ｐ＾ぜひやってみてくださ(ry 因みにブラスレイターまでは全部そうで(ry [mb]',\n",
       "  '[USR] さすがオクトパスだぜぇ（棒）',\n",
       "  '[USR] あ、じゃあ青の前とかどうすか？',\n",
       "  'こんなところにダヤンショップがあったのか…',\n",
       "  'エキシビションは未来ちゃんがよかった！！！',\n",
       "  'ガードレールかもしれない！ RT [USR] 郵便ポストかもしれないよっ！RT [USR] 落下物！？そ、それは自動販売機ですか！？',\n",
       "  '今年のホワイトデーに男性から欲しいもの（年代別、複数回答可）1位……………………スイーツ（52.0％）2位………………アクセサリー（47.0％）3位……食事（デート）のお誘い（44.0％）4位………………感謝の気持ち（41.0％）5位……もらえるものなら何でも（14.0％）',\n",
       "  'レシピってフランス語だったかなー。',\n",
       "  '[USR] わわ！いま自分のPOSTみてちょっと恥ずかしくなった(*ﾉｪﾉ)ｷｬｰ そしてしろさん今日は天使なのだね♡うれしいからふぁぼろー！',\n",
       "  '[USR] サンちゃんも最近ちやほやされすぎてきもちわるいので( ‘д‘⊂彡☆))Д´) ﾊﾟｰﾝ',\n",
       "  '[USR] おはよー！ありがとうw うちの家紋かなりのお気に入りっす♬',\n",
       "  '京成高砂なう。これから矢切の先輩宅うぃる。超久々の京成・北総だ！',\n",
       "  '[USR] 関東では，肝心のアンコモチが入手至難なので，作ってみたくても難しいですなぁ．一度食うてみたい．',\n",
       "  '速達も駆使してファイト！郵便局のサイトに出す場所→着く場所ごとの到着日数目安が載ってるところがあるからそれも活用するといいお(^ω^) RT [USR] 肝臓いたくてESかけないお。。。7日必着なら今日までなのだろうか。。。ウコンかお',\n",
       "  'あんっ・・・いいっ・・・ RT [USR] 変態のみんなが突いているですって///  RT [USR] でもいいさ！ボクには変態のみんながついてるんだ！',\n",
       "  '[USR] 行けば良かったじゃんw',\n",
       "  '[USR] 凄く、卑猥です…（笑） [mb]',\n",
       "  'あ、ワンピくじはファミマが多いみたいだけど、ミニストップとかスリーエフとかローソンとかでもやってるとこあるっぽいなり(・∀・)ﾉつ[URL]',\n",
       "  'RT [USR] 調べてたらこんなの発見した。 【コンビニのおでんにゴミは入らないの？[URL]',\n",
       "  '[USR] ( ﾟ∀ﾟ)人(ﾟ∀ﾟ )ﾅｶﾏｰ! [mb]',\n",
       "  'セーイさんの本なら買う',\n",
       "  '寒いなぁー(&gt;_&lt;)',\n",
       "  'ONE PIECE MEMORIAL BEST初回版をな、アマゾン様で頼んだんだけども\\u3000\\u30002枚頼んじゃったっぽい＼(^o^)／',\n",
       "  '[USR] それは一体どう云うもので．仕事柄わかるかも．',\n",
       "  '適当に打ち込んでたけど、サンジからもらえるチョコは14パターンあるます',\n",
       "  'とりあえず、誰もかわねーでFA',\n",
       "  '液晶ディスプレイとか僕の美顔が写って液晶が壊れるから止めた方がいいと思うんだ ヮ＜',\n",
       "  'うろたん枕といちゃいちゃなう',\n",
       "  'マリクたんそういえば弟ｗｗｗ リシド×宿主マリクが好きです(`･ω･´) ｼｬｷｰﾝ [mb]',\n",
       "  '明日・・・しごと・・・いきたくないな・・・',\n",
       "  'www RT [USR] www RT [USR] ブログを更新しました→【CRIMSON FOX】「職質なう」はつぶやけませんでした [URL] [URL] #crimsonfox',\n",
       "  'はあ。長官かわゆ…。 [mb]',\n",
       "  '【DQ4】ぜんぜん、わかんない・・・＞＜  たぶん。へんげの杖（？）か、かわきのつぼみたいなのっが必要だと思うんだけど。ろうやのカギみたいなのを持ってないし。どうすれば、いいのかなぁ・・・。',\n",
       "  '中野でみた中央特快高尾ゆきもなかなかの混雑だった。都心部～多摩の輸送需要はやはり目を見張るものがあると毎度思う。',\n",
       "  'やばい\\u3000ねむい\\u3000すし・・・',\n",
       "  '弟でおｋ QT [USR] もう弟でもいいじゃない RT [USR] 俺の弟は性格はいい、俺の言うことはほとんど何でも聞く。ただ性別が間違ってた',\n",
       "  '言えてるなw RT [USR] それこそが魅力じゃないですかwwwRT [USR] 笑ってこらえてのディレクターのやる気なさが酷いwww',\n",
       "  'さいきん、水が麦茶かウーロン茶しか飲んでないものー！',\n",
       "  'たとえば嵐が来ると、浜辺に残されるものがある。それがどんな国から着たのか見たいと思いましてね。',\n",
       "  '比較幸福論なんか、したくないのに(´•ω•`)',\n",
       "  '[USR] わぁ\\u3000かわえぇｗ\\u3000作れねーｗｗ',\n",
       "  '[USR] ぬぅ．犯人は豪州ですか．ふむ，しかしダイソーの場合は中国辺りで作ったハンダでしょうから，きっと中国13億人がこぞってハンダをジュゥジュゥいわせてるから足りぬのだ，とばかり思うておりました．',\n",
       "  '[USR] ジャックは今どうしてる？',\n",
       "  '[USR] びんぼっちゃまｗｗｗｗｗｗｗ\\u3000うしろないやつなｗｗ',\n",
       "  '第参陣の筆頭は大変おいｓｈそうすぎてパーンする\\u3000素でデヘヘっていっちゃったつっこまれたなう',\n",
       "  '[USR] よしおじさんも「よしお！よしお！」だけでことが足りる日がくるといいね！ろりこん！',\n",
       "  'ステージ…………見たかった…………orz',\n",
       "  '[USR] うん、ガチムチが襲い受けなんだって。',\n",
       "  '[USR] ないですねまじで自給自足もできないので尚更＾＾＾＾＾れくすにゃあああああーん にゃー(ミ・∀・ミ) [mb]',\n",
       "  '[USR] ひどいｗｗｗｗ鬼畜ｗｗｗｗｗｗｗ\\u3000本来はこれぐらい簡単にでるはずなんですが……ね………(；´∀｀)',\n",
       "  '教え子の女子高生3人と10回以上セックスした教師をクビ\\u3000嫉妬に燃えた童貞ｸﾗｽﾒｰﾄの怒りの告発で発覚\\u3000[URL]',\n",
       "  'Hey #aptakigawa Hey #aptakigawa 今のはヒドかったwww (PTF live › [URL]',\n",
       "  'もうすぐ２２時？いいえ、みまちがえよね？',\n",
       "  '[USR] 私も飲んでますがw\\u3000こういうのは「ついのみ」とかいうハッシュタグつけるといいんでしたっけ．',\n",
       "  'おおー！ぜひお話をうかがってみたいです！司会進行頑張って下さい！ RT [USR] おお！\\u3000RT [USR] 仙台にて東北観光のキーパーソン達に集って頂き座談会開催。第一回目なのでテーマは「東北観光を磨くには？」司会進行役なので、しゃべり過ぎないように注意しよう\\ue409',\n",
       "  '[USR] こんにちは～！わ、みられてましたか！とりあえずこれで。ほんとはもうちょっと拡大したほうがバランスいいんですけどおそれおおいのでこれでw',\n",
       "  'そういえば昨日はドライオーガズムに達しそうでヤバかった。\\u3000出したかったんだけど1年間オナ禁をやり遂げるために抑えた。\\u3000\\u3000もう深めに呼吸するだけで出そうになるんでヤバかった。',\n",
       "  '起きてた！バス混んでました…。今日もクソゲー頑張ってきま',\n",
       "  '奥の方がエビだと思ってグロ画像だと空目\\u3000「サンタエビ」話題に\\u3000 [URL]',\n",
       "  \"[USR] 薄っぺらい心臓なのに(つд∩) ｸﾞｼｸﾞｼ  ほんと、はやく解放されないと、また深夜にだれかに疲れてるとかいわれちゃうもんね(ｏ'д')('д'ｏ)ﾈｰ\",\n",
       "  '[USR] あ。僕も、ビジネスとか。好きじゃないかもー。',\n",
       "  '[USR] Matureの意味が、わからなかったお｡･ﾟ･(ﾉД｀)･ﾟ･｡',\n",
       "  'なんか、これ、卑猥じゃね？',\n",
       "  '[USR] 今回は宣伝するだけにしとくw',\n",
       "  'かくいう自分は、いくらなんでも最近外出が多いので、今日は家でがんばる。たまにはこういう日があってもいい。というか、なくちゃだめだｗｗ',\n",
       "  'とりあえずごはんごはんーーーー',\n",
       "  '[USR] お、お酒？(;´･ω･`) おっさんサークル…？ [mb]',\n",
       "  'あ。そういえば牛尾さんが、「俺はサテライトが管轄だった」って言ってたけど、伝説のＤホイーラーがいた時にはまだセキュリティはやってなかったのかなてか牛尾さん今いくつ [mb]',\n",
       "  'こっから銀座までなんぷんかね',\n",
       "  '[USR] え！？持ってるんですか！？？って、ぜったいアイスのじゃないでしょう| 冫､)ｼﾞｰ',\n",
       "  '90年代初めの超円高の時は洋書やら車のパーツなどの個人輸入で随分とトクをしたが，今回は利に与れそうにないな．何せ手持ちの日本円が無いわ．',\n",
       "  '[USR] 擬人化はかわいかったよ！ｗｗｗｗ',\n",
       "  '[USR] 風下に立ってるのか？w',\n",
       "  '[USR] やっほーーーーぃo(^３^)o',\n",
       "  'うわ！\\u3000エア始まってるやんwww\\u3000はい\\u3000かんぱーい！\\u3000ってラス１ですよw',\n",
       "  'RT [USR] ステータスブログを更新しました。「パスワード変更をお願いした理由について」\\u3000[URL]',\n",
       "  '[USR] おはようございまー。',\n",
       "  '[USR] 基準がおかしいおかしい。',\n",
       "  '[USR] あびんぐどんってTMの西川さんの？Ｄグレの主題歌あったらほしー！ 7188も好きだおー＾＾////// あらあらあらｗｗｗ類は友ｗｗｗ [mb]',\n",
       "  '[USR] 引き起こす時に副操縦士も手伝って計器盤に脚を突っ張ってよっこらさ．なんて話があるねぇ．',\n",
       "  'あの僕をフォローしてくれるんはいいですが変態丸出しなので注意してくださいね [幼女bot作ったらしい\\u3000[USR]',\n",
       "  '[USR] ほぇー。僕もほしいかもー。',\n",
       "  '仕入れなくちゃ！ RT [USR] ショコラブルワリー(サッポロ)とショコラカクテル(アサヒ) [URL]',\n",
       "  'フォローしようと思ってた人がフォローしてくれてた',\n",
       "  '[USR] きゃーーーー！！こじゅーーー！！斬り捨ててーーーー！！！ｗｗｗ',\n",
       "  '（なぬ？？聞き捨てならないつぶやきな・・・',\n",
       "  '牛めし290円最強＼(^o^)／',\n",
       "  '[USR] あ、おかえりー(´ω｀●) パタパタパタ←玄関に向かう音',\n",
       "  '諏訪湖をあうーあうー言わせたい！\\u3000\\u3000中に思いっきりブチまけたい！\\u3000\\u3000そして生まれた卵を食べるんだ!',\n",
       "  '[USR] おかえりなさいませー。死なないでー！＞＜',\n",
       "  'どちらにしても、夜まで秋葉にはいるつもりだったのでだいじょぶですよー。またーり待ってるので、気をつけて来てくださいなヽ(´ー｀)ノ',\n",
       "  'あれ、しかもRetweetぼたんできとるわ。ん？何がなくなったんだ？',\n",
       "  'いや 休みの日に限らんな なーんや',\n",
       "  '[USR] よろしくおねがいしますー   まったり二度寝楽しんでくださいませ(＞ω＜)',\n",
       "  '足湯なう[USR] #touhokutrip  [URL]',\n",
       "  '[USR] はいー…だいじょうぶですー…(´Д｀)',\n",
       "  'なんでこんな煙草ＴＬなのｗｗｗ',\n",
       "  '汗かくような運動してる？体と精神のバランスだから・・・私が抱きしめてあげる～ぅRT [USR] ここんとこ、睡眠の質が悪い。疲れが取れないよ…',\n",
       "  '【海外ボカロ、リアル路線からアニメ/コミック路線に方針転換？｜スラッシュドット・ジャパン】  [URL] ずいぶん以前のことだが，SweetAnnも，日本の某氏が描いた二次創作イラストをPowerFX側が使いたいと申し入れてきた件があったような．',\n",
       "  '今年はショパンが生誕200年らしいですね',\n",
       "  '[USR] ザッと読んでみたが，まぁこのくらいでは楽して食えてる方じゃないのかなw',\n",
       "  '映画ＴＬに嫉妬＾＾＾// いいなあはやくみたいー！ [mb]',\n",
       "  '綿アメかと思うくらい雪質が柔らかい！RT [USR] 綿あめだろ？ｗｗ RT [USR] きれい！RT [USR] 東北本線杉田駅付近にて。快晴の雪景色もまた綺麗！ #touhokutrip [URL]',\n",
       "  '[USR] そうなんだよー\\u3000しかも自分は生まれつきお腹が弱いし次の日が休日の時にしかしないようにしてるの',\n",
       "  '[USR] Googleカレンダーに同期させて，それをさらにiCalに同期させるとかw',\n",
       "  '[USR] TwitBirdのRTが変だから変えてくれ、と言われて変えたはず。',\n",
       "  'でも大概の謝罪文起草者は間違いを仕出かした本人ではないので，どうしても「俺がやったんじゃないのに」という感情から受動態を使ってしまうのだよなぁ．そこがまぁ，まずいわけだが．',\n",
       "  '[USR] 即席焼きそば！食べたいなー！',\n",
       "  'みすずちん！さっきのうぷ失敗してた… [URL]',\n",
       "  'マジックテープってクラレの登録商標なのか。クラレってアルパカCMのおかげで就職希望者殺到したらしいね。案外、そんなもんなのね♪',\n",
       "  \"[USR] うまいです'`ァ(*´Д｀*)'`ァ 会社の近くにあってよかった\",\n",
       "  '角をどうやってカチュにつけるか、っと… [mb]',\n",
       "  'RT [USR] RT [USR] 俺がメイドだ！',\n",
       "  '[USR] 実写アイコンで誰だこのリア充って思ったけど変態postのおかげですぐに誰か分かりました',\n",
       "  '[USR] デカすぎても不便なんだよ m9(^Д^)',\n",
       "  '[USR] ごっつぁんです！ちゃんこ！',\n",
       "  '[USR] 美味しいですよー(o・v・o) カップ麺になるぐらいなので、安定した美味しさ(´∀｀)',\n",
       "  'しかしあれだよなぁ．闇雲に急ぐ，ってのはある程度までは効率がいいが，ある領域を越えるとジャムって効率が急落する気がするなぁ．そうなると急げば急ぐほどダメになる．大阪がそうなのかどうかはわからないが．',\n",
       "  'あるあるｗｗｗ RT [USR] あるあるwwRT [USR] ちょwww風呂の栓抜いたままだったwwwww',\n",
       "  '[USR] [USR] べべさんにはほぼすっぴん披露済みだしね！っておい。',\n",
       "  '[USR] ピンは軽く圧入されておるか，あるいは開閉時の偏磨耗で段付きに減っておると思われますからな．普通ですと平行ピンポンチで下から叩いて抜きます．',\n",
       "  '[USR] ……空戦シーンで同じ事を思ってる人も居りましょうからなぁ……',\n",
       "  'やっぱりようわかれへん',\n",
       "  '[USR] まぁ…。あでも弊社の下のローソンもいれてないですね；サンクスにはある',\n",
       "  '[USR] 同じ会社だったらどうしようwww',\n",
       "  'あれ。tomblooって、Firefoxに追加する（？）機能なのかぁ。引用しかできないのかなぁ？？',\n",
       "  '「個別都市\\u3000東京」でググっても個人指導の学習塾ばかりでした。。RT [USR] ググって出ないのは深刻。池袋でやっているパフォーマンスです。「個別都市\\u3000東京」が正式。RT [USR] [USR] TLをみて、\"個別都市東京\" とquoteしてググったら0件..',\n",
       "  'ぎゃああああああ長官の書き下ろしあったああああああああてかこれはあれか、ＤＴの絵柄くさいんですがまさか参戦！？ [mb]',\n",
       "  '何、故、フォローしたし [mb]',\n",
       "  '[USR] な、何Σ＾＾ まさか俺以外に旦那が…＾＾＾＾ 超、食べにいくおｗｗｗ多分足りないとかいいだすおｗｗｗｗ [mb]',\n",
       "  '[USR] がんばってくださーい＾＾ [mb]',\n",
       "  'ＡＫＢ48なのに72人いるの…？いつの日か男はみんなエグザイルで女はみんなＡＫＢになるの？',\n",
       "  '[USR] い、いやああああそりゃ風邪もひきます、よう（;´Д⊂）インテ後は、沢山おやすみくださいね｡･ﾟ･(ﾉД`)･ﾟ･｡ し、しななくてよかったですあわわわ [mb]',\n",
       "  '[USR] 乗組員も視覚が狂って艦上構造物にぶつかったりしそうな．',\n",
       "  'うららかな土曜日の昼下がり～どうでもいいことばかり、連続で呟いてる自分が可愛く愛おしいｗｗｗはーぁぁ（●＾o＾●）',\n",
       "  '[USR] こちらから見ると，田渕的な学生っぽさってのは80年代で一旦切れてるような感じがありますが，実はけっこう連綿と続いておるのかも．',\n",
       "  'また多いなw RT [USR] latorがてんこもりアップデート！！ [URL]',\n",
       "  'デュラとのファーストコンタクトであるコミックスは、主人公が帝人だった。アニメも帝人ではじまって、各回それぞれ別の人がフィーチャーされてたから、帝人ベースの話だとばかり',\n",
       "  'マイピクが増えた(*´д｀*)ﾊｧﾊｧ 嬉しすぎるぅ……(*´д｀*)ﾊｧﾊｧ [m]',\n",
       "  'そういえば言い忘れてた\\u3000オナ禁3日目 #onakin',\n",
       "  '[USR] ヾ(･ω･`●)ｮﾁｮﾁ',\n",
       "  '大貧民と大富豪、大貧民ていうのは東京だけって妹がいうんだけどほんまかいな（さすがにびびって小声）',\n",
       "  '[USR] 最近は、テトリスが多いからだろうねw',\n",
       "  'ナタちゃんまた規制じゃね？',\n",
       "  ...],\n",
       " 'labels': [0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  ...]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JpSentiDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from datasets import Dataset\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=2023) # random_stateを決めてため結果は変わらない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 東北大バートversion2モデルを使用\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples['text']を入力としてトークナイズする関数\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['texts'], padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Fold: 1-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5900701284408569, 'eval_accuracy': 0.6772727272727272, 'eval_f1': 0.6776148338784741, 'eval_precision': 0.6782085228687172, 'eval_recall': 0.6772727272727272, 'eval_runtime': 1.0272, 'eval_samples_per_second': 214.173, 'eval_steps_per_second': 4.868, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6209838390350342, 'eval_accuracy': 0.7272727272727273, 'eval_f1': 0.7193209428544384, 'eval_precision': 0.7368277368277368, 'eval_recall': 0.7272727272727273, 'eval_runtime': 0.9704, 'eval_samples_per_second': 226.701, 'eval_steps_per_second': 5.152, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6164185404777527, 'eval_accuracy': 0.7545454545454545, 'eval_f1': 0.7533907624633431, 'eval_precision': 0.7542613636363636, 'eval_recall': 0.7545454545454545, 'eval_runtime': 0.9672, 'eval_samples_per_second': 227.455, 'eval_steps_per_second': 5.169, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9449218511581421, 'eval_accuracy': 0.75, 'eval_f1': 0.7477330853289932, 'eval_precision': 0.7508426238008814, 'eval_recall': 0.75, 'eval_runtime': 0.998, 'eval_samples_per_second': 220.448, 'eval_steps_per_second': 5.01, 'epoch': 4.0}\n",
      "{'train_runtime': 56.2777, 'train_samples_per_second': 1563.674, 'train_steps_per_second': 33.761, 'train_loss': 0.38081445192035873, 'epoch': 4.0}\n",
      "-----------------Fold: 2-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6114963889122009, 'eval_accuracy': 0.6454545454545455, 'eval_f1': 0.6419535157399235, 'eval_precision': 0.6705058218421635, 'eval_recall': 0.6454545454545455, 'eval_runtime': 1.1519, 'eval_samples_per_second': 190.988, 'eval_steps_per_second': 4.341, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6888175010681152, 'eval_accuracy': 0.65, 'eval_f1': 0.6296320164980345, 'eval_precision': 0.7378107846302873, 'eval_recall': 0.65, 'eval_runtime': 1.1029, 'eval_samples_per_second': 199.467, 'eval_steps_per_second': 4.533, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6210349202156067, 'eval_accuracy': 0.7090909090909091, 'eval_f1': 0.7095978455201756, 'eval_precision': 0.7111582558454455, 'eval_recall': 0.7090909090909091, 'eval_runtime': 1.2213, 'eval_samples_per_second': 180.132, 'eval_steps_per_second': 4.094, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6713140606880188, 'eval_accuracy': 0.75, 'eval_f1': 0.7490088313649806, 'eval_precision': 0.7495554991109983, 'eval_recall': 0.75, 'eval_runtime': 1.0838, 'eval_samples_per_second': 202.993, 'eval_steps_per_second': 4.613, 'epoch': 4.0}\n",
      "{'train_runtime': 49.1742, 'train_samples_per_second': 1789.556, 'train_steps_per_second': 38.638, 'train_loss': 0.4639288249768709, 'epoch': 4.0}\n",
      "-----------------Fold: 3-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6123478412628174, 'eval_accuracy': 0.6863636363636364, 'eval_f1': 0.6601712132743753, 'eval_precision': 0.7251244995605898, 'eval_recall': 0.6863636363636364, 'eval_runtime': 0.999, 'eval_samples_per_second': 220.215, 'eval_steps_per_second': 5.005, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5889261960983276, 'eval_accuracy': 0.7136363636363636, 'eval_f1': 0.6989672319265587, 'eval_precision': 0.7356241037032871, 'eval_recall': 0.7136363636363636, 'eval_runtime': 0.9711, 'eval_samples_per_second': 226.559, 'eval_steps_per_second': 5.149, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7304030060768127, 'eval_accuracy': 0.6954545454545454, 'eval_f1': 0.6752893965118074, 'eval_precision': 0.7239669421487603, 'eval_recall': 0.6954545454545454, 'eval_runtime': 1.1375, 'eval_samples_per_second': 193.413, 'eval_steps_per_second': 4.396, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7052761912345886, 'eval_accuracy': 0.75, 'eval_f1': 0.7486280199331355, 'eval_precision': 0.7498083312036802, 'eval_recall': 0.75, 'eval_runtime': 1.1569, 'eval_samples_per_second': 190.157, 'eval_steps_per_second': 4.322, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0342061519622803, 'eval_accuracy': 0.7272727272727273, 'eval_f1': 0.7276352759902112, 'eval_precision': 0.7284784181335906, 'eval_recall': 0.7272727272727273, 'eval_runtime': 1.1208, 'eval_samples_per_second': 196.286, 'eval_steps_per_second': 4.461, 'epoch': 5.0}\n",
      "{'train_runtime': 62.5952, 'train_samples_per_second': 1405.859, 'train_steps_per_second': 30.354, 'train_loss': 0.3290489397550884, 'epoch': 5.0}\n",
      "-----------------Fold: 4-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.611037015914917, 'eval_accuracy': 0.65, 'eval_f1': 0.6506587247419909, 'eval_precision': 0.6558597303779671, 'eval_recall': 0.65, 'eval_runtime': 1.0861, 'eval_samples_per_second': 202.559, 'eval_steps_per_second': 4.604, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5672509074211121, 'eval_accuracy': 0.6863636363636364, 'eval_f1': 0.6859115691603003, 'eval_precision': 0.6857155919263035, 'eval_recall': 0.6863636363636364, 'eval_runtime': 1.0052, 'eval_samples_per_second': 218.854, 'eval_steps_per_second': 4.974, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7300013899803162, 'eval_accuracy': 0.6727272727272727, 'eval_f1': 0.6716716415666047, 'eval_precision': 0.6897700408338706, 'eval_recall': 0.6727272727272727, 'eval_runtime': 1.312, 'eval_samples_per_second': 167.687, 'eval_steps_per_second': 3.811, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8038434386253357, 'eval_accuracy': 0.6727272727272727, 'eval_f1': 0.6727272727272727, 'eval_precision': 0.683939393939394, 'eval_recall': 0.6727272727272727, 'eval_runtime': 1.0013, 'eval_samples_per_second': 219.712, 'eval_steps_per_second': 4.993, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1790878772735596, 'eval_accuracy': 0.6772727272727272, 'eval_f1': 0.6776128543812616, 'eval_precision': 0.6860765986979579, 'eval_recall': 0.6772727272727272, 'eval_runtime': 1.0079, 'eval_samples_per_second': 218.273, 'eval_steps_per_second': 4.961, 'epoch': 5.0}\n",
      "{'train_runtime': 62.0966, 'train_samples_per_second': 1417.146, 'train_steps_per_second': 30.597, 'train_loss': 0.360548882735403, 'epoch': 5.0}\n",
      "-----------------Fold: 5-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6231052875518799, 'eval_accuracy': 0.6272727272727273, 'eval_f1': 0.6255454244530709, 'eval_precision': 0.6446084486166008, 'eval_recall': 0.6272727272727273, 'eval_runtime': 0.899, 'eval_samples_per_second': 244.705, 'eval_steps_per_second': 5.561, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7502521276473999, 'eval_accuracy': 0.6590909090909091, 'eval_f1': 0.6589429909333213, 'eval_precision': 0.670924117205109, 'eval_recall': 0.6590909090909091, 'eval_runtime': 1.0527, 'eval_samples_per_second': 208.985, 'eval_steps_per_second': 4.75, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2925001382827759, 'eval_accuracy': 0.5909090909090909, 'eval_f1': 0.5765404807958, 'eval_precision': 0.6352730087250212, 'eval_recall': 0.5909090909090909, 'eval_runtime': 1.1487, 'eval_samples_per_second': 191.52, 'eval_steps_per_second': 4.353, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3403939008712769, 'eval_accuracy': 0.6818181818181818, 'eval_f1': 0.6803213587487781, 'eval_precision': 0.6806447628458497, 'eval_recall': 0.6818181818181818, 'eval_runtime': 0.9575, 'eval_samples_per_second': 229.755, 'eval_steps_per_second': 5.222, 'epoch': 4.0}\n",
      "{'train_runtime': 50.0471, 'train_samples_per_second': 1758.344, 'train_steps_per_second': 37.964, 'train_loss': 0.3282520645543149, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, eval_index) in enumerate(skf.split(data['texts'], data['labels'])):\n",
    "    print(f\"-----------------Fold: {fold+1}-----------------\")\n",
    "\n",
    "    # 文章分類を行うクラス：BertForSequenceClassification\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "    # モデルをGPUに配置\n",
    "    model\n",
    "    # 訓練データと評価データを辞書型で抽出\n",
    "    train_dataset = {\n",
    "        'texts': [data['texts'][i] for i in train_index],\n",
    "        'labels': [data['labels'][i] for i in train_index]\n",
    "    }\n",
    "    eval_dataset = {\n",
    "        'texts': [data['texts'][i] for i in eval_index],\n",
    "        'labels': [data['labels'][i] for i in eval_index]\n",
    "    }\n",
    "    # データセットの作成\n",
    "    train_encodings = tokenizer(train_dataset['texts'], padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "    train_labels = torch.tensor(train_dataset['labels'])\n",
    "    eval_encodings = tokenizer(eval_dataset['texts'], padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "    eval_labels = torch.tensor(eval_dataset['labels'])\n",
    "    train_dataset = JpSentiDataset(train_encodings, train_labels)\n",
    "    eval_dataset = JpSentiDataset(eval_encodings, eval_labels)\n",
    "    # 学習の設定\n",
    "    # 学習を行う時間を取得\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    # ハイパーパラメータの設定\n",
    "    trainingargs = TrainingArguments(\n",
    "        # 学習を行った時間をファイル名にして保存\n",
    "        output_dir = f\"{output_dir}/{MODEL_NAME}{timestamp}/fold{fold+1}\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=100,\n",
    "        learning_rate=2e-5,\n",
    "        seed=0,\n",
    "        # 進捗バーを表示するかどうか\n",
    "        disable_tqdm = True,\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "    # トレーナーの設定\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=trainingargs,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Fold: 1-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6185951828956604, 'eval_accuracy': 0.6545454545454545, 'eval_f1': 0.645618749067025, 'eval_precision': 0.6559018545319916, 'eval_recall': 0.6545454545454545, 'eval_runtime': 1.0445, 'eval_samples_per_second': 210.627, 'eval_steps_per_second': 4.787, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5883213877677917, 'eval_accuracy': 0.7090909090909091, 'eval_f1': 0.7072535885167464, 'eval_precision': 0.7083916083916085, 'eval_recall': 0.7090909090909091, 'eval_runtime': 0.9892, 'eval_samples_per_second': 222.411, 'eval_steps_per_second': 5.055, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6172588467597961, 'eval_accuracy': 0.7090909090909091, 'eval_f1': 0.7055335968379447, 'eval_precision': 0.7097020626432391, 'eval_recall': 0.7090909090909091, 'eval_runtime': 1.188, 'eval_samples_per_second': 185.184, 'eval_steps_per_second': 4.209, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.664452314376831, 'eval_accuracy': 0.7181818181818181, 'eval_f1': 0.7125981489134418, 'eval_precision': 0.722118257329525, 'eval_recall': 0.7181818181818181, 'eval_runtime': 1.0125, 'eval_samples_per_second': 217.294, 'eval_steps_per_second': 4.938, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7310881018638611, 'eval_accuracy': 0.7181818181818181, 'eval_f1': 0.7181818181818181, 'eval_precision': 0.7181818181818181, 'eval_recall': 0.7181818181818181, 'eval_runtime': 1.0584, 'eval_samples_per_second': 207.859, 'eval_steps_per_second': 4.724, 'epoch': 5.0}\n",
      "{'train_runtime': 61.9424, 'train_samples_per_second': 1420.674, 'train_steps_per_second': 30.674, 'train_loss': 0.4094097338224712, 'epoch': 5.0}\n",
      "-----------------Fold: 2-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6309741139411926, 'eval_accuracy': 0.6363636363636364, 'eval_f1': 0.6132505991660921, 'eval_precision': 0.6476876781754831, 'eval_recall': 0.6363636363636364, 'eval_runtime': 1.1361, 'eval_samples_per_second': 193.644, 'eval_steps_per_second': 4.401, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6325587630271912, 'eval_accuracy': 0.6454545454545455, 'eval_f1': 0.6438115013090187, 'eval_precision': 0.663568428853755, 'eval_recall': 0.6454545454545455, 'eval_runtime': 1.024, 'eval_samples_per_second': 214.843, 'eval_steps_per_second': 4.883, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6312320232391357, 'eval_accuracy': 0.6727272727272727, 'eval_f1': 0.6724267468069122, 'eval_precision': 0.6722375984671067, 'eval_recall': 0.6727272727272727, 'eval_runtime': 1.1626, 'eval_samples_per_second': 189.226, 'eval_steps_per_second': 4.301, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6108844876289368, 'eval_accuracy': 0.7272727272727273, 'eval_f1': 0.7250621718706826, 'eval_precision': 0.7272727272727273, 'eval_recall': 0.7272727272727273, 'eval_runtime': 1.0902, 'eval_samples_per_second': 201.795, 'eval_steps_per_second': 4.586, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7171614170074463, 'eval_accuracy': 0.6909090909090909, 'eval_f1': 0.6911390122399297, 'eval_precision': 0.7006707151273452, 'eval_recall': 0.6909090909090909, 'eval_runtime': 1.1767, 'eval_samples_per_second': 186.969, 'eval_steps_per_second': 4.249, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.805457353591919, 'eval_accuracy': 0.740909090909091, 'eval_f1': 0.7361342183149157, 'eval_precision': 0.7455622750532528, 'eval_recall': 0.740909090909091, 'eval_runtime': 1.1363, 'eval_samples_per_second': 193.607, 'eval_steps_per_second': 4.4, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0592164993286133, 'eval_accuracy': 0.7090909090909091, 'eval_f1': 0.7096686828563691, 'eval_precision': 0.7144660894660896, 'eval_recall': 0.7090909090909091, 'eval_runtime': 1.0554, 'eval_samples_per_second': 208.447, 'eval_steps_per_second': 4.737, 'epoch': 7.0}\n",
      "{'train_runtime': 82.5893, 'train_samples_per_second': 1065.514, 'train_steps_per_second': 23.005, 'train_loss': 0.36112445458433684, 'epoch': 7.0}\n",
      "-----------------Fold: 3-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5909446477890015, 'eval_accuracy': 0.6272727272727273, 'eval_f1': 0.6243067277550037, 'eval_precision': 0.6487603305785123, 'eval_recall': 0.6272727272727273, 'eval_runtime': 0.9662, 'eval_samples_per_second': 227.687, 'eval_steps_per_second': 5.175, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5700275301933289, 'eval_accuracy': 0.7227272727272728, 'eval_f1': 0.7223276191127292, 'eval_precision': 0.72219809358356, 'eval_recall': 0.7227272727272728, 'eval_runtime': 1.1253, 'eval_samples_per_second': 195.509, 'eval_steps_per_second': 4.443, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6233312487602234, 'eval_accuracy': 0.7181818181818181, 'eval_f1': 0.7043900233348673, 'eval_precision': 0.7394112624819035, 'eval_recall': 0.7181818181818181, 'eval_runtime': 1.1251, 'eval_samples_per_second': 195.538, 'eval_steps_per_second': 4.444, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.545831024646759, 'eval_accuracy': 0.740909090909091, 'eval_f1': 0.7361342183149157, 'eval_precision': 0.7455622750532528, 'eval_recall': 0.740909090909091, 'eval_runtime': 0.9241, 'eval_samples_per_second': 238.063, 'eval_steps_per_second': 5.411, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5968321561813354, 'eval_accuracy': 0.7318181818181818, 'eval_f1': 0.732368110358541, 'eval_precision': 0.7353650564659739, 'eval_recall': 0.7318181818181818, 'eval_runtime': 1.0403, 'eval_samples_per_second': 211.48, 'eval_steps_per_second': 4.806, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6493903398513794, 'eval_accuracy': 0.7772727272727272, 'eval_f1': 0.7769516940413725, 'eval_precision': 0.7769218460694447, 'eval_recall': 0.7772727272727272, 'eval_runtime': 1.0058, 'eval_samples_per_second': 218.73, 'eval_steps_per_second': 4.971, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8105540871620178, 'eval_accuracy': 0.740909090909091, 'eval_f1': 0.740795641731858, 'eval_precision': 0.7407129142666332, 'eval_recall': 0.740909090909091, 'eval_runtime': 1.0849, 'eval_samples_per_second': 202.785, 'eval_steps_per_second': 4.609, 'epoch': 7.0}\n",
      "{'train_runtime': 86.8277, 'train_samples_per_second': 1013.502, 'train_steps_per_second': 21.882, 'train_loss': 0.349682829433814, 'epoch': 7.0}\n",
      "-----------------Fold: 4-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6305538415908813, 'eval_accuracy': 0.6909090909090909, 'eval_f1': 0.6838842975206613, 'eval_precision': 0.6941786283891547, 'eval_recall': 0.6909090909090909, 'eval_runtime': 0.9508, 'eval_samples_per_second': 231.391, 'eval_steps_per_second': 5.259, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6028831005096436, 'eval_accuracy': 0.6772727272727272, 'eval_f1': 0.6736811677988148, 'eval_precision': 0.6765300059417706, 'eval_recall': 0.6772727272727272, 'eval_runtime': 1.0648, 'eval_samples_per_second': 206.62, 'eval_steps_per_second': 4.696, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6492401361465454, 'eval_accuracy': 0.7090909090909091, 'eval_f1': 0.7006090057114007, 'eval_precision': 0.7168304668304668, 'eval_recall': 0.7090909090909091, 'eval_runtime': 1.08, 'eval_samples_per_second': 203.695, 'eval_steps_per_second': 4.629, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6149250864982605, 'eval_accuracy': 0.7, 'eval_f1': 0.6969773939547881, 'eval_precision': 0.6997570288094411, 'eval_recall': 0.7, 'eval_runtime': 1.1612, 'eval_samples_per_second': 189.455, 'eval_steps_per_second': 4.306, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8628806471824646, 'eval_accuracy': 0.6909090909090909, 'eval_f1': 0.6771425817024969, 'eval_precision': 0.7045454545454546, 'eval_recall': 0.6909090909090909, 'eval_runtime': 1.0643, 'eval_samples_per_second': 206.71, 'eval_steps_per_second': 4.698, 'epoch': 5.0}\n",
      "{'train_runtime': 62.7803, 'train_samples_per_second': 1401.713, 'train_steps_per_second': 30.264, 'train_loss': 0.44901966295744244, 'epoch': 5.0}\n",
      "-----------------Fold: 5-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.626086413860321, 'eval_accuracy': 0.5863636363636363, 'eval_f1': 0.5841293374147946, 'eval_precision': 0.6027693236995563, 'eval_recall': 0.5863636363636363, 'eval_runtime': 0.8924, 'eval_samples_per_second': 246.519, 'eval_steps_per_second': 5.603, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6580135226249695, 'eval_accuracy': 0.6272727272727273, 'eval_f1': 0.6190425499558989, 'eval_precision': 0.6647727272727273, 'eval_recall': 0.6272727272727273, 'eval_runtime': 0.9007, 'eval_samples_per_second': 244.267, 'eval_steps_per_second': 5.552, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6498874425888062, 'eval_accuracy': 0.6863636363636364, 'eval_f1': 0.6846424250070248, 'eval_precision': 0.6852449875705688, 'eval_recall': 0.6863636363636364, 'eval_runtime': 1.1462, 'eval_samples_per_second': 191.945, 'eval_steps_per_second': 4.362, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/is/akiyoshi-n/my-project/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7803714871406555, 'eval_accuracy': 0.6454545454545455, 'eval_f1': 0.6454545454545455, 'eval_precision': 0.6562121212121211, 'eval_recall': 0.6454545454545455, 'eval_runtime': 0.9106, 'eval_samples_per_second': 241.586, 'eval_steps_per_second': 5.491, 'epoch': 4.0}\n",
      "{'train_runtime': 49.7838, 'train_samples_per_second': 1767.642, 'train_steps_per_second': 38.165, 'train_loss': 0.4794906816984478, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, eval_index) in enumerate(skf.split(data['texts'], data['labels'])):\n",
    "    print(f\"-----------------Fold: {fold+1}-----------------\")\n",
    "\n",
    "    # 文章分類を行うクラス：BertForSequenceClassification\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "    # モデルをGPUに配置\n",
    "    model\n",
    "    # 訓練データと評価データを辞書型で抽出\n",
    "    train_dataset = {\n",
    "        'texts': [data['texts'][i] for i in train_index],\n",
    "        'labels': [data['labels'][i] for i in train_index]\n",
    "    }\n",
    "    eval_dataset = {\n",
    "        'texts': [data['texts'][i] for i in eval_index],\n",
    "        'labels': [data['labels'][i] for i in eval_index]\n",
    "    }\n",
    "    # データセットの作成\n",
    "    train_encodings = tokenizer(train_dataset['texts'], padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "    train_labels = torch.tensor(train_dataset['labels'])\n",
    "    eval_encodings = tokenizer(eval_dataset['texts'], padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "    eval_labels = torch.tensor(eval_dataset['labels'])\n",
    "    train_dataset = JpSentiDataset(train_encodings, train_labels)\n",
    "    eval_dataset = JpSentiDataset(eval_encodings, eval_labels)\n",
    "    # 学習の設定\n",
    "    # 学習を行う時間を取得\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    # ハイパーパラメータの設定\n",
    "    trainingargs = TrainingArguments(\n",
    "        # 学習を行った時間をファイル名にして保存\n",
    "        output_dir = f\"{output_dir}/{MODEL_NAME}{timestamp}/fold{fold+1}\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=100,\n",
    "        learning_rate=2e-5,\n",
    "        seed=0,\n",
    "        # 進捗バーを表示するかどうか\n",
    "        disable_tqdm = True,\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "    # トレーナーの設定\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=trainingargs,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wandb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/is/akiyoshi-n/my-project/notebooks/act2.ipynb セル 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bkogecha/home/is/akiyoshi-n/my-project/notebooks/act2.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwandb\u001b[39;00m \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wandb'"
     ]
    }
   ],
   "source": [
    "import wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(data['texts'], padding=True, truncation=True, max_length=128, return_tensors='pt').to(device)\n",
    "train_labels = torch.tensor(data['labels']).to(device)\n",
    "train_dataset = JpSentiDataset(train_encodings, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([1100, 128])\n",
      "token_type_ids torch.Size([1100, 128])\n",
      "attention_mask torch.Size([1100, 128])\n"
     ]
    }
   ],
   "source": [
    "for key, val in a.items():\n",
    "    print(key, val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = JpSentiDataset(a, data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class JpSentiDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = JpSentiDataset(a, data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1653171/2963044426.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    2, 11719,  6307,   896, 29588,  6146,   892,  1897,  2302,   896,\n",
       "         20487,   897, 14245,  3099,   889, 13049, 17420,  1476,   829, 11145,\n",
       "         20487,   862,  1523,  7390, 15066, 16080,   881,   829,  4370, 10101,\n",
       "           829, 14594,   916,   873,   888,  1031,  2202,   897, 12224, 12337,\n",
       "           829, 11258,   829, 13711,   828,  1330, 14594,   862,   829, 17773,\n",
       "          3287,  6304,   889, 12332,  6215,   829,  5670, 23796,   888,    15,\n",
       "          3762,   890,  5512,  6262, 11661,   896,  1104,   893,  1976, 23508,\n",
       "           932,  3918,  3022,   860,   895, 17567,   873, 12343,   812,     3,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "880"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset['texts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 31 11:13:28 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Quadro P6000                   On  | 00000000:1A:00.0 Off |                  Off |\n",
      "| 26%   25C    P8               8W / 250W |      4MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 8000                On  | 00000000:67:00.0 Off |                  Off |\n",
      "| 68%   88C    P2             237W / 260W |  20911MiB / 49152MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 8000                On  | 00000000:68:00.0 Off |                  Off |\n",
      "| 63%   79C    P2             128W / 260W |  26209MiB / 49152MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    1   N/A  N/A   2113277      C   ...o-ni/miniconda3/envs/NEC/bin/python     1132MiB |\n",
      "|    1   N/A  N/A   2114525      C   ...s/takuya-f/Med-LLM/.venv/bin/python    19776MiB |\n",
      "|    2   N/A  N/A   2114525      C   ...s/takuya-f/Med-LLM/.venv/bin/python    26206MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32768, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/is/akiyoshi-n/my-project/notebooks/act2.ipynb セル 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bkogecha/home/is/akiyoshi-n/my-project/notebooks/act2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_dataset\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "train_data = Dataset.from_dict(train_dataset)\n",
    "test_data = Dataset.from_dict(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data = DatasetDict({'train': train_data, 'test': test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['texts', 'labels'],\n",
       "        num_rows: 880\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['texts', 'labels'],\n",
       "        num_rows: 220\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "def compute_metrics(eval_pred):\n",
    "    pred, labels = eval_pred\n",
    "    pred = np.argmax(pred, axis=-1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# 東北大バートversion2モデルを使用\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "# 学習を行う時間を取得\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "args = TrainingArguments(\n",
    "    # 学習を行った時間をファイル名にして保存\n",
    "    output_dir = {f\"{output_dir}/{MODEL_NAME}{timestamp}\"},\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=100,\n",
    "    seed=0,\n",
    "    # 進捗バーを表示するかどうか\n",
    "    disable_tqdm = True,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 東北大バートversion2モデルを使用\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# 交差検証の実行\n",
    "trainer = ActClassifier(model_name = MODEL_NAME, num_labels=num_labels, tokenizer=tokenizer, criterion=CRITERION, device=device, seed=SEED)\n",
    "trainer.train_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ作成のためのコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# 東北大バートversion2モデルを使用\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 3946, 897, 14385, 12461, 28, 12203, 893, 14167, 932, 13507, 888, 854, 12343, 28, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer('私は先生です．生徒に数学を教えています．')\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 私 は 先生 です. 生徒 に 数学 を 教え て い ます. [SEP]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2,  3946,   897, 14385, 12461,    28, 12203,   893, 14167,   932,\n",
      "         13507,   888,   854, 12343,    28,     3,     0,     0,     0],\n",
      "        [    2,  3946,   897, 12203, 12461,    28, 14385,   893, 14167,   932,\n",
      "         13507,   888, 16744,   888,   854, 12343,    28,     3,     0],\n",
      "        [    2,  3946,   897, 15681, 12461,    28, 14385,   918, 12203,   893,\n",
      "         12269,  2706,   932, 13507,   888,   854, 12343,    28,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "batch_sentences = [\n",
    "    '私は先生です．生徒に数学を教えています．',\n",
    "    '私は生徒です．先生に数学を教えてもらっています．',\n",
    "    '私は校長です．先生や生徒に生き方を教えています．',\n",
    "]\n",
    "encoded_inputs = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(encoded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "train_data = Dataset.from_dict(train_dataset)\n",
    "test_data = Dataset.from_dict(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"texts\"], padding=True, truncation=True, max_length=128)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": np.mean(predictions == labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoModelForSequenceClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/is/akiyoshi-n/my-project/notebooks/act2.ipynb セル 41\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkogecha/home/is/akiyoshi-n/my-project/notebooks/act2.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 文章分類を行うクラス：BertForSequenceClassification\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bkogecha/home/is/akiyoshi-n/my-project/notebooks/act2.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForSequenceClassification\u001b[39m.\u001b[39mfrom_pretrained(MODEL_NAME, num_labels\u001b[39m=\u001b[39mnum_labels)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkogecha/home/is/akiyoshi-n/my-project/notebooks/act2.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# set the wandb project where this run will be logged\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkogecha/home/is/akiyoshi-n/my-project/notebooks/act2.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mWANDB_PROJECT\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmy-awesome-project\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoModelForSequenceClassification' is not defined"
     ]
    }
   ],
   "source": [
    "# 文章分類を行うクラス：BertForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "\n",
    "# set the wandb project where this run will be logged\n",
    "os.environ[\"WANDB_PROJECT\"]=\"my-awesome-project\"\n",
    "\n",
    "# save your trained model checkpoint to wandb\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "\n",
    "# turn off watch to log faster\n",
    "os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "\n",
    "# 訓練データと評価データを辞書型で抽出\n",
    "train_dataset = {\n",
    "    'texts': [data['texts'][i] for i in range(900)],\n",
    "    'labels': [data['labels'][i] for i in range(900)]\n",
    "}\n",
    "eval_dataset = {\n",
    "    'texts': [data['texts'][i] for i in range(900, 1100)],\n",
    "    'labels': [data['labels'][i] for i in range(900, 1100)]\n",
    "}\n",
    "# データセットの作成\n",
    "train_data = Dataset.from_dict(train_dataset)\n",
    "eval_data = Dataset.from_dict(eval_dataset)\n",
    "\n",
    "train_dataset = train_data.map(tokenize_function, batched=True)\n",
    "eval_dataset = eval_data.map(tokenize_function, batched=True)\n",
    "\n",
    "# 学習を行う時間を取得\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "# ハイパーパラメータの設定\n",
    "trainingargs = TrainingArguments(\n",
    "    # 学習を行った時間をファイル名にして保存\n",
    "    output_dir = f\"{output_dir}/{MODEL_NAME}{timestamp}\",\n",
    "    report_to=\"wandb\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=100,\n",
    "    learning_rate=2e-5,\n",
    "    seed=0,\n",
    "    # 進捗バーを表示するかどうか\n",
    "    disable_tqdm = True,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "# トレーナーの設定\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=trainingargs,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "trainer.train()\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
